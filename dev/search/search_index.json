{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Azure IoT Edge LoRaWAN Starter Kit Built for Low Power Wide Area Network Connectivity to Azure IoT Hub The LoRaWAN starter kit is an OSS cross platform private network implementation of the LoRaWAN specification built for connectivity to Azure IoT Hub. It enables users to setup their own LoRaWAN network that can connect to LoRa based nodes (sensors) and send decoded message packets to Azure IoT Hub for cloud based processing, analytics and other workloads. Alternatively, it allows sending commands from the cloud to the end nodes. The goal of the the project is to provide guidance and a reference for Azure IoT Edge users to experiment with LoRaWAN technology. There is a list of possible deployment scenarios that outlines some of the scenarios this Starter Kit enables. Key Challenges Allows LoRa-enabled field gateways to connect directly to Azure without the need for a network operator as intermediary. Enables Azure IoT Edge capabilities for the LoRaWAN network, e.g.: Local processing on the Edge gateway Routing to local storage from the Edge gateway Offline capabilities of the gateway Homogenous management of devices and concentrators independent of connectivity technology through Azure IoT. Off-the-shelf integration with Azure IoT ecosystem, e.g., Azure IoT Hub, Azure Digital Twins, Time Series Insights, etc... Features LoRaWAN 1.0.2 implementation (see LoRaWAN Specification Support for more details) Device and Concentrator management done through Azure IoT Hub. Bi-directional communication between LoRa end devices and Azure cloud. Custom packet decoding framework. Identity Translation for LoRa devices with caching support. Partial Offline and Casually connected Gateways scenarios.* Easy deployment and setup using Azure ARM templates. Small to Midsize Scalability Tests. Simulator for development and testing without the need to own a Gateway. LoRaWAN Specification Support We plan to support the following key features of LoRaWAN 1.0.2 specification, however please note that not all of them are available as of today. Please refer to our release notes for more details on what is available. Current supported Specification: 1.0.2 . Support of Class A and C devices. Support of EU868 , US915 , AS923 , CN470 and AU915 channel frequencies. Activation through ABP and OTAA . Confirmed and unconfirmed upstream messages. Confirmed and unconfirmed downstream messages. Multi-gateways. Multi-concentrators. LoRa Basics\u2122 Station Support Message de-duplication. Support of MAC commands. ADR Support. Getting Started We have a variety of ways you can get started with the kit, chose the appropriate documentation based on your persona and applicability. Setup a LoRaWAN Gateway : We provide an easy to use Azure ARM template and deployment guidance to get you quickly started with the LoRaWAN starter kit. Use the Quick Start to setup a LoRaWAN Gateway and connect to LoRA end nodes. Upgrade an existing installation : Refer to the upgrade guide for instructions and tips for a clean upgrade. Develop and debug the LoRaWAN starter kit : If you are a developer and want to contribute or customize the LoRaWAN starter kit, refer to our Developer Guidance for more details on how to build, test and deploy the kit in your dev environment. We also support a Enable a gateway or device to be compatible with the starter kit : We have developed the LoRaWAN starter kit agnostic of a device manufacturer implementation and focused on the specifics on underlying architectures (arm, x86). However, we understand that device manufacturers can have specific requirements; these could be specific to the gateway and the concentrator they use, or to the LoRa nodes and the decoders the device may use. We have provided specific instructions on making such specialized hardware compatible with our kit. You can follow these instructions depending on your scenarios and also have your device gateway highlighted on our repo. Known Issues and Limitations Refer to Known Issues for known issues, gotchas and limitations. Tested Gateways Seeed Studio LoRa LoRaWAN Gateway - 868MHz Kit with Raspberry Pi 3 AAEON AIOT-ILRA01 LoRa\u00ae Certified Intel\u00ae Based Gateway and Network Server AAEON Indoor 4G LoRaWAN Edge Gateway & Network Server AAEON AIOT-IP6801 Multi radio Outdoor Industrial Edge Gateway MyPi Industrial IoT Integrator Board with RAK833-SPI mPCIe-LoRa-Concentrator Raspberry Pi 3 with IC880A RAK833-USB mPCIe-LoRa-Concentrator with Raspberry Pi 3","title":"Home"},{"location":"#azure-iot-edge-lorawan-starter-kit","text":"Built for Low Power Wide Area Network Connectivity to Azure IoT Hub The LoRaWAN starter kit is an OSS cross platform private network implementation of the LoRaWAN specification built for connectivity to Azure IoT Hub. It enables users to setup their own LoRaWAN network that can connect to LoRa based nodes (sensors) and send decoded message packets to Azure IoT Hub for cloud based processing, analytics and other workloads. Alternatively, it allows sending commands from the cloud to the end nodes. The goal of the the project is to provide guidance and a reference for Azure IoT Edge users to experiment with LoRaWAN technology. There is a list of possible deployment scenarios that outlines some of the scenarios this Starter Kit enables.","title":"Azure IoT Edge LoRaWAN Starter Kit"},{"location":"#key-challenges","text":"Allows LoRa-enabled field gateways to connect directly to Azure without the need for a network operator as intermediary. Enables Azure IoT Edge capabilities for the LoRaWAN network, e.g.: Local processing on the Edge gateway Routing to local storage from the Edge gateway Offline capabilities of the gateway Homogenous management of devices and concentrators independent of connectivity technology through Azure IoT. Off-the-shelf integration with Azure IoT ecosystem, e.g., Azure IoT Hub, Azure Digital Twins, Time Series Insights, etc...","title":"Key Challenges"},{"location":"#features","text":"LoRaWAN 1.0.2 implementation (see LoRaWAN Specification Support for more details) Device and Concentrator management done through Azure IoT Hub. Bi-directional communication between LoRa end devices and Azure cloud. Custom packet decoding framework. Identity Translation for LoRa devices with caching support. Partial Offline and Casually connected Gateways scenarios.* Easy deployment and setup using Azure ARM templates. Small to Midsize Scalability Tests. Simulator for development and testing without the need to own a Gateway.","title":"Features"},{"location":"#lorawan-specification-support","text":"We plan to support the following key features of LoRaWAN 1.0.2 specification, however please note that not all of them are available as of today. Please refer to our release notes for more details on what is available. Current supported Specification: 1.0.2 . Support of Class A and C devices. Support of EU868 , US915 , AS923 , CN470 and AU915 channel frequencies. Activation through ABP and OTAA . Confirmed and unconfirmed upstream messages. Confirmed and unconfirmed downstream messages. Multi-gateways. Multi-concentrators. LoRa Basics\u2122 Station Support Message de-duplication. Support of MAC commands. ADR Support.","title":"LoRaWAN Specification Support"},{"location":"#getting-started","text":"We have a variety of ways you can get started with the kit, chose the appropriate documentation based on your persona and applicability. Setup a LoRaWAN Gateway : We provide an easy to use Azure ARM template and deployment guidance to get you quickly started with the LoRaWAN starter kit. Use the Quick Start to setup a LoRaWAN Gateway and connect to LoRA end nodes. Upgrade an existing installation : Refer to the upgrade guide for instructions and tips for a clean upgrade. Develop and debug the LoRaWAN starter kit : If you are a developer and want to contribute or customize the LoRaWAN starter kit, refer to our Developer Guidance for more details on how to build, test and deploy the kit in your dev environment. We also support a Enable a gateway or device to be compatible with the starter kit : We have developed the LoRaWAN starter kit agnostic of a device manufacturer implementation and focused on the specifics on underlying architectures (arm, x86). However, we understand that device manufacturers can have specific requirements; these could be specific to the gateway and the concentrator they use, or to the LoRa nodes and the decoders the device may use. We have provided specific instructions on making such specialized hardware compatible with our kit. You can follow these instructions depending on your scenarios and also have your device gateway highlighted on our repo.","title":"Getting Started"},{"location":"#known-issues-and-limitations","text":"Refer to Known Issues for known issues, gotchas and limitations.","title":"Known Issues and Limitations"},{"location":"#tested-gateways","text":"Seeed Studio LoRa LoRaWAN Gateway - 868MHz Kit with Raspberry Pi 3 AAEON AIOT-ILRA01 LoRa\u00ae Certified Intel\u00ae Based Gateway and Network Server AAEON Indoor 4G LoRaWAN Edge Gateway & Network Server AAEON AIOT-IP6801 Multi radio Outdoor Industrial Edge Gateway MyPi Industrial IoT Integrator Board with RAK833-SPI mPCIe-LoRa-Concentrator Raspberry Pi 3 with IC880A RAK833-USB mPCIe-LoRa-Concentrator with Raspberry Pi 3","title":"Tested Gateways"},{"location":"contributing/","text":"Contributing If you would like to contribute to the IoT Edge LoRaWAN Starter Kit source code, please base your own branch and pull request (PR) off our dev branch. Refer to the Dev Guide for development and debugging instructions.","title":"Contributing"},{"location":"contributing/#contributing","text":"If you would like to contribute to the IoT Edge LoRaWAN Starter Kit source code, please base your own branch and pull request (PR) off our dev branch. Refer to the Dev Guide for development and debugging instructions.","title":"Contributing"},{"location":"issues/","text":"Known Issues and Limitations Reporting Security Issues Security issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) at secure@microsoft.com . You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the MSRC PGP key, can be found in the Security TechCenter . Limitations Tested only for EU868, US915, AS923, CN470 and AU915 frequency IoT Edge must have internet connectivity, it can work for limited time offline if the device has previously transmitted an upstream message. The network server Azure IoT Edge module and the Facade function have an API dependency on each other. its generally recommended for the deployments on the same source level. In addition we generally recommend as read the Azure IoT Edge trouble shooting guide","title":"Known Issues"},{"location":"issues/#known-issues-and-limitations","text":"","title":"Known Issues and Limitations"},{"location":"issues/#reporting-security-issues","text":"Security issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) at secure@microsoft.com . You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the MSRC PGP key, can be found in the Security TechCenter .","title":"Reporting Security Issues"},{"location":"issues/#limitations","text":"Tested only for EU868, US915, AS923, CN470 and AU915 frequency IoT Edge must have internet connectivity, it can work for limited time offline if the device has previously transmitted an upstream message. The network server Azure IoT Edge module and the Facade function have an API dependency on each other. its generally recommended for the deployments on the same source level. In addition we generally recommend as read the Azure IoT Edge trouble shooting guide","title":"Limitations"},{"location":"license/","text":"MIT License Copyright (c) Microsoft Corporation. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE Third party licenses This software incorporates material from third parties: LoRaEngine/modules/LoRaWanNetworkSrvModule/NOTICE.txt LoRaEngine/modules/LoRaBasicsStationModule/NOTICE.txt Samples/UniversalDecoder/NOTICE.txt","title":"License"},{"location":"license/#mit-license","text":"Copyright (c) Microsoft Corporation. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE","title":"MIT License"},{"location":"license/#third-party-licenses","text":"This software incorporates material from third parties: LoRaEngine/modules/LoRaWanNetworkSrvModule/NOTICE.txt LoRaEngine/modules/LoRaBasicsStationModule/NOTICE.txt Samples/UniversalDecoder/NOTICE.txt","title":"Third party licenses"},{"location":"quickstart/","text":"An Azure deployment template is available to deploy all the required Azure infrastructure and get you started quickly. If you'd rather deploy it manually please jump directly into the do it yourself section . Prerequisites The following should be completed before proceeding with the LoRaWAN starter kit development or deployment in your environment. You must have an Azure subscription. Get an Azure Free account to get started. We are based on Azure IoT Edge so it is important that you understand the concepts and deployment model for Azure IoT Edge. Refer to Azure IoT Edge documentation to see how it works. Understand how LoRa and LoRaWAN works. A great primer is available at the LoRa Alliance website . To test the solution on a device, you need to have a LoRaWAN Device Kit Gateway and a LoRa end node. We have some recommendations in the Tested Gateways section below. The template supports x86 and ARM architectures and will automatically deploy the correct version to your gateway. Make sure to provide your gateway's reset pin in the dialog before the deployment. However, your gateway might use a different SPI_DEV or SPI_SPEED, and the Basics Station module could not work out-of-the-box. To fix this, refer to the Basics Station Module Configuration page. The LoRa device demo code in the Arduino folder is built only for Seeduino LoRaWan board and was not test with other Arduino LoRa boards. Deployed Azure Infrastructure The template will deploy in your Azure subscription the Following resources: IoT Hub Azure Function Redis Cache Application Insights Log Analytics App Service (when opted in to use standalone discovery service ) Step-by-step instructions Press on the button here below to start your Azure Deployment. You will get to a page asking you to fill the following fields : - Resource Group - A logical \"folder\" where all the template resource would be put into, just choose a meaningful name. - Location - In which DataCenter the resources should be deployed. Make sure to choose a location where IoT Hub is available - Unique Solution Prefix - A string that would be used as prefix for all the resources name to ensure their uniqueness. Hence, avoid any standard prefix such as \"lora\" as it might already be in use and might make your deployment fail. NB: the template is creating a Storage account with the value specified here, therefore the naming restrictions of Storage apply here. - Edge gateway name - the name of your LoRa Gateway node in the IoT Hub. - Deploy Device - Do you want demo end devices to be already provisioned (one using OTAA and one using ABP )? If yes set this to true, the code located in the Arduino folder would be ready to use immediately. - Reset pin - The reset pin of your gateway (the value should be 7 for the Seed Studio LoRaWam, 25 for the IC880A) - Region - In what region are you operating your device (currently only EU868 and US915 is supported) - Station Eui - The EUI of the Basics Station concentrator that will be used for connecting to LoRaWAN Network Server - Spi speed - (In Mbps) Custom SPI speed for your gateway, currently only supported for ARM gateways - Spi dev - A number identifying the SPI location where the board should be accessed (i.e.: when X, board accessed at /dev/spidevX.0) - Use Azure Monitor On Edge - You can opt out of using Azure Monitor services for observability on IoT Edge. - Use Discovery Service - You can opt in to use a standalone discovery service. This deploys an additional App Service (including a dedicated App Service Plan). Detailed information can be found LNS Discovery . The deployment would take c.a. 10 minutes to complete. During this time, you can proceed to install IoT Edge to your gateway . Once the Azure deployment is finished, connect your IoT Edge with the cloud as described in point 3 . You can get the connection string by clicking on the deployed IoT Hub -> IoT Edge Devices -> Connection string, as shown in the picture below. If your gateway is a Raspberry Pi, don't forget to enable SPI and to restart your Pi By using the docker ps command, you should see the Edge containers being deployed on your local gateway. You can now try one of the samples in the Arduino folder to see LoRa messages being sent to the cloud. If you have checked the Deploy Device checkbox you can use this sample directly \"TransmissionTestOTAALoRa.ino\" without provisioning the device first. What does the template do? The template provision an IoT Hub with a LoRa Basics\u2122 Station and a network server module already pre-configured to work out of the box. As soon as you connect your IoT Edge device in point 4 above, those will be pushed on your device. You can find template definition and Edge deployment specification here . When setting the \"deployDevice\" argument to true, some LoRaWan devices will be ready to be used immediately, please consult the Arduino Samples Documentation to discover how to quickly use them for tests. If you are using the the RAK833-USB, you'll need to build a different LoRa Basics\u2122 Station image. You can find a fork of the official Basic Station repository with support for RAK833-USB here . If you are using a SX1302 (Corecell) board, you'll need to properly configure the built-in deployed module by having a look at the parameters in Basics\u2122 Station Module Configuration page. Using a Proxy Server to connect your Concentrator to Azure This is an optional configuration that should only be executed if your concentrator needs to use a proxy server to communicate with Azure. Follow this guide to: Configure the Docker daemon and the IoT Edge daemon on your device to use a proxy server. Configure the edgeAgent properties in the config.yaml file on your device. Set environment variables for the IoT Edge runtime in the deployment manifest. Add the https_proxy environment variable to the LoRaWanNetworkSrvModule in IoT Hub. LoRa Device provisioning A LoRa device is a normal IoT Hub device with some specific device twin tags. You manage it like you would with any other IoT Hub device. To avoid caching issues you should not allow the device to join or send data before it is provisioned in IoT Hub. In case that you did please follow the ClearCache procedure that you find below. ABP (personalization) and OTAA (over the air) provisioning You can provision the devices manually in the Azure portal or better use the provided Command Line Interface Provisioning Tool to list , query , verify , add , update , and remove devices in IoT Hub. It is also recommended to use the CLI tool to verify manually added or edited LoRa devices in IoT Hub to ensure the device twin settings are all correct and will work. To manually provision: Login in to the Azure portal go to IoT Hub -> IoT devices -> Add Use the DeviceEUI as DeviceID -> Save Click on the newly created device Click on Device Twin menu Add the followings desired properties for OTAA : \"desired\" : { \"AppEUI\" : \"App EUI\" , \"AppKey\" : \"App Key\" , \"GatewayID\" : \"\" , \"SensorDecoder\" : \"\" }, Or the followings desired properties for ABP : DevAddr must be unique for every device! It is like an ip address for lora. \"desired\" : { \"AppSKey\" : \"Device AppSKey\" , \"NwkSKey\" : \"Device NwkSKey\" , \"DevAddr\" : \"Device Addr\" , \"SensorDecoder\" : \"\" , \"GatewayID\" : \"\" }, It should look something like this for ABP : { \"deviceId\" : \"BE7A00000000888F\" , \"etag\" : \"AAAAAAAAAAs=\" , \"deviceEtag\" : \"NzMzMTE3MTAz\" , \"status\" : \"enabled\" , \"statusUpdateTime\" : \"0001-01-01T00:00:00\" , \"connectionState\" : \"Disconnected\" , \"lastActivityTime\" : \"2018-08-06T15:16:32.0658492\" , \"cloudToDeviceMessageCount\" : 0 , \"authenticationType\" : \"sas\" , \"x509Thumbprint\" : { \"primaryThumbprint\" : null , \"secondaryThumbprint\" : null }, \"version\" : 324 , \"tags\" : { }, \"properties\" : { \"desired\" : { \"AppSKey\" : \"2B7E151628AED2A6ABF7158809CF4F3C\" , \"NwkSKey\" : \"1B6E151628AED2A6ABF7158809CF4F2C\" , \"DevAddr\" : \"0028B9B9\" , \"SensorDecoder\" : \"\" , \"GatewayID\" : \"\" , \"$metadata\" : { \"$lastUpdated\" : \"2018-03-28T06:12:46.1007943Z\" }, \"$version\" : 1 }, \"reported\" : { \"$metadata\" : { \"$lastUpdated\" : \"2018-08-06T15:16:32.2689851Z\" }, \"$version\" : 313 } } } Click Save Turn on the device and you are ready to go Optional device properties Customization's to lora devices are set by creating specific twin desired properties on the device. The following customization's are available: Name Description Configuration When to use Enable/disable downstream messages Allows disabling the downstream (cloud to device) for a device. By default downstream messages are enabled Add twin desired property \"Downlink\": false to disable downstream messages. The absence of the twin property or setting value to true will enable downlink messages. Disabling downlink on devices decreases message processing latency, since the network server will not look for cloud to device messages when an uplink is received. Only disable it in devices that are not expecting messages from cloud. Acknowledgement of confirmed upstream are sent to devices even when downlink is set to false Preferred receive window Allows setting the device preferred receive window (RX1 or RX2). The default preferred receive window is 1 Add twin desired property \"PreferredWindow\": 2 sets RX2 as preferred window. The absence of the twin property or setting the value to 1 will set RX1 as preferred window. Using the second receive window increases the chances that the end application can process the upstream message and send a cloud to device message to the lora device without requiring and additional upstream message. Basically completing the round trip in less than 2 seconds. Message Deduplication Allows controlling the handling of duplicate messages received by multiple gateways.The default is None. Add twin desired property \"Deduplication\": \"Drop\" to instruct dropping duplicate messages on the gateway, set it to \"Mark\" if you want to mark messages to the IotHub with \"dupmsg\": true in case the message was already processed. Example payload: Device: [47AAC86800430028], Data:[{\"time\":null,\"tmms\":0,\"tmst\":3201165987,\"freq\":868.3,\"chan\":1,\"rfch\":1,\"stat\":1,\"modu\":\"LORA\",\"datr\":\"SF7BW125\",\"codr\":\"4/5\",\"rssi\":-61,\"lsnr\":8.2,\"size\":14,\"data\":{\"value\":1},\"port\":10,\"fcnt\":2,\"rawdata\":\"QImRWQIAAgAK8I3rbqc=\",\"eui\":\"47AAC86800430028\",\"gatewayid\":\"simulatorpaschule1\",\"edgets\":1550501633879, \"dupmsg\": true }] Deduplication on the gateway allows you to control how you want to handle duplicate messages in a multi gateway environment without having to add additional logic on the receiving or processing end. RX1 Datarate Offset Allows setting an offset between received Datarate and retransmit datarate as specified in the LoRa Specifiations. Valid for OTAA devices. If an invalid value is provided the network server will use default value 0. Add twin desired property \"RX1DROffset\": # where # is a valid specification number to create an offset of # between received Datarate and Transmit Datarate. Please find the full table in the LoRa Specification example: upstream DR2, with a RX1DROffset of 1 will result in a transmission on DR1 Setting an offset between receive and transmit could help deal with very saturated network. Warning, this is an advanced option, please only use if you are aware of your network specification. RX2 Datarate Allows setting a custom Datarate for second receive windows. Valid for OTAA devices. If an invalid value is provided the network server will use default value 0 (DR0). Add twin desired property \"RX2DataRate\": # where # is a valid specification number to set the RX2 DR to DR#. Example: if a value of 2 is provided, second receive windows will use DR2 instead of the default DR0. Setting a custom RX2 Datarate could help your RX2 devices to benefit of higher datarate. Warning, this is an advanced topic, changing it to higher datarate could be very dangerous and result in RX2 becoming unusable if the devices are not within reach of the specified datarate. Usage of this feature is especially not recommanded if ADR is enabled. RX Delay Allows setting a custom wait time between receiving and transmission as specified in the specification. Add twin desired property \"RXDelay\": # where # is a valid specification number to set the RxDelay to wait for # seconds. Note that values 0 and 1 are default. Example: if a value of 2 is provided, The RX1 transmit windows will open 2 second after receiving the message. RX2 windows will always stay 1 second after RX1 Setting a custom RXDelay could be usefull in case of long processing time, this could give more time to the server/device to compute their answers and lower the risk of missing the transmission windows. The defaults should work in most production scenarios, we recommend to use the default unless you have an explicit need for a longer delay Disable ABP relax mode Allows to disable the relax mode when using ABP . By default relaxed mode is enabled Add twin desired property \"ABPRelaxMode\": false will disable relaxed mode. Disable the relaxed mode to minimize reply attack possiblitites. Allowing relaxed mode, allows a device to reset framecounters on the server by specifying 0/1. Important : in production deployments, we recommend turning relaxed mode off Specify frame counter up start value Allows to explicitly specify a frame counter up start value. If the device joins, this value will be used to validate the first frame and initialize the server state for the device. Add twin desired property \"FCntUpStart\": 10 will set the frame counter up to 10. If you disable ABP relax mode (see ABPRelaxMode) you usually want to set this value. In general, if your device starts with anything but 0 or 1, you specify the value here. If your device has relaxed mode disabled or uses 32 bit counters and got out of sync, this is a way to re-synchronize the counter between the server and the device. see 32bit counter support and reset counter Specify frame counter down start value Allows to explicitly specify a frame counter down start value. Add twin desired property \"FCntDownStart\": 10 will set the frame counter up to 10. If your device expects a frame counter down other than 1 in the first message, use this to configure the value 32bit counter support Allow the usage of 32bit counters on your device. Add twin desired property \"Supports32BitFCnt\": true will enable 32bit support for your device. Your device will keep a 32bit counter but only sends the lower 16bit over the wire. The server will infere the upper 16bit by looking at the traffic. The additional 2 bytes increase security and minimize the reply atack surface Reset counter Allows to reset the frame counters to the FCntUpStart/FCntDownStart values respectively. Add twin desired property \"FCntResetCounter\": 1 will use the values specified in \"FCntUpStart\" and \"FCntDownStart\" to set the framecounters to the desired values. The \"FCntResetCounter\" in the desired properties has to be higher than the value in the reported properties for this to take effect. If there is no value in the reporte properties yet, it will be applied and the reported properties get updated, as soon as the counters got updated. If your device got out of sync (missed frames larger than the specified MAX_FCNT_GAP in the specification (16384 as of this writing)), you can re-synchronize the counters using this reset mechanism. Device Connection Timeout Allows defining a sliding expiration to the connection between the leaf device and IoT/Edge Hub. The default is none, which causes the connection to not be dropped Add twin desired property \"KeepAliveTimeout\": 60 to add a 60 seconds sliding expiration. The minimum value is 60 seconds. Enabling device connection timeout allows a large device deployment to have a better usage of gateway resources by limiting open connections. We don't recommend enabling connection timeout in devices that send confirmed messages and/or expected cloud to device messages, as the reconnection time might prevent the network server from responding in time. Important : changes made to twin desired properties in devices that are already connected will only take effect once the network server is restarted or cache is cleared . Device Reported Properties This section provide a brief description of the device reported properties you can see appear on your device. Name Description Used By DataRate The Device Current Datarate This value will be only reported if you are using Adaptive Data Rate TxPower The Device Current Transmit Power This value will be only reported if you are using Adaptive Data Rate NbRep The Device Current repetition when transmitting. E.g. if set to two, the device will transmit twice his upstream messages This value will be only reported if you are using Adaptive Data Rate RX2DataRate The Device Current Rx2Datarate This value will be only reported if you set a Custom property as specified in the previous section. The two values might differ as a device value is currently updated only as part of the join process. RX1DROffset The Device Current RX1DROffset This value will be only reported if you set a Custom property as specified in the previous section. The two values might differ as a device value is currently updated only as part of the join process. RXDelay The Device Current RXDelay This value will be only reported if you set a Custom property as specified in the previous section. The two values might differ as a device value is currently updated only as part of the join process. Decoders The SensorDecoder tag is used to define which method will be used to decode the LoRa payload. If you leave it out or empty it will send the raw decrypted payload in the data field of the json message as Base64 encoded value to IoT Hub. If you want to decode it on the Edge you have the following two options: Specify a method that implements the right logic in the LoraDecoders class in the LoraDecoders.cs file of the LoRaWan.NetworkServer . Adapt the DecoderSample which allows you to create and run your own LoRa message decoder in an independent container running on your LoRa gateway without having to edit the main LoRa Engine. This description shows you how to get started. In both cases, we have already provided a simple decoder called \"DecoderValueSensor\" that takes the whole payload as a single numeric value and constructs the following json output as a response (The example of an Arduino sending a sensor value as string (i.e. \"23.5\") is available in the Arduino folder ): { ..... \"data\" : { \"value\" : 23.5 } ..... } If you want the raw decrypted payload to be sent to IoT Hub as Hex encoded value in the data field of the json message, you can set the decoder to \"DecoderHexSensor\" . The byte array {1, 2, 4, 8, 255} for example will be converted to \"01020408FF\" by this built-in decoder. { ..... \"data\" : { \"value\" : \"01020408FF\" } ..... } To add the sample \"DecoderValueSensor\" or \"DecoderHexSensor \" to the sample LoRa device configured above, change it's desired properties in IoT Hub as follows for option 1: \"desired\" : { \"AppEUI\" : \"App EUI\" , \"AppKey\" : \"App Key\" , \"GatewayID\" : \"\" , \"SensorDecoder\" : \"DecoderValueSensor\" }, or as follows for option 2: \"desired\" : { \"AppEUI\" : \"App EUI\" , \"AppKey\" : \"App Key\" , \"GatewayID\" : \"\" , \"SensorDecoder\" : \"http://your_container_name/api/DecoderValueSensor\" }, The \"DecoderValueSensor\" and \"DecoderHexSensor\" decoders are not a best practice but it makes it easier to experiment sending sensor readings to IoT Hub without having to change any code. if the SensorDecoder tag has a \"http\" in it's string value, it will forward the decoding call to an external decoder, as described in option 2 above, using standard Http. The call expects a return value with the same format as the json here above or an error string. Cache Clearing Due to the gateway caching the device information (tags) for 1 day, if the device tries to connect before you have provisioned it, it will not be able to connect because it will be considered a device for another LoRa network. To clear the cache and allow the device to connect follow these steps: IoT Hub -> IoT Edge -> click on the device ID of your gateway Click on LoRaWanNetworkSrvModule Click Direct Method Type \"ClearCache\" on Method Name Click Invoke Method Alternatively you can restart the Gateway or the LoRaWanNetworkSrvModule container. Monitoring and Logging There is a logging mechanism that outputs valuable information to the console of the docker container and can optionally forward these messages to IoT Hub. You can control logging with the following environment variables in the LoRaWanNetworkSrvModule IoT Edge module: Variable Value Explanation LOG_LEVEL \"1\" or \"Debug\" Everything is logged, including the up- and downstream messages to the basic station. \"2\" or \"Information\" Errors and information are logged. \"3\" or \"Error\" Only errors are logged. (default if omitted) For production environments, the LOG_LEVEL should be set to Error . Setting LOG_LEVEL to Debug causes a lot of messages to be generated. Make sure to set LOG_TO_HUB to false in this case. Variable Value Explanation LOG_TO_HUB true Log info are sent from the module to IoT Hub. false Log info is not sent to IoT Hub (default if omitted) You can use VSCode or Azure IoT CLI extension to monitor the log messages directly in IoT Hub if LOG_TO_HUB is set to true . Log in to the gateway and use sudo docker logs LoRaWanNetworkSrvModule -f to follow the logs if you are not logging to IoT Hub. Variable Value Explanation LOG_TO_CONSOLE true Log to docker logs (default if omitted) false Does not log to docker logs Local Processing and Routing By default the network server does not use the local edge queue (edgeHub), sending directly messages to IoT Hub. If you need to do local processing, please set the following setting to true on the LoRaWanNetworkSrvModule . Variable Value Explanation ENABLE_GATEWAY true Messages go to edgeHub and then to IoT Hub false Messages go directly to IoT Hub, skipping local edgeHub Queue LNS Discovery When opted-in to use the LNS discovery service while also opting in to deploy the sample devices using the quickstart template, the LNS discovery service is automatically configured for you. You only need to adapt the hostAddress in the desired properties of the LNS module of your Edge device to point to the real IP/DNS of your gateway. If you did not opt-in to one of the abovementioned options when using the quickstart, refer to the LNS discovery guide for instructions on how to configure the LNS discovery service. Warning The LNS discovery service from the quickstart allows both HTTP and HTTPS per default. Make sure to change this if you only want to allow HTTPS. Customize the solution & Deep dive Have a look at the LoRaEngine folder for more in details explanation. Cloud to device message Sending cloud to device messages in the solution uses the following JSON format to describe the downstream: { \"devEUI\" : \"string\" , \"fport\" : i nte ger , \"confirmed\" : boolea n , \"payload\" : \"string\" , \"rawPayload\" : \"string\" , \"macCommands\" :[ { \"cid\" : \"string\" } ] } Fields Field Type Description Required devEUI String Device EUI Only when sending messages to class C devices fport Integer Payload fport, must be between 1 and 223 if you are sending data. 0 if it is Mac command Yes confirmed Boolean Indicates if an ack is required from the LoRa device. By default false No payload String Payload as text Either payload or rawPayload must be provided rawPayload String Payload as byte encoded in base64 format Either payload or rawPayload must be provided Mac command cid String Mac command identifier. The mac command DevStatusCmd is implemented, allowing you to request a device its status Sending messages using the Azure Function Sending messages to class A devices is a simple task, since those devices will send an upstream link giving the network server the chance of looking in Azure IoT Hub cloud to device message queue for pending downlink messages. Class C devices are more complex because they, for the most part, are only listening for messages. Using the cloud to device message queue would not be very effective as it would require the network server to keep a client connection that would rarely be used, wasting resources. In this solution sending messages to class C devices is available through a direct method in the network server. The Azure Function deployed with the solution can handle both class A and class C devices and, depending on the device type, sends the message via C2D message queue for class A or via direct method for class C devices. In a multiple gateway scenario there is still the need to resolve the closest gateway for a Class C device before calling the relevant network server via direct method. The gateway is resolved in the Azure Function by fetching the device twin and selecting the gateway ID from the twin properties. In order for this mechanism to work, the device first needs to send at least one upstream message so that the LNS can determine the gateway ID and save it in the device twin. In order to send a C2D message to a device using the Azure Function, the SendCloudToDeviceMessage endpoint should be used which takes away the complexity of figuring out the device type and closest gateway. The function endpoint looks like https://YOUR-FUNCTION-NAME.azurewebsites.net/api/cloudtodevicemessage/{devEUI}?code=YOUR-FUNCTION-APP-CODE To send a message to a device send a POST request including the content as the body: curl -d '{\"rawPayload\": \"AAA=\",\"fport\": 1}' -H \"Content-Type: application/json\" -H \"api-version: API-VERSION\" https://YOUR-FUNCTION-NAME.azurewebsites.net/api/cloudtodevicemessage/YOUR-DEVEUI?code = YOUR-FUNCTION-APP-CODE Should return { \"devEUI\" : \"47AAC86800430028\" , \"messageID\" : \"10c3e09f-0e58-4d28-8da1-37bb3fcf9435\" , \"deviceClassType\" : \"A\" } Class A devices The solution also support sending Cloud to device (C2D) messages to LoRa class A devices using standard IoT Hub SDKs . The message body should follow the following contract: The following tools can be used to send cloud to devices messages from Azure : Azure Portal \u2192 IoT Hub \u2192 Devices \u2192 message to device Azure IoT CLI Extension Visual Studio Code IoT Hub Extension In confirmed messages a ConfirmedDataDown message will be send to the LoRa device (as in picture above and below). You can enable additional message tracking options by setting the C2D message id to a value (C2D message ID is automatically populated with the Device Explorer tool used in the image below). As soon as the device acknowledges the message, it will report it in the logs and as a message property named 'C2DMsgConfirmed' on a message upstream (or generate an empty message in case of an empty ack message). The value of the message property will be set to the C2D message id that triggered the response if not null, otherwise to 'C2D Msg Confirmation'. You can find here below a set of picture illustrating the response when the C2D message id was sent to the value '4d3d0cd3-603a-4e00-a441-74aa55f53401'. Class C devices Using the SendCloudToDeviceMessage endpoint is the preferred way of sending messages to class C devices. However, it's also possible to use the standard IoT Hub SDK directly. To send downstream messages to class C devices using this method the following is required: The device twin desired property \"ClassType\": \"C\" must be set. The device must send at least one message upstream. Once the requirements are met, sending downstream messages is achieved by calling the direct method CloudToDeviceMessage in the module client. In Azure Portal: Azure Portal \u2192 IoT Hub \u2192 IoT Edge \u2192 LoRaWanNetworkSrvModule (under Modules) \u2192 Direct Method Visual Studio Code IoT Hub Extension The method name is CloudToDeviceMessage and the payload is the JSON following the structure previously described. Don't forget to set a value to the devEUI property. MAC Commands The Solution has an initial support for MAC Commands. Currently only the command Device Status is available. The command will return the device status (battery and communication margin). To try it, send a Cloud to Device message with the following format: { \"fport\" : 0 , \"macCommands\" : [ { \"cid\" : \"DevStatusCmd\" } ] }","title":"Quick Start"},{"location":"quickstart/#prerequisites","text":"The following should be completed before proceeding with the LoRaWAN starter kit development or deployment in your environment. You must have an Azure subscription. Get an Azure Free account to get started. We are based on Azure IoT Edge so it is important that you understand the concepts and deployment model for Azure IoT Edge. Refer to Azure IoT Edge documentation to see how it works. Understand how LoRa and LoRaWAN works. A great primer is available at the LoRa Alliance website . To test the solution on a device, you need to have a LoRaWAN Device Kit Gateway and a LoRa end node. We have some recommendations in the Tested Gateways section below. The template supports x86 and ARM architectures and will automatically deploy the correct version to your gateway. Make sure to provide your gateway's reset pin in the dialog before the deployment. However, your gateway might use a different SPI_DEV or SPI_SPEED, and the Basics Station module could not work out-of-the-box. To fix this, refer to the Basics Station Module Configuration page. The LoRa device demo code in the Arduino folder is built only for Seeduino LoRaWan board and was not test with other Arduino LoRa boards.","title":"Prerequisites"},{"location":"quickstart/#deployed-azure-infrastructure","text":"The template will deploy in your Azure subscription the Following resources: IoT Hub Azure Function Redis Cache Application Insights Log Analytics App Service (when opted in to use standalone discovery service )","title":"Deployed Azure Infrastructure"},{"location":"quickstart/#step-by-step-instructions","text":"Press on the button here below to start your Azure Deployment. You will get to a page asking you to fill the following fields : - Resource Group - A logical \"folder\" where all the template resource would be put into, just choose a meaningful name. - Location - In which DataCenter the resources should be deployed. Make sure to choose a location where IoT Hub is available - Unique Solution Prefix - A string that would be used as prefix for all the resources name to ensure their uniqueness. Hence, avoid any standard prefix such as \"lora\" as it might already be in use and might make your deployment fail. NB: the template is creating a Storage account with the value specified here, therefore the naming restrictions of Storage apply here. - Edge gateway name - the name of your LoRa Gateway node in the IoT Hub. - Deploy Device - Do you want demo end devices to be already provisioned (one using OTAA and one using ABP )? If yes set this to true, the code located in the Arduino folder would be ready to use immediately. - Reset pin - The reset pin of your gateway (the value should be 7 for the Seed Studio LoRaWam, 25 for the IC880A) - Region - In what region are you operating your device (currently only EU868 and US915 is supported) - Station Eui - The EUI of the Basics Station concentrator that will be used for connecting to LoRaWAN Network Server - Spi speed - (In Mbps) Custom SPI speed for your gateway, currently only supported for ARM gateways - Spi dev - A number identifying the SPI location where the board should be accessed (i.e.: when X, board accessed at /dev/spidevX.0) - Use Azure Monitor On Edge - You can opt out of using Azure Monitor services for observability on IoT Edge. - Use Discovery Service - You can opt in to use a standalone discovery service. This deploys an additional App Service (including a dedicated App Service Plan). Detailed information can be found LNS Discovery . The deployment would take c.a. 10 minutes to complete. During this time, you can proceed to install IoT Edge to your gateway . Once the Azure deployment is finished, connect your IoT Edge with the cloud as described in point 3 . You can get the connection string by clicking on the deployed IoT Hub -> IoT Edge Devices -> Connection string, as shown in the picture below. If your gateway is a Raspberry Pi, don't forget to enable SPI and to restart your Pi By using the docker ps command, you should see the Edge containers being deployed on your local gateway. You can now try one of the samples in the Arduino folder to see LoRa messages being sent to the cloud. If you have checked the Deploy Device checkbox you can use this sample directly \"TransmissionTestOTAALoRa.ino\" without provisioning the device first.","title":"Step-by-step instructions"},{"location":"quickstart/#what-does-the-template-do","text":"The template provision an IoT Hub with a LoRa Basics\u2122 Station and a network server module already pre-configured to work out of the box. As soon as you connect your IoT Edge device in point 4 above, those will be pushed on your device. You can find template definition and Edge deployment specification here . When setting the \"deployDevice\" argument to true, some LoRaWan devices will be ready to be used immediately, please consult the Arduino Samples Documentation to discover how to quickly use them for tests. If you are using the the RAK833-USB, you'll need to build a different LoRa Basics\u2122 Station image. You can find a fork of the official Basic Station repository with support for RAK833-USB here . If you are using a SX1302 (Corecell) board, you'll need to properly configure the built-in deployed module by having a look at the parameters in Basics\u2122 Station Module Configuration page.","title":"What does the template do?"},{"location":"quickstart/#using-a-proxy-server-to-connect-your-concentrator-to-azure","text":"This is an optional configuration that should only be executed if your concentrator needs to use a proxy server to communicate with Azure. Follow this guide to: Configure the Docker daemon and the IoT Edge daemon on your device to use a proxy server. Configure the edgeAgent properties in the config.yaml file on your device. Set environment variables for the IoT Edge runtime in the deployment manifest. Add the https_proxy environment variable to the LoRaWanNetworkSrvModule in IoT Hub.","title":"Using a Proxy Server to connect your Concentrator to Azure"},{"location":"quickstart/#lora-device-provisioning","text":"A LoRa device is a normal IoT Hub device with some specific device twin tags. You manage it like you would with any other IoT Hub device. To avoid caching issues you should not allow the device to join or send data before it is provisioned in IoT Hub. In case that you did please follow the ClearCache procedure that you find below.","title":"LoRa Device provisioning"},{"location":"quickstart/#abp-personalization-and-otaa-over-the-air-provisioning","text":"You can provision the devices manually in the Azure portal or better use the provided Command Line Interface Provisioning Tool to list , query , verify , add , update , and remove devices in IoT Hub. It is also recommended to use the CLI tool to verify manually added or edited LoRa devices in IoT Hub to ensure the device twin settings are all correct and will work. To manually provision: Login in to the Azure portal go to IoT Hub -> IoT devices -> Add Use the DeviceEUI as DeviceID -> Save Click on the newly created device Click on Device Twin menu Add the followings desired properties for OTAA : \"desired\" : { \"AppEUI\" : \"App EUI\" , \"AppKey\" : \"App Key\" , \"GatewayID\" : \"\" , \"SensorDecoder\" : \"\" }, Or the followings desired properties for ABP : DevAddr must be unique for every device! It is like an ip address for lora. \"desired\" : { \"AppSKey\" : \"Device AppSKey\" , \"NwkSKey\" : \"Device NwkSKey\" , \"DevAddr\" : \"Device Addr\" , \"SensorDecoder\" : \"\" , \"GatewayID\" : \"\" }, It should look something like this for ABP : { \"deviceId\" : \"BE7A00000000888F\" , \"etag\" : \"AAAAAAAAAAs=\" , \"deviceEtag\" : \"NzMzMTE3MTAz\" , \"status\" : \"enabled\" , \"statusUpdateTime\" : \"0001-01-01T00:00:00\" , \"connectionState\" : \"Disconnected\" , \"lastActivityTime\" : \"2018-08-06T15:16:32.0658492\" , \"cloudToDeviceMessageCount\" : 0 , \"authenticationType\" : \"sas\" , \"x509Thumbprint\" : { \"primaryThumbprint\" : null , \"secondaryThumbprint\" : null }, \"version\" : 324 , \"tags\" : { }, \"properties\" : { \"desired\" : { \"AppSKey\" : \"2B7E151628AED2A6ABF7158809CF4F3C\" , \"NwkSKey\" : \"1B6E151628AED2A6ABF7158809CF4F2C\" , \"DevAddr\" : \"0028B9B9\" , \"SensorDecoder\" : \"\" , \"GatewayID\" : \"\" , \"$metadata\" : { \"$lastUpdated\" : \"2018-03-28T06:12:46.1007943Z\" }, \"$version\" : 1 }, \"reported\" : { \"$metadata\" : { \"$lastUpdated\" : \"2018-08-06T15:16:32.2689851Z\" }, \"$version\" : 313 } } } Click Save Turn on the device and you are ready to go","title":"ABP (personalization) and OTAA (over the air) provisioning"},{"location":"quickstart/#optional-device-properties","text":"Customization's to lora devices are set by creating specific twin desired properties on the device. The following customization's are available: Name Description Configuration When to use Enable/disable downstream messages Allows disabling the downstream (cloud to device) for a device. By default downstream messages are enabled Add twin desired property \"Downlink\": false to disable downstream messages. The absence of the twin property or setting value to true will enable downlink messages. Disabling downlink on devices decreases message processing latency, since the network server will not look for cloud to device messages when an uplink is received. Only disable it in devices that are not expecting messages from cloud. Acknowledgement of confirmed upstream are sent to devices even when downlink is set to false Preferred receive window Allows setting the device preferred receive window (RX1 or RX2). The default preferred receive window is 1 Add twin desired property \"PreferredWindow\": 2 sets RX2 as preferred window. The absence of the twin property or setting the value to 1 will set RX1 as preferred window. Using the second receive window increases the chances that the end application can process the upstream message and send a cloud to device message to the lora device without requiring and additional upstream message. Basically completing the round trip in less than 2 seconds. Message Deduplication Allows controlling the handling of duplicate messages received by multiple gateways.The default is None. Add twin desired property \"Deduplication\": \"Drop\" to instruct dropping duplicate messages on the gateway, set it to \"Mark\" if you want to mark messages to the IotHub with \"dupmsg\": true in case the message was already processed. Example payload: Device: [47AAC86800430028], Data:[{\"time\":null,\"tmms\":0,\"tmst\":3201165987,\"freq\":868.3,\"chan\":1,\"rfch\":1,\"stat\":1,\"modu\":\"LORA\",\"datr\":\"SF7BW125\",\"codr\":\"4/5\",\"rssi\":-61,\"lsnr\":8.2,\"size\":14,\"data\":{\"value\":1},\"port\":10,\"fcnt\":2,\"rawdata\":\"QImRWQIAAgAK8I3rbqc=\",\"eui\":\"47AAC86800430028\",\"gatewayid\":\"simulatorpaschule1\",\"edgets\":1550501633879, \"dupmsg\": true }] Deduplication on the gateway allows you to control how you want to handle duplicate messages in a multi gateway environment without having to add additional logic on the receiving or processing end. RX1 Datarate Offset Allows setting an offset between received Datarate and retransmit datarate as specified in the LoRa Specifiations. Valid for OTAA devices. If an invalid value is provided the network server will use default value 0. Add twin desired property \"RX1DROffset\": # where # is a valid specification number to create an offset of # between received Datarate and Transmit Datarate. Please find the full table in the LoRa Specification example: upstream DR2, with a RX1DROffset of 1 will result in a transmission on DR1 Setting an offset between receive and transmit could help deal with very saturated network. Warning, this is an advanced option, please only use if you are aware of your network specification. RX2 Datarate Allows setting a custom Datarate for second receive windows. Valid for OTAA devices. If an invalid value is provided the network server will use default value 0 (DR0). Add twin desired property \"RX2DataRate\": # where # is a valid specification number to set the RX2 DR to DR#. Example: if a value of 2 is provided, second receive windows will use DR2 instead of the default DR0. Setting a custom RX2 Datarate could help your RX2 devices to benefit of higher datarate. Warning, this is an advanced topic, changing it to higher datarate could be very dangerous and result in RX2 becoming unusable if the devices are not within reach of the specified datarate. Usage of this feature is especially not recommanded if ADR is enabled. RX Delay Allows setting a custom wait time between receiving and transmission as specified in the specification. Add twin desired property \"RXDelay\": # where # is a valid specification number to set the RxDelay to wait for # seconds. Note that values 0 and 1 are default. Example: if a value of 2 is provided, The RX1 transmit windows will open 2 second after receiving the message. RX2 windows will always stay 1 second after RX1 Setting a custom RXDelay could be usefull in case of long processing time, this could give more time to the server/device to compute their answers and lower the risk of missing the transmission windows. The defaults should work in most production scenarios, we recommend to use the default unless you have an explicit need for a longer delay Disable ABP relax mode Allows to disable the relax mode when using ABP . By default relaxed mode is enabled Add twin desired property \"ABPRelaxMode\": false will disable relaxed mode. Disable the relaxed mode to minimize reply attack possiblitites. Allowing relaxed mode, allows a device to reset framecounters on the server by specifying 0/1. Important : in production deployments, we recommend turning relaxed mode off Specify frame counter up start value Allows to explicitly specify a frame counter up start value. If the device joins, this value will be used to validate the first frame and initialize the server state for the device. Add twin desired property \"FCntUpStart\": 10 will set the frame counter up to 10. If you disable ABP relax mode (see ABPRelaxMode) you usually want to set this value. In general, if your device starts with anything but 0 or 1, you specify the value here. If your device has relaxed mode disabled or uses 32 bit counters and got out of sync, this is a way to re-synchronize the counter between the server and the device. see 32bit counter support and reset counter Specify frame counter down start value Allows to explicitly specify a frame counter down start value. Add twin desired property \"FCntDownStart\": 10 will set the frame counter up to 10. If your device expects a frame counter down other than 1 in the first message, use this to configure the value 32bit counter support Allow the usage of 32bit counters on your device. Add twin desired property \"Supports32BitFCnt\": true will enable 32bit support for your device. Your device will keep a 32bit counter but only sends the lower 16bit over the wire. The server will infere the upper 16bit by looking at the traffic. The additional 2 bytes increase security and minimize the reply atack surface Reset counter Allows to reset the frame counters to the FCntUpStart/FCntDownStart values respectively. Add twin desired property \"FCntResetCounter\": 1 will use the values specified in \"FCntUpStart\" and \"FCntDownStart\" to set the framecounters to the desired values. The \"FCntResetCounter\" in the desired properties has to be higher than the value in the reported properties for this to take effect. If there is no value in the reporte properties yet, it will be applied and the reported properties get updated, as soon as the counters got updated. If your device got out of sync (missed frames larger than the specified MAX_FCNT_GAP in the specification (16384 as of this writing)), you can re-synchronize the counters using this reset mechanism. Device Connection Timeout Allows defining a sliding expiration to the connection between the leaf device and IoT/Edge Hub. The default is none, which causes the connection to not be dropped Add twin desired property \"KeepAliveTimeout\": 60 to add a 60 seconds sliding expiration. The minimum value is 60 seconds. Enabling device connection timeout allows a large device deployment to have a better usage of gateway resources by limiting open connections. We don't recommend enabling connection timeout in devices that send confirmed messages and/or expected cloud to device messages, as the reconnection time might prevent the network server from responding in time. Important : changes made to twin desired properties in devices that are already connected will only take effect once the network server is restarted or cache is cleared .","title":"Optional device properties"},{"location":"quickstart/#device-reported-properties","text":"This section provide a brief description of the device reported properties you can see appear on your device. Name Description Used By DataRate The Device Current Datarate This value will be only reported if you are using Adaptive Data Rate TxPower The Device Current Transmit Power This value will be only reported if you are using Adaptive Data Rate NbRep The Device Current repetition when transmitting. E.g. if set to two, the device will transmit twice his upstream messages This value will be only reported if you are using Adaptive Data Rate RX2DataRate The Device Current Rx2Datarate This value will be only reported if you set a Custom property as specified in the previous section. The two values might differ as a device value is currently updated only as part of the join process. RX1DROffset The Device Current RX1DROffset This value will be only reported if you set a Custom property as specified in the previous section. The two values might differ as a device value is currently updated only as part of the join process. RXDelay The Device Current RXDelay This value will be only reported if you set a Custom property as specified in the previous section. The two values might differ as a device value is currently updated only as part of the join process.","title":"Device Reported Properties"},{"location":"quickstart/#decoders","text":"The SensorDecoder tag is used to define which method will be used to decode the LoRa payload. If you leave it out or empty it will send the raw decrypted payload in the data field of the json message as Base64 encoded value to IoT Hub. If you want to decode it on the Edge you have the following two options: Specify a method that implements the right logic in the LoraDecoders class in the LoraDecoders.cs file of the LoRaWan.NetworkServer . Adapt the DecoderSample which allows you to create and run your own LoRa message decoder in an independent container running on your LoRa gateway without having to edit the main LoRa Engine. This description shows you how to get started. In both cases, we have already provided a simple decoder called \"DecoderValueSensor\" that takes the whole payload as a single numeric value and constructs the following json output as a response (The example of an Arduino sending a sensor value as string (i.e. \"23.5\") is available in the Arduino folder ): { ..... \"data\" : { \"value\" : 23.5 } ..... } If you want the raw decrypted payload to be sent to IoT Hub as Hex encoded value in the data field of the json message, you can set the decoder to \"DecoderHexSensor\" . The byte array {1, 2, 4, 8, 255} for example will be converted to \"01020408FF\" by this built-in decoder. { ..... \"data\" : { \"value\" : \"01020408FF\" } ..... } To add the sample \"DecoderValueSensor\" or \"DecoderHexSensor \" to the sample LoRa device configured above, change it's desired properties in IoT Hub as follows for option 1: \"desired\" : { \"AppEUI\" : \"App EUI\" , \"AppKey\" : \"App Key\" , \"GatewayID\" : \"\" , \"SensorDecoder\" : \"DecoderValueSensor\" }, or as follows for option 2: \"desired\" : { \"AppEUI\" : \"App EUI\" , \"AppKey\" : \"App Key\" , \"GatewayID\" : \"\" , \"SensorDecoder\" : \"http://your_container_name/api/DecoderValueSensor\" }, The \"DecoderValueSensor\" and \"DecoderHexSensor\" decoders are not a best practice but it makes it easier to experiment sending sensor readings to IoT Hub without having to change any code. if the SensorDecoder tag has a \"http\" in it's string value, it will forward the decoding call to an external decoder, as described in option 2 above, using standard Http. The call expects a return value with the same format as the json here above or an error string.","title":"Decoders"},{"location":"quickstart/#cache-clearing","text":"Due to the gateway caching the device information (tags) for 1 day, if the device tries to connect before you have provisioned it, it will not be able to connect because it will be considered a device for another LoRa network. To clear the cache and allow the device to connect follow these steps: IoT Hub -> IoT Edge -> click on the device ID of your gateway Click on LoRaWanNetworkSrvModule Click Direct Method Type \"ClearCache\" on Method Name Click Invoke Method Alternatively you can restart the Gateway or the LoRaWanNetworkSrvModule container.","title":"Cache Clearing"},{"location":"quickstart/#monitoring-and-logging","text":"There is a logging mechanism that outputs valuable information to the console of the docker container and can optionally forward these messages to IoT Hub. You can control logging with the following environment variables in the LoRaWanNetworkSrvModule IoT Edge module: Variable Value Explanation LOG_LEVEL \"1\" or \"Debug\" Everything is logged, including the up- and downstream messages to the basic station. \"2\" or \"Information\" Errors and information are logged. \"3\" or \"Error\" Only errors are logged. (default if omitted) For production environments, the LOG_LEVEL should be set to Error . Setting LOG_LEVEL to Debug causes a lot of messages to be generated. Make sure to set LOG_TO_HUB to false in this case. Variable Value Explanation LOG_TO_HUB true Log info are sent from the module to IoT Hub. false Log info is not sent to IoT Hub (default if omitted) You can use VSCode or Azure IoT CLI extension to monitor the log messages directly in IoT Hub if LOG_TO_HUB is set to true . Log in to the gateway and use sudo docker logs LoRaWanNetworkSrvModule -f to follow the logs if you are not logging to IoT Hub. Variable Value Explanation LOG_TO_CONSOLE true Log to docker logs (default if omitted) false Does not log to docker logs","title":"Monitoring and Logging"},{"location":"quickstart/#local-processing-and-routing","text":"By default the network server does not use the local edge queue (edgeHub), sending directly messages to IoT Hub. If you need to do local processing, please set the following setting to true on the LoRaWanNetworkSrvModule . Variable Value Explanation ENABLE_GATEWAY true Messages go to edgeHub and then to IoT Hub false Messages go directly to IoT Hub, skipping local edgeHub Queue","title":"Local Processing and Routing"},{"location":"quickstart/#lns-discovery","text":"When opted-in to use the LNS discovery service while also opting in to deploy the sample devices using the quickstart template, the LNS discovery service is automatically configured for you. You only need to adapt the hostAddress in the desired properties of the LNS module of your Edge device to point to the real IP/DNS of your gateway. If you did not opt-in to one of the abovementioned options when using the quickstart, refer to the LNS discovery guide for instructions on how to configure the LNS discovery service. Warning The LNS discovery service from the quickstart allows both HTTP and HTTPS per default. Make sure to change this if you only want to allow HTTPS.","title":"LNS Discovery"},{"location":"quickstart/#customize-the-solution-deep-dive","text":"Have a look at the LoRaEngine folder for more in details explanation.","title":"Customize the solution &amp; Deep dive"},{"location":"quickstart/#cloud-to-device-message","text":"Sending cloud to device messages in the solution uses the following JSON format to describe the downstream: { \"devEUI\" : \"string\" , \"fport\" : i nte ger , \"confirmed\" : boolea n , \"payload\" : \"string\" , \"rawPayload\" : \"string\" , \"macCommands\" :[ { \"cid\" : \"string\" } ] }","title":"Cloud to device message"},{"location":"quickstart/#fields","text":"Field Type Description Required devEUI String Device EUI Only when sending messages to class C devices fport Integer Payload fport, must be between 1 and 223 if you are sending data. 0 if it is Mac command Yes confirmed Boolean Indicates if an ack is required from the LoRa device. By default false No payload String Payload as text Either payload or rawPayload must be provided rawPayload String Payload as byte encoded in base64 format Either payload or rawPayload must be provided Mac command cid String Mac command identifier. The mac command DevStatusCmd is implemented, allowing you to request a device its status","title":"Fields"},{"location":"quickstart/#sending-messages-using-the-azure-function","text":"Sending messages to class A devices is a simple task, since those devices will send an upstream link giving the network server the chance of looking in Azure IoT Hub cloud to device message queue for pending downlink messages. Class C devices are more complex because they, for the most part, are only listening for messages. Using the cloud to device message queue would not be very effective as it would require the network server to keep a client connection that would rarely be used, wasting resources. In this solution sending messages to class C devices is available through a direct method in the network server. The Azure Function deployed with the solution can handle both class A and class C devices and, depending on the device type, sends the message via C2D message queue for class A or via direct method for class C devices. In a multiple gateway scenario there is still the need to resolve the closest gateway for a Class C device before calling the relevant network server via direct method. The gateway is resolved in the Azure Function by fetching the device twin and selecting the gateway ID from the twin properties. In order for this mechanism to work, the device first needs to send at least one upstream message so that the LNS can determine the gateway ID and save it in the device twin. In order to send a C2D message to a device using the Azure Function, the SendCloudToDeviceMessage endpoint should be used which takes away the complexity of figuring out the device type and closest gateway. The function endpoint looks like https://YOUR-FUNCTION-NAME.azurewebsites.net/api/cloudtodevicemessage/{devEUI}?code=YOUR-FUNCTION-APP-CODE To send a message to a device send a POST request including the content as the body: curl -d '{\"rawPayload\": \"AAA=\",\"fport\": 1}' -H \"Content-Type: application/json\" -H \"api-version: API-VERSION\" https://YOUR-FUNCTION-NAME.azurewebsites.net/api/cloudtodevicemessage/YOUR-DEVEUI?code = YOUR-FUNCTION-APP-CODE Should return { \"devEUI\" : \"47AAC86800430028\" , \"messageID\" : \"10c3e09f-0e58-4d28-8da1-37bb3fcf9435\" , \"deviceClassType\" : \"A\" }","title":"Sending messages using the Azure Function"},{"location":"quickstart/#class-a-devices","text":"The solution also support sending Cloud to device (C2D) messages to LoRa class A devices using standard IoT Hub SDKs . The message body should follow the following contract: The following tools can be used to send cloud to devices messages from Azure : Azure Portal \u2192 IoT Hub \u2192 Devices \u2192 message to device Azure IoT CLI Extension Visual Studio Code IoT Hub Extension In confirmed messages a ConfirmedDataDown message will be send to the LoRa device (as in picture above and below). You can enable additional message tracking options by setting the C2D message id to a value (C2D message ID is automatically populated with the Device Explorer tool used in the image below). As soon as the device acknowledges the message, it will report it in the logs and as a message property named 'C2DMsgConfirmed' on a message upstream (or generate an empty message in case of an empty ack message). The value of the message property will be set to the C2D message id that triggered the response if not null, otherwise to 'C2D Msg Confirmation'. You can find here below a set of picture illustrating the response when the C2D message id was sent to the value '4d3d0cd3-603a-4e00-a441-74aa55f53401'.","title":"Class A devices"},{"location":"quickstart/#class-c-devices","text":"Using the SendCloudToDeviceMessage endpoint is the preferred way of sending messages to class C devices. However, it's also possible to use the standard IoT Hub SDK directly. To send downstream messages to class C devices using this method the following is required: The device twin desired property \"ClassType\": \"C\" must be set. The device must send at least one message upstream. Once the requirements are met, sending downstream messages is achieved by calling the direct method CloudToDeviceMessage in the module client. In Azure Portal: Azure Portal \u2192 IoT Hub \u2192 IoT Edge \u2192 LoRaWanNetworkSrvModule (under Modules) \u2192 Direct Method Visual Studio Code IoT Hub Extension The method name is CloudToDeviceMessage and the payload is the JSON following the structure previously described. Don't forget to set a value to the devEUI property.","title":"Class C devices"},{"location":"quickstart/#mac-commands","text":"The Solution has an initial support for MAC Commands. Currently only the command Device Status is available. The command will return the device status (battery and communication margin). To try it, send a Cloud to Device message with the following format: { \"fport\" : 0 , \"macCommands\" : [ { \"cid\" : \"DevStatusCmd\" } ] }","title":"MAC Commands"},{"location":"release-notes/","text":"v2.2.1 New features Class B Beaconing support (#1906) AU915 frequency support (#1907) Release workflow (#1942) Bugfixes Fix EU868 concentrator twin documentation (#1919) Changed verbosity of the HTTP communication in logs (#1916) Misc From now on the ARM template and the LoRaWan device provisioning CLI will be provided in the Starterkit releases The infrastructure generation part has been fully updated to up-to-date services and product versions. Assets LoRaWaN Network Server image: loraedge/lorawannetworksrvmodule:2.2.1 BasicsStation Module image: loraedge/lorabasicsstationmodule:2.2.1 Azure Functions zip file can be downloaded from the release Discovery service zip file can be downloaded from the release LoRaWan CLI provision tool can be downloaded from the release Azure ARM template can be downloaded from the release v2.2.0 New features #1746 : Running LoRaWAN Network Server decoupled from IoT Edge #1780 : arm64v8 support #1807 , #1810 : AS923 Arduino examples and Documentation Breaking Changes #1794 : Application Insights is now requiring a connection string instead of instrumentation key. Make sure that, when updating to this version, the APPLICATIONINSIGHTS_CONNECTION_STRING is set instead of obsolete APPINSIGHTS_INSTRUMENTATIONKEY . More information on how to migrate from Application Insights instrumentation keys to connection strings on the official Azure documentation. Bugfixes #1711 : Remove unused DevEUI that breaks deserialization #1728 : Fix restart of the Basic Station Docker container #1729 : Don't use rx1droffset during join accept #1776 : Redis cache not properly updated because of IoT Hub query results delay Various additional fixes covered in v2.1.0 <-> v2.2.0 v2.1.0 New Features Increase scalability for multi-gateway scenarios . This eliminates several disadvantages in a multi-LNS deployment scenario . See ADR - 010. LNS sticky affinity over multiple sessions . Standalone discovery service for dynamic LNS discovery. See ADR - 009. LoRaWAN Network Server (LNS) discovery . LoRaBasicsStationModule updated to Basics Station v2.0.6: Support for SX1302 ( configurable via \"CORECELL\" parameter) Adjustable log level ( configurable via \"LOG_LEVEL\" parameter) Breaking Changes #1576 : The default deduplication strategy is now \"Drop\" instead of \"None\". More information found in the decision record . Quality Improvements #1573 : Handling ObjectDisposedException and other exceptions by recreating the DeviceClient . #1564 : Throttling disposal of DeviceClient s. #1540 : Observe unobserved tasks. #1462 : Tracing of AMQP/MQTT dependencies to IoT Hub in Application Insights. We enforce stricter naming conventions . We change the way we make HTTP requests to conform with how to make HTTP requests using IHttpClientFactory in ASP.NET Core . When using the quickstart template, we now deploy a Workspace-based Application Insights instance instead of a classic Application Insights. Bugfixes #1344 : Duplicate log statement. Fixing erroneous join request count metric . v2.0.0 New Features Support for LoRa Basics\u2122 Station LNS Protocol (v2.0.5) Support for LoRa Basics\u2122 Station CUPS Protocol (v2.0.5) for credential management and firmware upgrade LoRaWAN Network Server and Basics\u2122 Station can be decoupled, allowing the possibility to connect multiple concentrators on a single LoRaWAN Network Server instance Support for running LNS on a separate Edge or Cloud device Support for secure communication between LoRaWAN Network Server and Basics\u2122 Station Support for running LoRaWAN Network Server on Azure IoT Edge for Linux on Windows Regional support for AS923 and CN470 (Regional Parameters v1.0.3rA and RP002-1.0.3 revisions) Observability : Integration with Azure Monitor Exposing a Prometheus endpoint for metrics scraping Collection of metrics for edgeAgent and edgeHub modules with Metrics collector module Code Quality Improvements Introduction of LoRaWAN Primitives and refactoring of existing code to make wide use of those Upgrade to .NET 6 (LTS version) Upgrade container base images to Debian 11 Improvements in E2E CI, continuously testing multiple scenarios and authentication modes Breaking Changes Deprecated support for Packet Forwarder ( upgrade instructions ) Upgrade to RaspberryPi OS based on Debian 11.0 Bullseye ( upgrade instructions ) Infrastructure changes: New storage containers for CUPS credentials management and firmware upgrade (more in related ADRs ) A Log Analytics workspace is required for integrating with metrics collector (more in related ADRs ) Azure Functions runtime upgrade to v4 Bugfixes #249 At least one resource deployment operation failed #310 Incorrect data type for the tmms property v2.0.0-beta Breaking Changes when updating from v2.0.0-alpha Certificate Validation: In addition to validating the thumbprint, it also validates that the chain of trust is correct. See instructions here Previous Releases Release notes of all previous release can be found on the Release page on the repository: v1.0.7 v1.0.6 v1.0.5 v1.0.4 v1.0.3 v1.0.2 v1.0.1 v1.0.0 v0.4.0-preview","title":"Release Notes"},{"location":"release-notes/#v221","text":"","title":"v2.2.1"},{"location":"release-notes/#new-features","text":"Class B Beaconing support (#1906) AU915 frequency support (#1907) Release workflow (#1942)","title":"New features"},{"location":"release-notes/#bugfixes","text":"Fix EU868 concentrator twin documentation (#1919) Changed verbosity of the HTTP communication in logs (#1916)","title":"Bugfixes"},{"location":"release-notes/#misc","text":"From now on the ARM template and the LoRaWan device provisioning CLI will be provided in the Starterkit releases The infrastructure generation part has been fully updated to up-to-date services and product versions.","title":"Misc"},{"location":"release-notes/#assets","text":"LoRaWaN Network Server image: loraedge/lorawannetworksrvmodule:2.2.1 BasicsStation Module image: loraedge/lorabasicsstationmodule:2.2.1 Azure Functions zip file can be downloaded from the release Discovery service zip file can be downloaded from the release LoRaWan CLI provision tool can be downloaded from the release Azure ARM template can be downloaded from the release","title":"Assets"},{"location":"release-notes/#v220","text":"","title":"v2.2.0"},{"location":"release-notes/#new-features_1","text":"#1746 : Running LoRaWAN Network Server decoupled from IoT Edge #1780 : arm64v8 support #1807 , #1810 : AS923 Arduino examples and Documentation","title":"New features"},{"location":"release-notes/#breaking-changes","text":"#1794 : Application Insights is now requiring a connection string instead of instrumentation key. Make sure that, when updating to this version, the APPLICATIONINSIGHTS_CONNECTION_STRING is set instead of obsolete APPINSIGHTS_INSTRUMENTATIONKEY . More information on how to migrate from Application Insights instrumentation keys to connection strings on the official Azure documentation.","title":"Breaking Changes"},{"location":"release-notes/#bugfixes_1","text":"#1711 : Remove unused DevEUI that breaks deserialization #1728 : Fix restart of the Basic Station Docker container #1729 : Don't use rx1droffset during join accept #1776 : Redis cache not properly updated because of IoT Hub query results delay Various additional fixes covered in v2.1.0 <-> v2.2.0","title":"Bugfixes"},{"location":"release-notes/#v210","text":"","title":"v2.1.0"},{"location":"release-notes/#new-features_2","text":"Increase scalability for multi-gateway scenarios . This eliminates several disadvantages in a multi-LNS deployment scenario . See ADR - 010. LNS sticky affinity over multiple sessions . Standalone discovery service for dynamic LNS discovery. See ADR - 009. LoRaWAN Network Server (LNS) discovery . LoRaBasicsStationModule updated to Basics Station v2.0.6: Support for SX1302 ( configurable via \"CORECELL\" parameter) Adjustable log level ( configurable via \"LOG_LEVEL\" parameter)","title":"New Features"},{"location":"release-notes/#breaking-changes_1","text":"#1576 : The default deduplication strategy is now \"Drop\" instead of \"None\". More information found in the decision record .","title":"Breaking Changes"},{"location":"release-notes/#quality-improvements","text":"#1573 : Handling ObjectDisposedException and other exceptions by recreating the DeviceClient . #1564 : Throttling disposal of DeviceClient s. #1540 : Observe unobserved tasks. #1462 : Tracing of AMQP/MQTT dependencies to IoT Hub in Application Insights. We enforce stricter naming conventions . We change the way we make HTTP requests to conform with how to make HTTP requests using IHttpClientFactory in ASP.NET Core . When using the quickstart template, we now deploy a Workspace-based Application Insights instance instead of a classic Application Insights.","title":"Quality Improvements"},{"location":"release-notes/#bugfixes_2","text":"#1344 : Duplicate log statement. Fixing erroneous join request count metric .","title":"Bugfixes"},{"location":"release-notes/#v200","text":"","title":"v2.0.0"},{"location":"release-notes/#new-features_3","text":"Support for LoRa Basics\u2122 Station LNS Protocol (v2.0.5) Support for LoRa Basics\u2122 Station CUPS Protocol (v2.0.5) for credential management and firmware upgrade LoRaWAN Network Server and Basics\u2122 Station can be decoupled, allowing the possibility to connect multiple concentrators on a single LoRaWAN Network Server instance Support for running LNS on a separate Edge or Cloud device Support for secure communication between LoRaWAN Network Server and Basics\u2122 Station Support for running LoRaWAN Network Server on Azure IoT Edge for Linux on Windows Regional support for AS923 and CN470 (Regional Parameters v1.0.3rA and RP002-1.0.3 revisions) Observability : Integration with Azure Monitor Exposing a Prometheus endpoint for metrics scraping Collection of metrics for edgeAgent and edgeHub modules with Metrics collector module","title":"New Features"},{"location":"release-notes/#code-quality-improvements","text":"Introduction of LoRaWAN Primitives and refactoring of existing code to make wide use of those Upgrade to .NET 6 (LTS version) Upgrade container base images to Debian 11 Improvements in E2E CI, continuously testing multiple scenarios and authentication modes","title":"Code Quality Improvements"},{"location":"release-notes/#breaking-changes_2","text":"Deprecated support for Packet Forwarder ( upgrade instructions ) Upgrade to RaspberryPi OS based on Debian 11.0 Bullseye ( upgrade instructions ) Infrastructure changes: New storage containers for CUPS credentials management and firmware upgrade (more in related ADRs ) A Log Analytics workspace is required for integrating with metrics collector (more in related ADRs ) Azure Functions runtime upgrade to v4","title":"Breaking Changes"},{"location":"release-notes/#bugfixes_3","text":"#249 At least one resource deployment operation failed #310 Incorrect data type for the tmms property","title":"Bugfixes"},{"location":"release-notes/#v200-beta","text":"","title":"v2.0.0-beta"},{"location":"release-notes/#breaking-changes_3","text":"when updating from v2.0.0-alpha Certificate Validation: In addition to validating the thumbprint, it also validates that the chain of trust is correct. See instructions here","title":"Breaking Changes"},{"location":"release-notes/#previous-releases","text":"Release notes of all previous release can be found on the Release page on the repository: v1.0.7 v1.0.6 v1.0.5 v1.0.4 v1.0.3 v1.0.2 v1.0.1 v1.0.0 v0.4.0-preview","title":"Previous Releases"},{"location":"support/","text":"Support The LoRaWAN starter kit is an open source solution, it is NOT a Microsoft supported solution or product. For bugs and issues with the codebase please log an issue in the GitHub repository .","title":"Support"},{"location":"support/#support","text":"The LoRaWAN starter kit is an open source solution, it is NOT a Microsoft supported solution or product. For bugs and issues with the codebase please log an issue in the GitHub repository .","title":"Support"},{"location":"adr/001_region_cn470_implementation/","text":"001. Region CN470 implementation Epic : #416 Authors : Maggie Salak, Mikhail Chatillon Status : Accepted Overview / Problem Statement The specification of region CN470 has significant differences compared to regions already supported by the Starter Kit. Specifically, there are 4 different frequency channel plans involved and calculation of downstream frequencies requires knowing which channel plan has been activated for a given device during join or device provisioning: Plan A for 20 MHz antennas Plan B for 20 MHz antennas Plan A for 26 MHz antennas Plan B for 26 MHz antennas This document summarizes decisions taken for the purpose of implementing support for region CN470. In-Scope Support for OTAA and ABP devices Correct handling of join requests Calculation of downstream frequencies and data rates Calculation of RX2 default frequency Out-of-scope MAC commands - support for MAC commands will be added later on Choices OTAA join channel is needed to determine which channel plan should be activated for a given device and used when calculating downstream frequency. We plan to save the join channel index in the device twin inside reported properties in IoT Hub. The property would be named CN470JoinChannel and the value would be an int in range 0 - 19, corresponding to the 20 possible join channels. According to the specification , multiple join channels map to the same channel plan, e.g. join channels 0 - 7 are all mapped to Plan A for 20 MHz devices, where each of them has a different frequency. In total there are 20 possible join channels mapped to 4 channel plans as described in Overview. The join channel is also needed for computing the RX2 default frequency. In this case the join channel index directly determines the correct RX2 default frequency. In case of ABP devices the channel plan will need to be provisioned on the IoT Hub by the operator in the desired properties of the device twin, since there is no device join in this scenario. For simplicity of the implementation, the channel plan will be stored in the same way as in case of OTAA devices; it would be saved as a join channel index (named CN470JoinChannel as in case of OTAA) using the following table for determining the correct value: Channel plan CN470JoinChannel 20 MHz Plan A 0 20 MHz Plan B 8 26 MHz Plan A 10 26 MHz Plan B 15 Since there are no join channels in case of ABP devices, we will define a convention as to which channel index should be used for each channel plan. The suggested way would be to use the lowest index for each of the 4 channel plans, as in the table above. In the implementation of the region, we will first check if a join channel is set in the reported properties and, if not, we will retrieve it from desired properties. This will also give us the information whether a given device is an OTAA or ABP device.This is needed when calculating the RX2 default frequency. In case of OTAA devices we need to calculated it using the join channel index but in case of ABP it's a constant value.","title":"001. Region CN470 implementation"},{"location":"adr/001_region_cn470_implementation/#001-region-cn470-implementation","text":"Epic : #416 Authors : Maggie Salak, Mikhail Chatillon Status : Accepted","title":"001. Region CN470 implementation"},{"location":"adr/001_region_cn470_implementation/#overview-problem-statement","text":"The specification of region CN470 has significant differences compared to regions already supported by the Starter Kit. Specifically, there are 4 different frequency channel plans involved and calculation of downstream frequencies requires knowing which channel plan has been activated for a given device during join or device provisioning: Plan A for 20 MHz antennas Plan B for 20 MHz antennas Plan A for 26 MHz antennas Plan B for 26 MHz antennas This document summarizes decisions taken for the purpose of implementing support for region CN470.","title":"Overview / Problem Statement"},{"location":"adr/001_region_cn470_implementation/#in-scope","text":"Support for OTAA and ABP devices Correct handling of join requests Calculation of downstream frequencies and data rates Calculation of RX2 default frequency","title":"In-Scope"},{"location":"adr/001_region_cn470_implementation/#out-of-scope","text":"MAC commands - support for MAC commands will be added later on","title":"Out-of-scope"},{"location":"adr/001_region_cn470_implementation/#choices","text":"OTAA join channel is needed to determine which channel plan should be activated for a given device and used when calculating downstream frequency. We plan to save the join channel index in the device twin inside reported properties in IoT Hub. The property would be named CN470JoinChannel and the value would be an int in range 0 - 19, corresponding to the 20 possible join channels. According to the specification , multiple join channels map to the same channel plan, e.g. join channels 0 - 7 are all mapped to Plan A for 20 MHz devices, where each of them has a different frequency. In total there are 20 possible join channels mapped to 4 channel plans as described in Overview. The join channel is also needed for computing the RX2 default frequency. In this case the join channel index directly determines the correct RX2 default frequency. In case of ABP devices the channel plan will need to be provisioned on the IoT Hub by the operator in the desired properties of the device twin, since there is no device join in this scenario. For simplicity of the implementation, the channel plan will be stored in the same way as in case of OTAA devices; it would be saved as a join channel index (named CN470JoinChannel as in case of OTAA) using the following table for determining the correct value: Channel plan CN470JoinChannel 20 MHz Plan A 0 20 MHz Plan B 8 26 MHz Plan A 10 26 MHz Plan B 15 Since there are no join channels in case of ABP devices, we will define a convention as to which channel index should be used for each channel plan. The suggested way would be to use the lowest index for each of the 4 channel plans, as in the table above. In the implementation of the region, we will first check if a join channel is set in the reported properties and, if not, we will retrieve it from desired properties. This will also give us the information whether a given device is an OTAA or ABP device.This is needed when calculating the RX2 default frequency. In case of OTAA devices we need to calculated it using the join channel index but in case of ABP it's a constant value.","title":"Choices"},{"location":"adr/002_lbs_configuration/","text":"002. LoRa Basic Station configuration endpoint implementation Epic : #388 Authors : Bastian Burger, Spyros Giannakakis Status : Accepted Overview / Problem Statement The LNS protocol specifies an endpoint that the LoRa Basic Station (LBS) invokes an endpoint on the LNS to load its configuration. After a successful configuration exchange, the LBS/LNS start to operate normally. From the protocol specification Right after the WebSocket connection has been established, the Station sends a version message. Next, the LNS shall respond with a router_config message. Afterwards, normal operation begins with uplink/downlink messages as described below. As part of this ADR we describe how the LNS can provide the LBS with the necessary configuration. We analyze different strategies with respect to their implementation simplicity, deployment simplicity and how to detect updates to the configuration. Restrictions / limitations Twins have a limit of 32KB for desired properties. Children devices can only have one parent and a parent can have up to 100 children devices. Possible solutions Option 1: Mount volume on LNS with the LBS configuration Since the LNS runs as an IoT edge module, we can use IoT Edge device local storage from a module . We would store the configuration of all LBSs in the file system of the LNS. Advantages : Implementation effort is low. No limitation in terms of how many LBSs can connect to an LNS. Disadvantages : An additional configuration mechanism besides the IoT Hub is introduced to the system. This would complicate the provisioning flow and potentially require the involvement of a separate infra team. Deployment of updated configuration is not straightforward, since for configuration updates we need access to the file system of where the LNS is hosted. To check if the configuration changed, we would also need to query the configuration file(s) periodically to detect changes and apply updates. Option 2: Hold LBS configurations in the LNS module twin Adding the configuration to the module twin of the LNS would make it possible to update the LBS configuration (e.g. adding new gateways, changing existing values) by adapting the module twin of the LNS. Since device twins have a 32kb size limit for desired properties , this means that we will have an effective limitation in terms of how many LBS we can connect to a single LNS. The device twin documentation states the following about the encoding of the twin desired properties: Property key is encoded as UTF-8-encoded string (usually one character takes 8 bytes) Boolean value takes 4 bytes Numeric value takes 8 bytes Nested object size is based on their content Taking as an example the configuration message from PR 569 , we are able to add 37 times the following LBS configuration to the device twins desired properties until we get an error: { \"msgtype\" : \"router_config\" , \"NetID\" :[ 1 ], \"JoinEui\" :[ \"9223372036854775807\" , \"9223372036854775807\" ], \"region\" : \"EU863\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" :[ 863000000 , 870000000 ], \"DRs\" :[[ 11 , 125 , 0 ],[ 10 , 125 , 0 ],[ 9 , 125 , 0 ],[ 8 , 125 , 0 ],[ 7 , 125 , 0 ],[ 7 , 250 , 0 ]], \"sx1301_conf\" :[{ \"radio_0\" :{ \"enable\" : true , \"freq\" : 867500000 }, \"radio_1\" :{ \"enable\" : true , \"freq\" : 868500000 }, \"chan_FSK\" :{ \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" :{ \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" :{ \"enable\" : true , \"radio\" : 1 , \"if\" : -400000 }, \"chan_multiSF_1\" :{ \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 }, \"chan_multiSF_2\" :{ \"enable\" : true , \"radio\" : 1 , \"if\" : 0 }, \"chan_multiSF_3\" :{ \"enable\" : true , \"radio\" : 0 , \"if\" : -400000 }, \"chan_multiSF_4\" :{ \"enable\" : true , \"radio\" : 0 , \"if\" : -200000 }, \"chan_multiSF_5\" :{ \"enable\" : true , \"radio\" : 0 , \"if\" : 0 }, \"chan_multiSF_6\" :{ \"enable\" : true , \"radio\" : 0 , \"if\" : 200000 }, \"chan_multiSF_7\" :{ \"enable\" : true , \"radio\" : 0 , \"if\" : 400000 }}], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } Assuming that we do not choose a different representation (e.g. compression, sharing of duplicated parts of the document) we can safely guarantee that we support 30 gateways per network server with this approach. NB : In case the specification requires us to transfer 64-bit numbers (e.g. for EUIs), we either need to split up such a number into two 32-bit numbers or represent it as a string. Device twins encode numbers as 32-bit values. Advantages : We can fetch the LBS configuration needing to have access to the contentrator device key (as in Option 3). No need to create additional IoT devices for each LBS. Configuration of all LBSs is centralized in one place which would make it easier to find. Disadvantages : The centralization of configuration complicates the changes needed to connect to other or multiple LNSs (for dynamic discovery or resiliency purposes) The limit of ~30 LBSs per LNS is considered enough for now (initially we considered 4-5 LBSs per LNS) but could be limiting in the future especially if the twins grow. Workarounds can be considered e.g. use this space only for non-default LBSs or potentially compress. Option 3: Track each LBS as separate IoT Hub device In this option, we create IoT Hub devices (not edge-enabled) for every LBS. The configuration of LBS is held in the device twin. Open question : Do we allow an LNS to get info for any LBS or only for the ones that are connected to it? LNS uses the Azure Function to retrieve the device key LBS requests its configuration passing its device id. LNS invokes the existing Azure Function to get the Device key passing the LBS id. The Function returns the Device Key (via a cache or by querying IoT Hub). LNS uses the Device Key to impersonate LBS, get its twin that holds the configuration (optionally: listens to future updates to it by DeviceClient.SetDesiredPropertyUpdateCallbackAsync ). Notes: Code changes are not extensive, as most of the code change is already there Advantages : LBSs are self-contained and therefore can be moved more easily for example to a different LNS (discovery phase) or connect to more than one LNS (resiliency). Disadvantages : We would need to provision and manage IoT devices for LBSs. More complex LNS flow since it involves the Function. Possible delay, though there is no timeout window within which we need to respond. Multiple open connections are required for each LBS. Alternative 1: utilize the child-parent feature to avoid invoking additional Azure services By establishing a child-parent relationship between LBSs and LNS, messages from and to LBS are passed transparently through the LNS. The idea here would be that LNS as the parent, has access to the LBS device twin without the need to use the LBS device key. Reason for disqualifying: There seems that there is no API in either the DeviceClient nor the ModuleClient to retrieve the device twin of a child without having the device key. Alternative 2: edge-enabled LBS sends upstream its twin to LNS If LBS was an IoT Edge enabled device, we could utilize ModuleClient.SetDesiredPropertyUpdateCallbackAsync to send upstream to its parent the updated module twin. LNS could filter messages coming from downstream/child devices based on whether they contain a module id or not to get a hold of this configuration. Reason for disqualifying: Given that LBS needs to run on low powered devices, we can not change them to IoT Edge enabled devices. Decision Based on this investigation and the team discussion, Option 3 was chosen due to the flexibility it offers in terms of use-cases (resiliency, dynamic discovery) as well as scaling options. The additional complexity is deemed reasonable given the additional future-proofness.","title":"002. LoRa Basic Station configuration endpoint implementation"},{"location":"adr/002_lbs_configuration/#002-lora-basic-station-configuration-endpoint-implementation","text":"Epic : #388 Authors : Bastian Burger, Spyros Giannakakis Status : Accepted","title":"002. LoRa Basic Station configuration endpoint implementation"},{"location":"adr/002_lbs_configuration/#overview-problem-statement","text":"The LNS protocol specifies an endpoint that the LoRa Basic Station (LBS) invokes an endpoint on the LNS to load its configuration. After a successful configuration exchange, the LBS/LNS start to operate normally. From the protocol specification Right after the WebSocket connection has been established, the Station sends a version message. Next, the LNS shall respond with a router_config message. Afterwards, normal operation begins with uplink/downlink messages as described below. As part of this ADR we describe how the LNS can provide the LBS with the necessary configuration. We analyze different strategies with respect to their implementation simplicity, deployment simplicity and how to detect updates to the configuration.","title":"Overview / Problem Statement"},{"location":"adr/002_lbs_configuration/#restrictions-limitations","text":"Twins have a limit of 32KB for desired properties. Children devices can only have one parent and a parent can have up to 100 children devices.","title":"Restrictions / limitations"},{"location":"adr/002_lbs_configuration/#possible-solutions","text":"","title":"Possible solutions"},{"location":"adr/002_lbs_configuration/#option-1-mount-volume-on-lns-with-the-lbs-configuration","text":"Since the LNS runs as an IoT edge module, we can use IoT Edge device local storage from a module . We would store the configuration of all LBSs in the file system of the LNS. Advantages : Implementation effort is low. No limitation in terms of how many LBSs can connect to an LNS. Disadvantages : An additional configuration mechanism besides the IoT Hub is introduced to the system. This would complicate the provisioning flow and potentially require the involvement of a separate infra team. Deployment of updated configuration is not straightforward, since for configuration updates we need access to the file system of where the LNS is hosted. To check if the configuration changed, we would also need to query the configuration file(s) periodically to detect changes and apply updates.","title":"Option 1: Mount volume on LNS with the LBS configuration"},{"location":"adr/002_lbs_configuration/#option-2-hold-lbs-configurations-in-the-lns-module-twin","text":"Adding the configuration to the module twin of the LNS would make it possible to update the LBS configuration (e.g. adding new gateways, changing existing values) by adapting the module twin of the LNS. Since device twins have a 32kb size limit for desired properties , this means that we will have an effective limitation in terms of how many LBS we can connect to a single LNS. The device twin documentation states the following about the encoding of the twin desired properties: Property key is encoded as UTF-8-encoded string (usually one character takes 8 bytes) Boolean value takes 4 bytes Numeric value takes 8 bytes Nested object size is based on their content Taking as an example the configuration message from PR 569 , we are able to add 37 times the following LBS configuration to the device twins desired properties until we get an error: { \"msgtype\" : \"router_config\" , \"NetID\" :[ 1 ], \"JoinEui\" :[ \"9223372036854775807\" , \"9223372036854775807\" ], \"region\" : \"EU863\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" :[ 863000000 , 870000000 ], \"DRs\" :[[ 11 , 125 , 0 ],[ 10 , 125 , 0 ],[ 9 , 125 , 0 ],[ 8 , 125 , 0 ],[ 7 , 125 , 0 ],[ 7 , 250 , 0 ]], \"sx1301_conf\" :[{ \"radio_0\" :{ \"enable\" : true , \"freq\" : 867500000 }, \"radio_1\" :{ \"enable\" : true , \"freq\" : 868500000 }, \"chan_FSK\" :{ \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" :{ \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" :{ \"enable\" : true , \"radio\" : 1 , \"if\" : -400000 }, \"chan_multiSF_1\" :{ \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 }, \"chan_multiSF_2\" :{ \"enable\" : true , \"radio\" : 1 , \"if\" : 0 }, \"chan_multiSF_3\" :{ \"enable\" : true , \"radio\" : 0 , \"if\" : -400000 }, \"chan_multiSF_4\" :{ \"enable\" : true , \"radio\" : 0 , \"if\" : -200000 }, \"chan_multiSF_5\" :{ \"enable\" : true , \"radio\" : 0 , \"if\" : 0 }, \"chan_multiSF_6\" :{ \"enable\" : true , \"radio\" : 0 , \"if\" : 200000 }, \"chan_multiSF_7\" :{ \"enable\" : true , \"radio\" : 0 , \"if\" : 400000 }}], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } Assuming that we do not choose a different representation (e.g. compression, sharing of duplicated parts of the document) we can safely guarantee that we support 30 gateways per network server with this approach. NB : In case the specification requires us to transfer 64-bit numbers (e.g. for EUIs), we either need to split up such a number into two 32-bit numbers or represent it as a string. Device twins encode numbers as 32-bit values. Advantages : We can fetch the LBS configuration needing to have access to the contentrator device key (as in Option 3). No need to create additional IoT devices for each LBS. Configuration of all LBSs is centralized in one place which would make it easier to find. Disadvantages : The centralization of configuration complicates the changes needed to connect to other or multiple LNSs (for dynamic discovery or resiliency purposes) The limit of ~30 LBSs per LNS is considered enough for now (initially we considered 4-5 LBSs per LNS) but could be limiting in the future especially if the twins grow. Workarounds can be considered e.g. use this space only for non-default LBSs or potentially compress.","title":"Option 2: Hold LBS configurations in the LNS module twin"},{"location":"adr/002_lbs_configuration/#option-3-track-each-lbs-as-separate-iot-hub-device","text":"In this option, we create IoT Hub devices (not edge-enabled) for every LBS. The configuration of LBS is held in the device twin. Open question : Do we allow an LNS to get info for any LBS or only for the ones that are connected to it?","title":"Option 3: Track each LBS as separate IoT Hub device"},{"location":"adr/002_lbs_configuration/#lns-uses-the-azure-function-to-retrieve-the-device-key","text":"LBS requests its configuration passing its device id. LNS invokes the existing Azure Function to get the Device key passing the LBS id. The Function returns the Device Key (via a cache or by querying IoT Hub). LNS uses the Device Key to impersonate LBS, get its twin that holds the configuration (optionally: listens to future updates to it by DeviceClient.SetDesiredPropertyUpdateCallbackAsync ). Notes: Code changes are not extensive, as most of the code change is already there Advantages : LBSs are self-contained and therefore can be moved more easily for example to a different LNS (discovery phase) or connect to more than one LNS (resiliency). Disadvantages : We would need to provision and manage IoT devices for LBSs. More complex LNS flow since it involves the Function. Possible delay, though there is no timeout window within which we need to respond. Multiple open connections are required for each LBS.","title":"LNS uses the Azure Function to retrieve the device key"},{"location":"adr/002_lbs_configuration/#alternative-1-utilize-the-child-parent-feature-to-avoid-invoking-additional-azure-services","text":"By establishing a child-parent relationship between LBSs and LNS, messages from and to LBS are passed transparently through the LNS. The idea here would be that LNS as the parent, has access to the LBS device twin without the need to use the LBS device key. Reason for disqualifying: There seems that there is no API in either the DeviceClient nor the ModuleClient to retrieve the device twin of a child without having the device key.","title":"Alternative 1: utilize the child-parent feature to avoid invoking additional Azure services"},{"location":"adr/002_lbs_configuration/#alternative-2-edge-enabled-lbs-sends-upstream-its-twin-to-lns","text":"If LBS was an IoT Edge enabled device, we could utilize ModuleClient.SetDesiredPropertyUpdateCallbackAsync to send upstream to its parent the updated module twin. LNS could filter messages coming from downstream/child devices based on whether they contain a module id or not to get a hold of this configuration. Reason for disqualifying: Given that LBS needs to run on low powered devices, we can not change them to IoT Edge enabled devices.","title":"Alternative 2: edge-enabled LBS sends upstream its twin to LNS"},{"location":"adr/002_lbs_configuration/#decision","text":"Based on this investigation and the team discussion, Option 3 was chosen due to the flexibility it offers in terms of use-cases (resiliency, dynamic discovery) as well as scaling options. The additional complexity is deemed reasonable given the additional future-proofness.","title":"Decision"},{"location":"adr/003_documentation/","text":"003. Documentation Feature : #700 Authors : Roel Fauconnier Status : Accepted Overview / Problem Statement Currently the documentation is not very well structured, and content is hard to discover. There is no search except for the built-in GitHub code search. Some of the documentation is spread out across different files. We want to bring the documentation up-to-date and make it more discoverable. Proposed solution Use GitHub Pages . GitHub has a \"Pages\" functionality which allows you to publish a static website to a predefined URL: https://projectname.github.io . It can be published from a branch and/or folder. The folders are limited to / or /docs . The best practice seems to be to create a detached branch or git subtree called gh-pages which contains only the static website in a /docs folder. Use DocFX static site generator . DocFX is an open source tool provided by Microsoft that allows you to generate a static website based on a set of markdown files. Additionally, it can build documentation for a codebase based on the \"triple slash\" comments ( /// ) in .NET code. It uses yaml files to provide structure to the documentation. There is no built-in support in GitHub, but there are already some GitHub Actions available to help automate the publishing of docs. However, we will not use the code documentation feature of DocFX, since the code does not represent an API. Create a detached branch to keep all docs , called docs/main . This keeps history out of the main code repository, and allows for changes to the documentation without triggering any tag, version or CI. Create a detached branch to keep static site , called gh-pages . This allows for a place where the docs can be published from. Versioning : the tool mike is used for managing the versions. Two different workflows will manage the deployment: CI for each push to docs/main will automatically deploy version called dev Manual workflow with parameter for version will deploy that version, set it to latest and additionally tag the repo with docs@<version> Open Questions [x] Can multiple branches be locked in GitHub? E.g. ideally docs/main will be locked and can only be updated through a PR. YES - it is possible to add rules to different branches. Alternatives Considered Structurize the current folders Bring more structure to the current documentation folders, and use GitHub \"markdown-preview\" feature. The docs can be searched via GitHub search function. This also means adding additional links from each document to other documents to make things more discoverable. Use Jekyll static site generator Jekyll is the default option that Github provides to generate a static website. There are Github Actions available to help you build and publish the static website. Jekyll requires you to add specific yaml snippets to your documentation to be able to build a static site. Also, it is not fully supported on Windows right now . Use a different repository for the docs While this is a solution for some OSS repositories, it is overkill for this one. Additionally, it may be hard to open a new repository within the Azure organization. here is a code sample example code 1 2 3 4 5 6 7 namespace hello { public class world { public world (){ } } }","title":"003. Documentation"},{"location":"adr/003_documentation/#003-documentation","text":"Feature : #700 Authors : Roel Fauconnier Status : Accepted","title":"003. Documentation"},{"location":"adr/003_documentation/#overview-problem-statement","text":"Currently the documentation is not very well structured, and content is hard to discover. There is no search except for the built-in GitHub code search. Some of the documentation is spread out across different files. We want to bring the documentation up-to-date and make it more discoverable.","title":"Overview / Problem Statement"},{"location":"adr/003_documentation/#proposed-solution","text":"Use GitHub Pages . GitHub has a \"Pages\" functionality which allows you to publish a static website to a predefined URL: https://projectname.github.io . It can be published from a branch and/or folder. The folders are limited to / or /docs . The best practice seems to be to create a detached branch or git subtree called gh-pages which contains only the static website in a /docs folder. Use DocFX static site generator . DocFX is an open source tool provided by Microsoft that allows you to generate a static website based on a set of markdown files. Additionally, it can build documentation for a codebase based on the \"triple slash\" comments ( /// ) in .NET code. It uses yaml files to provide structure to the documentation. There is no built-in support in GitHub, but there are already some GitHub Actions available to help automate the publishing of docs. However, we will not use the code documentation feature of DocFX, since the code does not represent an API. Create a detached branch to keep all docs , called docs/main . This keeps history out of the main code repository, and allows for changes to the documentation without triggering any tag, version or CI. Create a detached branch to keep static site , called gh-pages . This allows for a place where the docs can be published from. Versioning : the tool mike is used for managing the versions. Two different workflows will manage the deployment: CI for each push to docs/main will automatically deploy version called dev Manual workflow with parameter for version will deploy that version, set it to latest and additionally tag the repo with docs@<version>","title":"Proposed solution"},{"location":"adr/003_documentation/#open-questions","text":"[x] Can multiple branches be locked in GitHub? E.g. ideally docs/main will be locked and can only be updated through a PR. YES - it is possible to add rules to different branches.","title":"Open Questions"},{"location":"adr/003_documentation/#alternatives-considered","text":"Structurize the current folders Bring more structure to the current documentation folders, and use GitHub \"markdown-preview\" feature. The docs can be searched via GitHub search function. This also means adding additional links from each document to other documents to make things more discoverable. Use Jekyll static site generator Jekyll is the default option that Github provides to generate a static website. There are Github Actions available to help you build and publish the static website. Jekyll requires you to add specific yaml snippets to your documentation to be able to build a static site. Also, it is not fully supported on Windows right now . Use a different repository for the docs While this is a solution for some OSS repositories, it is overkill for this one. Additionally, it may be hard to open a new repository within the Azure organization. here is a code sample example code 1 2 3 4 5 6 7 namespace hello { public class world { public world (){ } } }","title":"Alternatives Considered"},{"location":"adr/004_region_as923_implementation/","text":"004. Region AS923 implementation Epic : #412 Authors : Maggie Salak, Bastian Burger Status : Accepted Overview / Problem Statement The specification of region AS923 defines a AS923_FREQ_OFFSET parameter which is used to accommodate different country-specific sub-bands across the 915 - 928 MHz band. The parameter can have one of four different values depending on a country. The corresponding frequency offset in Hz is AS923_FREQ_OFFSET_HZ = 100 x AS923_FREQ_OFFSET . The value of the parameter is needed for the purpose of calculating RX2 window frequencies for AS923 region. The parameter is not required for calculating RX1 receive window as it simply uses the same channel as the preceding uplink. In addition to sub-bands and frequency offsets, the regional parameter specification describes noteworthy behavior with respect to dwell times. The dwell time describes the time needed to transmit a LoRaWAN message, typically restrictions limit the dwell time to be not longer than 400ms. For the AS923 region, the specification says that dwell time limitations may apply to some locations in the AS923 region depending on local regulations. We are not able to get a comprehensive list of which locations use which regulations. To ensure conformity with these limitations, each gateway can configure an end device using TxParamSetupReq/Ans MAC commands. A typical flow may look like this: End device sends join request using DR2 - DR5 (which always complies with potential dwell time limitations of 400ms) The actual dwell time limitations are communicated by the gateway to the device using a downstream TxParamSetupReq MAC Command End device sends TxParamSetupAns MAC Command with empty payload as acknowledgement Both end device and gateway adhere to the limitations from there on With the LoRaWAN specification 1.0.3, the TxParamSetupReq/Ans MAC Command exchange is subject to a bug if the TxParamSetupAns is lost , which leaves the end devices unable to receive downlink messages. The bug will only be fixed in LoRaWAN specification version 1.0.4. This document summarizes decisions taken for the purpose of implementing support for region AS923. In-Scope Support for all countries using frequency plan AS923 Calculation of RX1 downstream frequencies and data rates Calculation of RX2 receive window Dwell time support Out-of-scope MAC commands - support will be added later on as part of #414 Adaptive Data Rate - support will be added later on as part of #415 FOpts - it is not yet clear whether this parameter needs to be used, this is tracked for all regions as part of user story #717 Decision Frequency offsets The AS923_FREQ_OFFSET parameter can be calculated based on the channel 0 and channel 1 frequencies in the LoRa Basics Station configuration. The corresponding channels for region AS923 are defined as follows: Channel 0 frequency Hz = 923200000 + AS923_FREQ_OFFSET_HZ Channel 1 frequency Hz = 923400000 + AS923_FREQ_OFFSET_HZ Using this formula we will calculate the offset by subtracting 923200000 from the configured channel 0 frequency. We will use the formula for channel 1 frequency to validate the offset value and throw and exception if values are not the same. In the implementation of region AS923 the frequencies for channel 0 and 1 will be passed to the region-specific constructor where the offset value will be calculated. Dwell Times We will support dwell times through the automatic dwell time management process described in the appendix. We will not support the automated cache refresh in a first version, but we will document the limitation that for multi-gateway support the device cache either needs to be manually invalidated or updated by waiting until it expires. Appendix Dwell times We discuss different approaches to handle dwell time limitations. No TxParamSetupReq support One option is to not support the TxParamSetupReq MAC Command as part of the initial version of the AS923 region implementation. One implication is that the maximum Equivalent Isotropically Radiated Power (EIRP), which is normally configurable through TxParamSetupReq , will be static and non-configurable. We introduce a Boolean configuration value in the concentrator device twin that specifies whether a dwell time limitation applies to that concentrator. Based on this configuration value, the gateway will apply a different set of regional parameters, which take the dwell time limitations into account. It will be the responsibility of the starter kit user to ensure that end devices are configured with the same dwell time settings as the concentrator to which they are connected, as it will not be automatically propagated to the end device through TxParamSetupReq . Pros: Easy to implement Cons: End devices (e.g. by Netvox) cannot be updated with different dwell time limitation defaults after shipping. If local regulations change, such devices cannot be used any longer with the starter kit Static EIRP Manual dwell time management The user configures the dwell time settings on a device-per-device basis by issuing a C2D messages, which gets translated to a TxParamSetupReq MAC command. Updating which dwell time setting is used happens as a separate manual step after the device settings were successfully updated. The flow looks as follows: The user issues a TxParamSetupReq through a C2D message to change the dwell time limitations on the end device The user (manually) checks whether the device picked up the correct dwell time limitations The user (manually) updates the device twin desired properties with the actual dwell time limitation flag Either the user (manually) needs to refresh all gateway caches and Redis or we only allow single gateway or OTAA joins The LNS fetches the desired properties from the device and uses a set of regional parameters based on the dwell time settings Pros: Relatively simple to implement Cons: A lot of manual steps involved/cumbersome for the user Does not resolve bug if the TxParamSetupAns is lost and the user does not have access to the serial output of the device Messages between successful C2D TxParamSetupReq transmission and device cache refresh might have inconsistent dwell time settings Automatic dwell time management The user configures the dwell time settings for all devices connected to a concentrator as part of the concentrator configuration. The LNS sends automated TxParamSetupReq MAC commands as a response to uplink messages. After a MAC command was sent, the LNS waits for the TxParamSetupAns . If the MAC answer was received, the LNS updates the reported properties of the device twin and uses a different set of regional parameters based on the dwell time setting (e.g. for the receive window channels). Also, the LNS invalidates the cache entries for that specific device in all other gateways. A visualization for this flow looks as follows: sequenceDiagram Iot Hub ->> LNS: C2D `TxParamSetupReq` message LNS ->> endDevice: `TxParamSetupReq` MAC Command alt endDevice sends acknowledgement `TxParamSetupAns` endDevice ->> LNS: `TxParamSetupAns` LNS ->> LNS: Updates in-memory state of dwell time setting (force persist in device twin reported properties -> error case needs to be handled) LNS ->> Function: Evict all cache entries for specific device else LNS ->> LNS: Continues to use default dwell time parameters (no modification of internal state), retries MAC Command on next uplink end Pros: Easiest solution of the three for the user Cons: Complexity Does not resolve bug if the TxParamSetupAns is lost","title":"004. Region AS923 implementation"},{"location":"adr/004_region_as923_implementation/#004-region-as923-implementation","text":"Epic : #412 Authors : Maggie Salak, Bastian Burger Status : Accepted","title":"004. Region AS923 implementation"},{"location":"adr/004_region_as923_implementation/#overview-problem-statement","text":"The specification of region AS923 defines a AS923_FREQ_OFFSET parameter which is used to accommodate different country-specific sub-bands across the 915 - 928 MHz band. The parameter can have one of four different values depending on a country. The corresponding frequency offset in Hz is AS923_FREQ_OFFSET_HZ = 100 x AS923_FREQ_OFFSET . The value of the parameter is needed for the purpose of calculating RX2 window frequencies for AS923 region. The parameter is not required for calculating RX1 receive window as it simply uses the same channel as the preceding uplink. In addition to sub-bands and frequency offsets, the regional parameter specification describes noteworthy behavior with respect to dwell times. The dwell time describes the time needed to transmit a LoRaWAN message, typically restrictions limit the dwell time to be not longer than 400ms. For the AS923 region, the specification says that dwell time limitations may apply to some locations in the AS923 region depending on local regulations. We are not able to get a comprehensive list of which locations use which regulations. To ensure conformity with these limitations, each gateway can configure an end device using TxParamSetupReq/Ans MAC commands. A typical flow may look like this: End device sends join request using DR2 - DR5 (which always complies with potential dwell time limitations of 400ms) The actual dwell time limitations are communicated by the gateway to the device using a downstream TxParamSetupReq MAC Command End device sends TxParamSetupAns MAC Command with empty payload as acknowledgement Both end device and gateway adhere to the limitations from there on With the LoRaWAN specification 1.0.3, the TxParamSetupReq/Ans MAC Command exchange is subject to a bug if the TxParamSetupAns is lost , which leaves the end devices unable to receive downlink messages. The bug will only be fixed in LoRaWAN specification version 1.0.4. This document summarizes decisions taken for the purpose of implementing support for region AS923.","title":"Overview / Problem Statement"},{"location":"adr/004_region_as923_implementation/#in-scope","text":"Support for all countries using frequency plan AS923 Calculation of RX1 downstream frequencies and data rates Calculation of RX2 receive window Dwell time support","title":"In-Scope"},{"location":"adr/004_region_as923_implementation/#out-of-scope","text":"MAC commands - support will be added later on as part of #414 Adaptive Data Rate - support will be added later on as part of #415 FOpts - it is not yet clear whether this parameter needs to be used, this is tracked for all regions as part of user story #717","title":"Out-of-scope"},{"location":"adr/004_region_as923_implementation/#decision","text":"","title":"Decision"},{"location":"adr/004_region_as923_implementation/#frequency-offsets","text":"The AS923_FREQ_OFFSET parameter can be calculated based on the channel 0 and channel 1 frequencies in the LoRa Basics Station configuration. The corresponding channels for region AS923 are defined as follows: Channel 0 frequency Hz = 923200000 + AS923_FREQ_OFFSET_HZ Channel 1 frequency Hz = 923400000 + AS923_FREQ_OFFSET_HZ Using this formula we will calculate the offset by subtracting 923200000 from the configured channel 0 frequency. We will use the formula for channel 1 frequency to validate the offset value and throw and exception if values are not the same. In the implementation of region AS923 the frequencies for channel 0 and 1 will be passed to the region-specific constructor where the offset value will be calculated.","title":"Frequency offsets"},{"location":"adr/004_region_as923_implementation/#dwell-times","text":"We will support dwell times through the automatic dwell time management process described in the appendix. We will not support the automated cache refresh in a first version, but we will document the limitation that for multi-gateway support the device cache either needs to be manually invalidated or updated by waiting until it expires.","title":"Dwell Times"},{"location":"adr/004_region_as923_implementation/#appendix","text":"","title":"Appendix"},{"location":"adr/004_region_as923_implementation/#dwell-times_1","text":"We discuss different approaches to handle dwell time limitations.","title":"Dwell times"},{"location":"adr/004_region_as923_implementation/#no-txparamsetupreq-support","text":"One option is to not support the TxParamSetupReq MAC Command as part of the initial version of the AS923 region implementation. One implication is that the maximum Equivalent Isotropically Radiated Power (EIRP), which is normally configurable through TxParamSetupReq , will be static and non-configurable. We introduce a Boolean configuration value in the concentrator device twin that specifies whether a dwell time limitation applies to that concentrator. Based on this configuration value, the gateway will apply a different set of regional parameters, which take the dwell time limitations into account. It will be the responsibility of the starter kit user to ensure that end devices are configured with the same dwell time settings as the concentrator to which they are connected, as it will not be automatically propagated to the end device through TxParamSetupReq . Pros: Easy to implement Cons: End devices (e.g. by Netvox) cannot be updated with different dwell time limitation defaults after shipping. If local regulations change, such devices cannot be used any longer with the starter kit Static EIRP","title":"No TxParamSetupReq support"},{"location":"adr/004_region_as923_implementation/#manual-dwell-time-management","text":"The user configures the dwell time settings on a device-per-device basis by issuing a C2D messages, which gets translated to a TxParamSetupReq MAC command. Updating which dwell time setting is used happens as a separate manual step after the device settings were successfully updated. The flow looks as follows: The user issues a TxParamSetupReq through a C2D message to change the dwell time limitations on the end device The user (manually) checks whether the device picked up the correct dwell time limitations The user (manually) updates the device twin desired properties with the actual dwell time limitation flag Either the user (manually) needs to refresh all gateway caches and Redis or we only allow single gateway or OTAA joins The LNS fetches the desired properties from the device and uses a set of regional parameters based on the dwell time settings Pros: Relatively simple to implement Cons: A lot of manual steps involved/cumbersome for the user Does not resolve bug if the TxParamSetupAns is lost and the user does not have access to the serial output of the device Messages between successful C2D TxParamSetupReq transmission and device cache refresh might have inconsistent dwell time settings","title":"Manual dwell time management"},{"location":"adr/004_region_as923_implementation/#automatic-dwell-time-management","text":"The user configures the dwell time settings for all devices connected to a concentrator as part of the concentrator configuration. The LNS sends automated TxParamSetupReq MAC commands as a response to uplink messages. After a MAC command was sent, the LNS waits for the TxParamSetupAns . If the MAC answer was received, the LNS updates the reported properties of the device twin and uses a different set of regional parameters based on the dwell time setting (e.g. for the receive window channels). Also, the LNS invalidates the cache entries for that specific device in all other gateways. A visualization for this flow looks as follows: sequenceDiagram Iot Hub ->> LNS: C2D `TxParamSetupReq` message LNS ->> endDevice: `TxParamSetupReq` MAC Command alt endDevice sends acknowledgement `TxParamSetupAns` endDevice ->> LNS: `TxParamSetupAns` LNS ->> LNS: Updates in-memory state of dwell time setting (force persist in device twin reported properties -> error case needs to be handled) LNS ->> Function: Evict all cache entries for specific device else LNS ->> LNS: Continues to use default dwell time parameters (no modification of internal state), retries MAC Command on next uplink end Pros: Easiest solution of the three for the user Cons: Complexity Does not resolve bug if the TxParamSetupAns is lost","title":"Automatic dwell time management"},{"location":"adr/005_observability/","text":"005. Observability Epic : #421 Authors : Patrick Schuler, Bastian Burger, Eugene Fedorenko Status : Accepted Status Accepted Context The goal of observability for the LoRaWAN IoT Edge starter kit is to: Monitor if the LoRaWAN Starter Kit solution works according to the user expectations regarding the following factors: Coverage. The data is coming from the majority of observed IoT assets Freshness. The data coming from the assets is fresh and relevant Throughput. The data is delivered from the assets without significant delays. Correctness. The ratio of errors and lost messages from the assets is small Provide monitoring instruments to detect possible failure/violation in each factor Provide instruments to identify and diagnose failures to get to the problem quickly The decisions in the following will apply to our LoRaWAN Network Server (LNS) implementation. Decisions We will support Azure Monitor as a first-class monitoring solution for our starter kit. A user can opt-in to use Application Insights with the starter kit, in which case we will support a rich set of observability features. If the user decides to not use Application Insights, we will still support essential monitoring capabilities. This means that we will: Track LNS logs in Application Insights (when opted in). We will adhere to the IoT Edge recommended format for the structure of the log console output. Export of logs to anything else than Application Insights requires a custom solution by the user and is not supported by the starter kit. Always expose metrics using prometheus-net . Additionally, we track LNS metrics using the ASP.NET Core Application Insights SDK (when opted in) Track traces using the Application Insights SDK (when opted in) Support alerts when using Application Insights and/or Log Analytics (with Prometheus format and metrics collector module) For now we will not support complete distributed tracing in the LoRaWAN starter kit, other than what Application Insights tracing will give us out of the box. We will evaluate this with #695 . A more thorough description of each bullet point follows below. Logs Using ILogger as the core method to log information from all parts of the application makes sure we have an abstracted logging framework we can use and can add/remove sinks as required. The different log sinks are implemented as ILoggerProvider . We will have three to start with: Console IoT Hub TCP The standard logger for Application Insights is added on an opt-in basis. We will adhere to the recommended logging format for the LNS console logger to comply with the IoT Edge log format and to simplify logs scraping. We will not support a full logs delivery solution, such as ELMS , since it will introduce too many components and too much complexity to the starter kit. This means that we will not support cloud delivery of edgeAgent and edgeHub logs other than what is documented in Retrieve IoT Edge logs - Azure IoT Edge | Microsoft Docs . If a user of the starter kit wants to scrape logs from modules other than LNS, or use a service other than the Application Insights SDK, the user will have to implement a custom solution. Traces We use built-in tracing from Azure Application Insights (on an opt-in basis). This works well for function calls and correlation to other services, such as Key Vault. We will not include message flow end to end tracing for now, but will reevaluate with #695 . Metrics The core modules edgeHub and edgeAgent support emitting metrics through a Prometheus endpoint, using the strategy described in Access built-in metrics - Azure IoT Edge | Microsoft Docs . To collect these metrics and integrate everything with Azure Monitor, we use the metric collector (preview) as suggested in Collect and transport metrics - Azure IoT Edge | Microsoft Docs to export metrics to a Log Analytics storage. We will always expose LNS custom metrics in Prometheus format using prometheus-net/prometheus-net , such that they can be consumed by any scraper that supports the Prometheus format. This will give us the following features: Unified metrics format accross all modules in the Edge device. The Prometheus format is industrial standard understood by various consumers. Decouples metrics exposure from the delivery-to-cloud approach. If at one point we decide to change how we scrap the metrics or how/where we deliver them to the observer, we can do that without changing the modules. Eliminates any dependencies on Azure Monitor services (Log Analytics / Application Insights) for essential monitoring Potentially gives ability to work offline if metrics are sent by the collector module through the Edge Hub using device-to-cloud channel. It's up to the customer to configure how, where and what metrics to deliver from any module on an edge device. In addition to this, we will support Application Insights metrics on an opt-in basis. When enabled, we will deliver most metrics (custom and default from LNS, except the edgeAgent and edgeHub metrics, which can only be delivered to Log Analytics) to Application Insights. This will ensure that we get many of the features that we get with Application Insights out of the box (Live Metrics, integration with alerts and workbooks), while still keeping the flexibility of consuming the metrics in Prometheus format and all the advantages that come with it. This comes at the cost of increased implementation complexity. Note: IoT Hub comes with curated workbooks and predefined queries for alerts based on built-in Prometheus-format metrics that are delivered by the metrics collector module to LogAnalytics. Custom metrics/events Name Description Source Namespace Dimensions ReceiveWindowHits Number of times we hit the different receive windows. LNS LoRaWan Gateway Id, (estimated) Receive Window ReceiveWindowMisses Number of missed on downstream windows LNS LoRaWan Gateway Id DeviceCacheHit Number of device cache hit LNS LoRaWan Gateway Id DeviceLoadRequests Number of device load requests LNS LoRaWan Gateway Id JoinRequests Number of join requests LNS LoRaWan Gateway Id StationConnectivityLost Connection to LBS lost LNS LoRaWan Gateway Id ActiveStationConnections Active connections to stations LNS LoRaWan Gateway Id UnhandledExceptions Number of unhandled exceptions in LNS processing LNS LoRaWan D2CMessagesReceived Number of messages received from device LNS LoRaWan Gateway Id D2CMessageDeliveryLatency Time from when we dispatched the message sent from the concentrator until we are done processing it LNS LoRaWan Gateway Id D2CMessageSize Message size in bytes received from device LNS LoRaWan Gateway Id C2DMessageTooLong Number of C2D messages that were too long to be sent downstream LNS LoRaWan Gateway Id Alerts We support the following alerts when the user opts in to use Application Insights. Name Description Source Condition HighUpstreamMessageLatency High device message processing time (throughput) D2CMessageDeliveryLatency Dynamic HighErrorCount High error count (correctness) Unhandled Exceptions Dynamic HighReceiveWindowMisses High device message processing time (throughput) ReceiveWindowMisses Dynamic HighDownstreamMessagesLostRatio High device messages lost ratio (correctness, throughput) Abandoned messages (IoT Hub metric) Dynamic Alternatives considered As a generic alternative to the Application Insights SDK we considered the OpenTelemetry .NET SDK. This would allow us to abstract emitting telemetry for different backend systems. However, the status of the project - open-telemetry/opentelemetry-dotnet: The OpenTelemetry .NET Client (github.com) - is not ready to be added to the Starter Kit. Especially Prometheus exporter (alpha) and metrics in general (experimental) do not help us improving our solution at the moment.","title":"005. Observability"},{"location":"adr/005_observability/#005-observability","text":"Epic : #421 Authors : Patrick Schuler, Bastian Burger, Eugene Fedorenko Status : Accepted","title":"005. Observability"},{"location":"adr/005_observability/#status","text":"Accepted","title":"Status"},{"location":"adr/005_observability/#context","text":"The goal of observability for the LoRaWAN IoT Edge starter kit is to: Monitor if the LoRaWAN Starter Kit solution works according to the user expectations regarding the following factors: Coverage. The data is coming from the majority of observed IoT assets Freshness. The data coming from the assets is fresh and relevant Throughput. The data is delivered from the assets without significant delays. Correctness. The ratio of errors and lost messages from the assets is small Provide monitoring instruments to detect possible failure/violation in each factor Provide instruments to identify and diagnose failures to get to the problem quickly The decisions in the following will apply to our LoRaWAN Network Server (LNS) implementation.","title":"Context"},{"location":"adr/005_observability/#decisions","text":"We will support Azure Monitor as a first-class monitoring solution for our starter kit. A user can opt-in to use Application Insights with the starter kit, in which case we will support a rich set of observability features. If the user decides to not use Application Insights, we will still support essential monitoring capabilities. This means that we will: Track LNS logs in Application Insights (when opted in). We will adhere to the IoT Edge recommended format for the structure of the log console output. Export of logs to anything else than Application Insights requires a custom solution by the user and is not supported by the starter kit. Always expose metrics using prometheus-net . Additionally, we track LNS metrics using the ASP.NET Core Application Insights SDK (when opted in) Track traces using the Application Insights SDK (when opted in) Support alerts when using Application Insights and/or Log Analytics (with Prometheus format and metrics collector module) For now we will not support complete distributed tracing in the LoRaWAN starter kit, other than what Application Insights tracing will give us out of the box. We will evaluate this with #695 . A more thorough description of each bullet point follows below.","title":"Decisions"},{"location":"adr/005_observability/#logs","text":"Using ILogger as the core method to log information from all parts of the application makes sure we have an abstracted logging framework we can use and can add/remove sinks as required. The different log sinks are implemented as ILoggerProvider . We will have three to start with: Console IoT Hub TCP The standard logger for Application Insights is added on an opt-in basis. We will adhere to the recommended logging format for the LNS console logger to comply with the IoT Edge log format and to simplify logs scraping. We will not support a full logs delivery solution, such as ELMS , since it will introduce too many components and too much complexity to the starter kit. This means that we will not support cloud delivery of edgeAgent and edgeHub logs other than what is documented in Retrieve IoT Edge logs - Azure IoT Edge | Microsoft Docs . If a user of the starter kit wants to scrape logs from modules other than LNS, or use a service other than the Application Insights SDK, the user will have to implement a custom solution.","title":"Logs"},{"location":"adr/005_observability/#traces","text":"We use built-in tracing from Azure Application Insights (on an opt-in basis). This works well for function calls and correlation to other services, such as Key Vault. We will not include message flow end to end tracing for now, but will reevaluate with #695 .","title":"Traces"},{"location":"adr/005_observability/#metrics","text":"The core modules edgeHub and edgeAgent support emitting metrics through a Prometheus endpoint, using the strategy described in Access built-in metrics - Azure IoT Edge | Microsoft Docs . To collect these metrics and integrate everything with Azure Monitor, we use the metric collector (preview) as suggested in Collect and transport metrics - Azure IoT Edge | Microsoft Docs to export metrics to a Log Analytics storage. We will always expose LNS custom metrics in Prometheus format using prometheus-net/prometheus-net , such that they can be consumed by any scraper that supports the Prometheus format. This will give us the following features: Unified metrics format accross all modules in the Edge device. The Prometheus format is industrial standard understood by various consumers. Decouples metrics exposure from the delivery-to-cloud approach. If at one point we decide to change how we scrap the metrics or how/where we deliver them to the observer, we can do that without changing the modules. Eliminates any dependencies on Azure Monitor services (Log Analytics / Application Insights) for essential monitoring Potentially gives ability to work offline if metrics are sent by the collector module through the Edge Hub using device-to-cloud channel. It's up to the customer to configure how, where and what metrics to deliver from any module on an edge device. In addition to this, we will support Application Insights metrics on an opt-in basis. When enabled, we will deliver most metrics (custom and default from LNS, except the edgeAgent and edgeHub metrics, which can only be delivered to Log Analytics) to Application Insights. This will ensure that we get many of the features that we get with Application Insights out of the box (Live Metrics, integration with alerts and workbooks), while still keeping the flexibility of consuming the metrics in Prometheus format and all the advantages that come with it. This comes at the cost of increased implementation complexity. Note: IoT Hub comes with curated workbooks and predefined queries for alerts based on built-in Prometheus-format metrics that are delivered by the metrics collector module to LogAnalytics.","title":"Metrics"},{"location":"adr/005_observability/#custom-metricsevents","text":"Name Description Source Namespace Dimensions ReceiveWindowHits Number of times we hit the different receive windows. LNS LoRaWan Gateway Id, (estimated) Receive Window ReceiveWindowMisses Number of missed on downstream windows LNS LoRaWan Gateway Id DeviceCacheHit Number of device cache hit LNS LoRaWan Gateway Id DeviceLoadRequests Number of device load requests LNS LoRaWan Gateway Id JoinRequests Number of join requests LNS LoRaWan Gateway Id StationConnectivityLost Connection to LBS lost LNS LoRaWan Gateway Id ActiveStationConnections Active connections to stations LNS LoRaWan Gateway Id UnhandledExceptions Number of unhandled exceptions in LNS processing LNS LoRaWan D2CMessagesReceived Number of messages received from device LNS LoRaWan Gateway Id D2CMessageDeliveryLatency Time from when we dispatched the message sent from the concentrator until we are done processing it LNS LoRaWan Gateway Id D2CMessageSize Message size in bytes received from device LNS LoRaWan Gateway Id C2DMessageTooLong Number of C2D messages that were too long to be sent downstream LNS LoRaWan Gateway Id","title":"Custom metrics/events"},{"location":"adr/005_observability/#alerts","text":"We support the following alerts when the user opts in to use Application Insights. Name Description Source Condition HighUpstreamMessageLatency High device message processing time (throughput) D2CMessageDeliveryLatency Dynamic HighErrorCount High error count (correctness) Unhandled Exceptions Dynamic HighReceiveWindowMisses High device message processing time (throughput) ReceiveWindowMisses Dynamic HighDownstreamMessagesLostRatio High device messages lost ratio (correctness, throughput) Abandoned messages (IoT Hub metric) Dynamic","title":"Alerts"},{"location":"adr/005_observability/#alternatives-considered","text":"As a generic alternative to the Application Insights SDK we considered the OpenTelemetry .NET SDK. This would allow us to abstract emitting telemetry for different backend systems. However, the status of the project - open-telemetry/opentelemetry-dotnet: The OpenTelemetry .NET Client (github.com) - is not ready to be added to the Starter Kit. Especially Prometheus exporter (alpha) and metrics in general (experimental) do not help us improving our solution at the moment.","title":"Alternatives considered"},{"location":"adr/006_cups/","text":"006. CUPS Protocol Implementation - Credential management Feature : #391 Author : Daniele Antonio Maggio Status : Accepted Overview LoRa Basics\u2122 Station defines a CUPS protocol for providing updated LNS/CUPS credentials and generic update data binary to any Client connecting to a CUPS Server. More information on the protocol can be found here . In-scope This document focuses on: Defining a flow diagram for common credential management scenarios: First connection Certificate rotation process Defining the changes needed in IoT Hub for handling Basics Station specific information Defining the changes needed in 'Facade' Azure Function for handling updated credential retrieval Defining the changes needed in LoRaWan Network Server for handling above mentioned flows Defining the changes needed in LoRa Device Provisioning CLI for handling creation/update of concentrators with certificate support Out-of-scope Out of scope for this document is: Defining a flow diagram for firmware update process Defining any change needed in IoT Hub / Azure Function / Network Server for handling firmware updates Authentication mechanisms with LoRa Basics\u2122 Station Context To better understand how the CUPS Protocol should be implemented, it is needed to understand how Basics Station is handling authentication. LoRa Basics\u2122 Station supports four different authentication modes: No Authentication TLS Server Authentication TLS Server and Client Authentication TLS Server Authentication and Client Token An authentication mode can be set by configuring some files in the device where Basics Station is going to be executed. More documentation here Basics Station can either use two different sets of credentials for achieving client authentication to the CUPS endpoint and to the LNS endpoint or re-use the same set of credentials for both. The aim of this document section is to take and record a decision for: Which authentication mode needs to be used for connecting to CUPS endpoint Which authentication mode needs to be used for connecting to LNS endpoint Where are the certificates stored and how to retrieve those? Decision(s) Out of the four authentication modes we should aim for \"TLS Server and Client Authentication\" for both CUPS and LNS endpoints. Driving this decision is the willing of increasing the overall security of the system. In order to keep the starter kit simple, the same set of server and client credentials are to be used for both CUPS and LNS protocol endpoints. For the same simplicity reason, credential bundles are going to be stored in an Azure Storage Account. Authentication to CUPS endpoint The CUPS endpoint should support mutual TLS authentication between client (basic station) and server (network server IoT Edge module). If not manually disabled via flags, for increased security, the server has to \"require\" client authentication and verify the provided credentials. Therefore, in order for Basic Station to connect to the CUPS HTTPS endpoint the following files should be provided to the station: cups.uri cups.crt (including the certificate in PEM format) cups.key (including the EC Private Key for the child certificate) cups.trust (including the chain of trust certificate for the server-side certificate) You may find an example on how to generate all the needed certificates in this script from the Basic Station official GitHub repository. Authentication to LNS endpoint As for CUPS, the LNS endpoint should support mutual TLS authentication between client (basic station) and server (network server IoT Edge module). For increased security the server should \"require\" client authentication and verify the provided credentials. Therefore, in order for Basic Station to connect to the LNS WSS endpoint the following files should be provided to the station: tc.uri (i.e.: \"wss://LoRaWanNetworkSrvModule:5001\") tc.crt (including the certificate in PEM format) tc.key (including the EC Private Key for the child certificate) tc.trust (including the chain of trust certificate for the server-side certificate) As stated in the decision section above, same certificate files as CUPS certificates above are expected to be used for the Starter Kit. There is no need to copy/paste manually these files in the Basic Station; the CUPS Protocol Implementation later described in this document will retrieve the needed credentials from a centralized repository and update the Basic Station configuration when it starts. This option is also providing an option to rotate certificates when these are near the expiration. Where to store certificates There are multiple options of where to store the cups.{trust,cert,key} and tc.{trust,cert,key} bundle files. As stated above, for the same simplicity reason, credential bundles are going to be stored in an Azure Storage Account. a. Azure Storage Account This is the easiest option for a new user of the Starter Kit, even though it's not the safest one. When deploying the Starter Kit, an Azure Storage Account is provisioned for Azure Functions. LoRa Device Provisioning tool should be capable of uploading the CLI provided bundle files and properly update the twin for the concentrator device being created in IoT Hub. When using this option, the 'Facade' Azure Function will retrieve certificate files from such storage account. b. Azure Key Vault secret This option requires more manual intervention, as the LoRa Device Provisioning tool is not adapted for uploading the credential bundle files to an Azure Key Vault instance. Following the documentation on how to set a secret in Azure Key Vault , you can just create two secrets and retrieve their URLs. When setting a Key Vault secret in the concentrator twin \"cups\" section, the 'Facade' Azure Function will retrieve it using a Managed Identity. c. External HTTPS repository This option requires most manual intervention. LoRa Device Provisioning tool is not uploading the credential bundle files to the repository. 'Facade' Azure Function can handle a HTTPS endpoint from where the bundles will be downloaded, even though there is no security check or additional AuthN/AuthZ option provided here. CUPS Protocol Implementation Flow diagram for credential management scenarios Prerequisites LoRa Basics\u2122 Station is configured with a cups.uri, a cups.trust and mandatory cups.cert/key The concentrator device twin should include changes as described in following section Flow sequenceDiagram autonumber Concentrator->>CUPS Server: POST /update-info CUPS Server->>IoT Hub: Retrieve 'Concentrator' twin CUPS Server->>CUPS Server: Verifies 'Concentrator' client certificate Note right of CUPS Server: Logic for client certificate validation to be defined. First version including a 'cupsClientThumbprint' to verify against. The client certificate thumbprint should be reported as a property. alt client certificate not valid CUPS Server->>Concentrator: Return forbidden else client certificate valid alt no cups config available CUPS Server->>CUPS Server: Throw as this is an indication of misconfiguration else cups config available alt different cupsUri alt different cupsCredCrc CUPS Server->>Facade Function: Retrieve CUPS Credential Blob Facade Function->>CUPS Server: CUPS Credential Blob CUPS Server->>Concentrator: Updated cupsUri and cupsCred else equal cupsCredCrc CUPS Server->>Concentrator: Updated cupsUri end else equal cupsUri alt different cupsCredCrc CUPS Server->>Facade Function: Retrieve CUPS Credential Blob Note right of CUPS Server: Different CRC is an indication of a credential rotation, therefore retrieval is needed. Facade Function->>CUPS Server: CUPS Credential Blob CUPS Server->>Concentrator: Updated cupsCred else equal cupsCredCrc CUPS Server->>CUPS Server: Checks tcUri and tcCredCrc as per above flow and properly return an update end end end end IoT Hub related changes Only change is related to the concentrator device twin. The following \"desired\" properties should be properly set: \"cups\" : { \"cupsUri\" : \"https://IP_or_DNS:PORT\" , \"tcUri\" : \"wss://IP_or_DNS:PORT\" , \"cupsCredCrc\" : INT , \"tcCredCrc\" : INT , \"cupsCredentialUrl\" : \"https://...\" , \"tcCredentialUrl\" : \"https://...\" }, // Following field to be used for first version client certificate validation \"clientThumbprint\" : [ \"Client certificate thumbprint\" ] 'cupsCredCrc' : should be computed as CRC32 checksum calculated over the concatenated credentials files cups.{trust,cert,key} 'tcCredCrc' : should be computed as CRC32 checksum calculated over the concatenated credentials files tc.{trust,cert,key} 'cupsCredentialUrl' : should point to the blob/secret containing the concatenated credentials cups.{trust,cert,key} 'tcCredentialUrl' : should point to the blob/secret containing the concatenated credentials tc.{trust,cert,key} 'clientThumbprint' : should include the thumbprint of the client certificate used for authenticating against the CUPS server. It is an array for allowing an old thumbprint to be accepted until the rotation mechanism completes Facade Azure Function related changes The Azure Function should implement a new endpoint 'FetchConcentratorCredentials' which executes the following flow: sequenceDiagram LoRaWanNetworkSrvModule->>Function: GET /fetchConcentratorCredentials Note right of LoRaWanNetworkSrvModule: Request includes 'stationEui' and 'credentialsType' (cups/tc) as query params Function->>IoT Hub: Retrieve Concentrator device Twin Function->>Function: Parse *CredentialUrl string to understand credentials location alt *CredentialUrl is a KeyVault Secret Function->>Azure KeyVault: Get KeyVault secret using Azure Function Managed Identity else *CredentialUrl is from Azure Blob Storage and no SAS is in Url Function->>Azure Blob Storage: Get Blob using MSI else *CredentialUrl is plain Url Function->>HTTPS Endpoint: Get Blob with HTTP GET Request end Function->>LoRaWanNetworkSrvModule: Return credential blob Note right of LoRaWanNetworkSrvModule: Response should be a base64 encoded credential sent as plaintext In addition to this, the Azure Function must be able to properly authenticate to target sink via Managed Identity (when using Azure Blob Storage or KeyVault). For the very first version of the implementation, only Azure Storage Account should be implemented and only connection string authentication is going to be supported. Considering that the default sink for the starter kit should be an Azure Storage Account, the template for the starter kit should be changed in such a way that a new Blob Container is created for uploading credential blob files. If using KeyVault secrets instead of Blob Storage, instructions on how to create a role assignment should be provided. LoRaWan Network Server changes LoRaDeviceAPIServiceBase and its implementation (LoRaDeviceAPIService) should include a method for calling the 'FetchConcentratorCredentials' endpoint IBasicsStationConfigurationService and its implementation (BasicsStationConfigurationService) should include a method for retrieving and parsing \"cups\" desired property in concentrator device twin BasicsStationNetworkServerStartup should include a new endpoint for handling CUPS '/update-info' POST requests BasicsStationNetworkServer should implement a basic client certificate validation when configuring kestrel A new CupsProtocolMessageProcessor class is implemented for achieving purposes of above drawn sequence diagram. LoRa Device Provisioning CLI changes The CLI should be changed in order to: Specify if the device being created is making use of CUPS or not In case a device being created is making use of CUPS, the tool should: accept as input a cupsCredentials file (being the concatenation of cups.{trust,cert,key} ) accept as input a tcCredentials file (being the concatenation of tc.{trust,cert,key} ) accept as input a clientThumbprint string (for client certificate validation) compute the CRC32 of above mentioned files create a device for the concentrator upload, via Azure Blob Storage C# SDK, the credential files to the Blob Storage update the Twin for the concentrator device accordingly In case a device being created is not making use of CUPS, tool should provide a --no-cups option, allowing to just specify a clientThumbprint (for client certificate validation on LNS endpoint) In case a device is already created and a credential rotation is required, the tool should: provide a \"update\" mechanism that: accept as input a cupsCredentials file (being the concatenation of cups.{trust,cert,key} ) accept as input a tcCredentials file (being the concatenation of tc.{trust,cert,key} ) accept as input a clientThumbprint string (for client certificate validation). New thumbprint is appended to the existing one. compute the CRC32 of above mentioned files create a device for the concentrator upload, via Azure Blob Storage C# SDK, the credential files to the Blob Storage update the Twin for the concentrator device accordingly provide a \"revoke\" mechanism that: accept as input an old clientThumbprint to be removed from the twin check that reported thumbprint property is not equal to the thumbprint that we want to remove (this means that the basic station has not rotated certificate yet) Appendix Generating the certificates For generating both server and client certificates there are two options. a) With an external PKI In this starter kit, we are assuming that the same server certificate is used for both CUPS and LNS endpoints. Using instructions at 'Basics Station authentication modes' page, copy the certificate so that the LoRaWan Network Server can retrieve it at its startup and use it within Kestrel. For concentrator configuration, it is important to retrieve the chain of trust which is used for signing the CUPS/LNS server certificate. This trust file needs to be: placed as cups.trust in the Concentrator BasicStation configuration folder stored in KeyVault/Blob Storage, using the provisioning tool, to be later retrieved from CUPS Server and transferred to BasicStation running on concentrator device (as tc.trust ) Regarding client authentication instead, to generate a concentrator specific certificate, you have two options: If your device is powerful enough to run OpenSSL: Generate a key and a certificate sign request Sign the request by using the PKI 'Install' the cups.cert/key and tc.cert/key on the concentrator Populate cupsCredCrc and tcCredCrc of the concentrator twin: either by manually calculating the CRC32 checksum of the concatenation of cups.{trust,cert,key} and tc.{trust,cert,key} (same file is expected for both cups and tc in the starter kit) by using the device provisioning tool If the device is not powerful enough and it's only providing you the ability to upload the .crt/.key bundle, you will have to execute the steps from previous option while generating the key and the certificate sign request on a different device b) Without an external PKI In this starter kit, we are providing some bash scripts to generate a self-signed root certificate and certificates for server/client authentication.","title":"006. CUPS Protocol Implementation - Credential management"},{"location":"adr/006_cups/#006-cups-protocol-implementation-credential-management","text":"Feature : #391 Author : Daniele Antonio Maggio Status : Accepted","title":"006. CUPS Protocol Implementation - Credential management"},{"location":"adr/006_cups/#overview","text":"LoRa Basics\u2122 Station defines a CUPS protocol for providing updated LNS/CUPS credentials and generic update data binary to any Client connecting to a CUPS Server. More information on the protocol can be found here .","title":"Overview"},{"location":"adr/006_cups/#in-scope","text":"This document focuses on: Defining a flow diagram for common credential management scenarios: First connection Certificate rotation process Defining the changes needed in IoT Hub for handling Basics Station specific information Defining the changes needed in 'Facade' Azure Function for handling updated credential retrieval Defining the changes needed in LoRaWan Network Server for handling above mentioned flows Defining the changes needed in LoRa Device Provisioning CLI for handling creation/update of concentrators with certificate support","title":"In-scope"},{"location":"adr/006_cups/#out-of-scope","text":"Out of scope for this document is: Defining a flow diagram for firmware update process Defining any change needed in IoT Hub / Azure Function / Network Server for handling firmware updates","title":"Out-of-scope"},{"location":"adr/006_cups/#authentication-mechanisms-with-lora-basicstm-station","text":"","title":"Authentication mechanisms with LoRa Basics\u2122 Station"},{"location":"adr/006_cups/#context","text":"To better understand how the CUPS Protocol should be implemented, it is needed to understand how Basics Station is handling authentication. LoRa Basics\u2122 Station supports four different authentication modes: No Authentication TLS Server Authentication TLS Server and Client Authentication TLS Server Authentication and Client Token An authentication mode can be set by configuring some files in the device where Basics Station is going to be executed. More documentation here Basics Station can either use two different sets of credentials for achieving client authentication to the CUPS endpoint and to the LNS endpoint or re-use the same set of credentials for both. The aim of this document section is to take and record a decision for: Which authentication mode needs to be used for connecting to CUPS endpoint Which authentication mode needs to be used for connecting to LNS endpoint Where are the certificates stored and how to retrieve those?","title":"Context"},{"location":"adr/006_cups/#decisions","text":"Out of the four authentication modes we should aim for \"TLS Server and Client Authentication\" for both CUPS and LNS endpoints. Driving this decision is the willing of increasing the overall security of the system. In order to keep the starter kit simple, the same set of server and client credentials are to be used for both CUPS and LNS protocol endpoints. For the same simplicity reason, credential bundles are going to be stored in an Azure Storage Account.","title":"Decision(s)"},{"location":"adr/006_cups/#authentication-to-cups-endpoint","text":"The CUPS endpoint should support mutual TLS authentication between client (basic station) and server (network server IoT Edge module). If not manually disabled via flags, for increased security, the server has to \"require\" client authentication and verify the provided credentials. Therefore, in order for Basic Station to connect to the CUPS HTTPS endpoint the following files should be provided to the station: cups.uri cups.crt (including the certificate in PEM format) cups.key (including the EC Private Key for the child certificate) cups.trust (including the chain of trust certificate for the server-side certificate) You may find an example on how to generate all the needed certificates in this script from the Basic Station official GitHub repository.","title":"Authentication to CUPS endpoint"},{"location":"adr/006_cups/#authentication-to-lns-endpoint","text":"As for CUPS, the LNS endpoint should support mutual TLS authentication between client (basic station) and server (network server IoT Edge module). For increased security the server should \"require\" client authentication and verify the provided credentials. Therefore, in order for Basic Station to connect to the LNS WSS endpoint the following files should be provided to the station: tc.uri (i.e.: \"wss://LoRaWanNetworkSrvModule:5001\") tc.crt (including the certificate in PEM format) tc.key (including the EC Private Key for the child certificate) tc.trust (including the chain of trust certificate for the server-side certificate) As stated in the decision section above, same certificate files as CUPS certificates above are expected to be used for the Starter Kit. There is no need to copy/paste manually these files in the Basic Station; the CUPS Protocol Implementation later described in this document will retrieve the needed credentials from a centralized repository and update the Basic Station configuration when it starts. This option is also providing an option to rotate certificates when these are near the expiration.","title":"Authentication to LNS endpoint"},{"location":"adr/006_cups/#where-to-store-certificates","text":"There are multiple options of where to store the cups.{trust,cert,key} and tc.{trust,cert,key} bundle files. As stated above, for the same simplicity reason, credential bundles are going to be stored in an Azure Storage Account.","title":"Where to store certificates"},{"location":"adr/006_cups/#a-azure-storage-account","text":"This is the easiest option for a new user of the Starter Kit, even though it's not the safest one. When deploying the Starter Kit, an Azure Storage Account is provisioned for Azure Functions. LoRa Device Provisioning tool should be capable of uploading the CLI provided bundle files and properly update the twin for the concentrator device being created in IoT Hub. When using this option, the 'Facade' Azure Function will retrieve certificate files from such storage account.","title":"a. Azure Storage Account"},{"location":"adr/006_cups/#b-azure-key-vault-secret","text":"This option requires more manual intervention, as the LoRa Device Provisioning tool is not adapted for uploading the credential bundle files to an Azure Key Vault instance. Following the documentation on how to set a secret in Azure Key Vault , you can just create two secrets and retrieve their URLs. When setting a Key Vault secret in the concentrator twin \"cups\" section, the 'Facade' Azure Function will retrieve it using a Managed Identity.","title":"b. Azure Key Vault secret"},{"location":"adr/006_cups/#c-external-https-repository","text":"This option requires most manual intervention. LoRa Device Provisioning tool is not uploading the credential bundle files to the repository. 'Facade' Azure Function can handle a HTTPS endpoint from where the bundles will be downloaded, even though there is no security check or additional AuthN/AuthZ option provided here.","title":"c. External HTTPS repository"},{"location":"adr/006_cups/#cups-protocol-implementation","text":"","title":"CUPS Protocol Implementation"},{"location":"adr/006_cups/#flow-diagram-for-credential-management-scenarios","text":"","title":"Flow diagram for credential management scenarios"},{"location":"adr/006_cups/#prerequisites","text":"LoRa Basics\u2122 Station is configured with a cups.uri, a cups.trust and mandatory cups.cert/key The concentrator device twin should include changes as described in following section","title":"Prerequisites"},{"location":"adr/006_cups/#flow","text":"sequenceDiagram autonumber Concentrator->>CUPS Server: POST /update-info CUPS Server->>IoT Hub: Retrieve 'Concentrator' twin CUPS Server->>CUPS Server: Verifies 'Concentrator' client certificate Note right of CUPS Server: Logic for client certificate validation to be defined. First version including a 'cupsClientThumbprint' to verify against. The client certificate thumbprint should be reported as a property. alt client certificate not valid CUPS Server->>Concentrator: Return forbidden else client certificate valid alt no cups config available CUPS Server->>CUPS Server: Throw as this is an indication of misconfiguration else cups config available alt different cupsUri alt different cupsCredCrc CUPS Server->>Facade Function: Retrieve CUPS Credential Blob Facade Function->>CUPS Server: CUPS Credential Blob CUPS Server->>Concentrator: Updated cupsUri and cupsCred else equal cupsCredCrc CUPS Server->>Concentrator: Updated cupsUri end else equal cupsUri alt different cupsCredCrc CUPS Server->>Facade Function: Retrieve CUPS Credential Blob Note right of CUPS Server: Different CRC is an indication of a credential rotation, therefore retrieval is needed. Facade Function->>CUPS Server: CUPS Credential Blob CUPS Server->>Concentrator: Updated cupsCred else equal cupsCredCrc CUPS Server->>CUPS Server: Checks tcUri and tcCredCrc as per above flow and properly return an update end end end end","title":"Flow"},{"location":"adr/006_cups/#iot-hub-related-changes","text":"Only change is related to the concentrator device twin. The following \"desired\" properties should be properly set: \"cups\" : { \"cupsUri\" : \"https://IP_or_DNS:PORT\" , \"tcUri\" : \"wss://IP_or_DNS:PORT\" , \"cupsCredCrc\" : INT , \"tcCredCrc\" : INT , \"cupsCredentialUrl\" : \"https://...\" , \"tcCredentialUrl\" : \"https://...\" }, // Following field to be used for first version client certificate validation \"clientThumbprint\" : [ \"Client certificate thumbprint\" ] 'cupsCredCrc' : should be computed as CRC32 checksum calculated over the concatenated credentials files cups.{trust,cert,key} 'tcCredCrc' : should be computed as CRC32 checksum calculated over the concatenated credentials files tc.{trust,cert,key} 'cupsCredentialUrl' : should point to the blob/secret containing the concatenated credentials cups.{trust,cert,key} 'tcCredentialUrl' : should point to the blob/secret containing the concatenated credentials tc.{trust,cert,key} 'clientThumbprint' : should include the thumbprint of the client certificate used for authenticating against the CUPS server. It is an array for allowing an old thumbprint to be accepted until the rotation mechanism completes","title":"IoT Hub related changes"},{"location":"adr/006_cups/#facade-azure-function-related-changes","text":"The Azure Function should implement a new endpoint 'FetchConcentratorCredentials' which executes the following flow: sequenceDiagram LoRaWanNetworkSrvModule->>Function: GET /fetchConcentratorCredentials Note right of LoRaWanNetworkSrvModule: Request includes 'stationEui' and 'credentialsType' (cups/tc) as query params Function->>IoT Hub: Retrieve Concentrator device Twin Function->>Function: Parse *CredentialUrl string to understand credentials location alt *CredentialUrl is a KeyVault Secret Function->>Azure KeyVault: Get KeyVault secret using Azure Function Managed Identity else *CredentialUrl is from Azure Blob Storage and no SAS is in Url Function->>Azure Blob Storage: Get Blob using MSI else *CredentialUrl is plain Url Function->>HTTPS Endpoint: Get Blob with HTTP GET Request end Function->>LoRaWanNetworkSrvModule: Return credential blob Note right of LoRaWanNetworkSrvModule: Response should be a base64 encoded credential sent as plaintext In addition to this, the Azure Function must be able to properly authenticate to target sink via Managed Identity (when using Azure Blob Storage or KeyVault). For the very first version of the implementation, only Azure Storage Account should be implemented and only connection string authentication is going to be supported. Considering that the default sink for the starter kit should be an Azure Storage Account, the template for the starter kit should be changed in such a way that a new Blob Container is created for uploading credential blob files. If using KeyVault secrets instead of Blob Storage, instructions on how to create a role assignment should be provided.","title":"Facade Azure Function related changes"},{"location":"adr/006_cups/#lorawan-network-server-changes","text":"LoRaDeviceAPIServiceBase and its implementation (LoRaDeviceAPIService) should include a method for calling the 'FetchConcentratorCredentials' endpoint IBasicsStationConfigurationService and its implementation (BasicsStationConfigurationService) should include a method for retrieving and parsing \"cups\" desired property in concentrator device twin BasicsStationNetworkServerStartup should include a new endpoint for handling CUPS '/update-info' POST requests BasicsStationNetworkServer should implement a basic client certificate validation when configuring kestrel A new CupsProtocolMessageProcessor class is implemented for achieving purposes of above drawn sequence diagram.","title":"LoRaWan Network Server changes"},{"location":"adr/006_cups/#lora-device-provisioning-cli-changes","text":"The CLI should be changed in order to: Specify if the device being created is making use of CUPS or not In case a device being created is making use of CUPS, the tool should: accept as input a cupsCredentials file (being the concatenation of cups.{trust,cert,key} ) accept as input a tcCredentials file (being the concatenation of tc.{trust,cert,key} ) accept as input a clientThumbprint string (for client certificate validation) compute the CRC32 of above mentioned files create a device for the concentrator upload, via Azure Blob Storage C# SDK, the credential files to the Blob Storage update the Twin for the concentrator device accordingly In case a device being created is not making use of CUPS, tool should provide a --no-cups option, allowing to just specify a clientThumbprint (for client certificate validation on LNS endpoint) In case a device is already created and a credential rotation is required, the tool should: provide a \"update\" mechanism that: accept as input a cupsCredentials file (being the concatenation of cups.{trust,cert,key} ) accept as input a tcCredentials file (being the concatenation of tc.{trust,cert,key} ) accept as input a clientThumbprint string (for client certificate validation). New thumbprint is appended to the existing one. compute the CRC32 of above mentioned files create a device for the concentrator upload, via Azure Blob Storage C# SDK, the credential files to the Blob Storage update the Twin for the concentrator device accordingly provide a \"revoke\" mechanism that: accept as input an old clientThumbprint to be removed from the twin check that reported thumbprint property is not equal to the thumbprint that we want to remove (this means that the basic station has not rotated certificate yet)","title":"LoRa Device Provisioning CLI changes"},{"location":"adr/006_cups/#appendix","text":"","title":"Appendix"},{"location":"adr/006_cups/#generating-the-certificates","text":"For generating both server and client certificates there are two options.","title":"Generating the certificates"},{"location":"adr/006_cups/#a-with-an-external-pki","text":"In this starter kit, we are assuming that the same server certificate is used for both CUPS and LNS endpoints. Using instructions at 'Basics Station authentication modes' page, copy the certificate so that the LoRaWan Network Server can retrieve it at its startup and use it within Kestrel. For concentrator configuration, it is important to retrieve the chain of trust which is used for signing the CUPS/LNS server certificate. This trust file needs to be: placed as cups.trust in the Concentrator BasicStation configuration folder stored in KeyVault/Blob Storage, using the provisioning tool, to be later retrieved from CUPS Server and transferred to BasicStation running on concentrator device (as tc.trust ) Regarding client authentication instead, to generate a concentrator specific certificate, you have two options: If your device is powerful enough to run OpenSSL: Generate a key and a certificate sign request Sign the request by using the PKI 'Install' the cups.cert/key and tc.cert/key on the concentrator Populate cupsCredCrc and tcCredCrc of the concentrator twin: either by manually calculating the CRC32 checksum of the concatenation of cups.{trust,cert,key} and tc.{trust,cert,key} (same file is expected for both cups and tc in the starter kit) by using the device provisioning tool If the device is not powerful enough and it's only providing you the ability to upload the .crt/.key bundle, you will have to execute the steps from previous option while generating the key and the certificate sign request on a different device","title":"a) With an external PKI"},{"location":"adr/006_cups/#b-without-an-external-pki","text":"In this starter kit, we are providing some bash scripts to generate a self-signed root certificate and certificates for server/client authentication.","title":"b) Without an external PKI"},{"location":"adr/007_message_deduplication/","text":"007. Deduplication of messages Feature : #946 Date : 10 January 2022 Authors : Spyros Giannakakis, Patrick Schuler Status : Accepted Introduction LoRaWan is a broadcast protocol. As such, a message sent from a device can be picked up by multiple concentrators which would then pass it upstream more than once. For some use-cases, sending upstream duplicate messages is not acceptable. With this ADR we provide an overview of the deduplication strategies employed in the Azure IoT Edge Starter Kit. The goal is also to provide insights as to how we arrived at the current solution. Glossary (Leaf) device: a sensor that measures and transmits IoT telemetry data Concentrator or station - LoRa Basics Station (LBS): converts from/to LoRa messages (demodulation/modulation) Gateway or network server - LoRa Network Server (LNS): IoT Edge enabled device connected to IoTHub FrameCounter strategy: can be single or multi gateway which is also the default. In single mode a device is connected to a specific gateway. Any other gateway that receives messages from this device drops them immediately. Deduplication strategy: indicates how duplicate messages should be handled. Drop: drops messages without further processing upstream nor downstream Mark: marks messages as duplicates but allows them upstream to IoTHub. The main use-case for this is to triangulate the location of sensors based on the signal strength. None (default): allows duplicates to pass upstream without marking them. Goals of the deduplication Besides dropping duplicates correctly, we must: Avoid calling the Azure Function more than required to not incur extra costs or performance/scale overhead. Support existing features like Mark, resubmissions etc. Overview We employ deduplication on 2 levels: on a single network server and across multiple network servers. 1. Deduplication on the network server level At this level we rely on information we have locally on the network server to detect duplicates. No calls to external services need to be made for the detection. In scope for this deduplication are: data messages (requiring confirmation or not) join requests Class A and C devices For the detection, a in-memory cache is utilised with a sliding expiration of 1 minute. The value of the cache entry is always the concentrator from where we received the message. The key depends on the type of message (data or join message). a. Data messages The relevant fields used for duplicate detection are the DevEui of the device the message came from, Mic and frame counter from the message. Duplicates from different concentrators This deduplication ensures that messages coming from different concentrators connected to the same network server are handled correctly. The most basic topology showcasing this scenario is the following: flowchart LR; Device-->LBS1; Device-->LBS2; LBS1-->LNS; LBS2-->LNS; LNS receives message A from LBS1 for the first time. Message is marked as NonDuplicate and a cache entry is created. LNS receives again message A this time from LBS2. LNS checks its local cache. If it's a cache miss, the message is marked as a NonDuplicate and considered as a new telemetry. This can happen for example if the second message takes longer than the retention period to arrive. If it's a cache hit, the following happens: stateDiagram-v2 direction LR state if_drop <<choice>> [*] --> Is_strategy_drop Is_strategy_drop --> if_drop if_drop --> True if_drop --> False True --> Duplicate False --> SoftDuplicate Duplicates from the same concentrator Under special circumstances, a network server might receive the same message multiple times from the same concentrator. These circumstances can be: a message that needs confirmation that was not confirmed in due time (missed window) a restarted device that happens to send the same measurement replay attacks The most basic topology showcasing this scenario is the following: flowchart LR; Device-->LBS-->LNS; LNS receives message A from LBS for the first time. Message is marked as NonDuplicate and a cache entry is created. LNS receives again message A from the same LBS. LNS checks its local cache. If it's a cache miss, it's marked as a NonDuplicate as before. If it's a cache hit the message is marked as DuplicateDueToResubmission independently of which deduplication strategy is used. Further processing of messages based on their duplication status Short version Status Upstream Downstream NonDuplicate \u2714 \u2714 SoftDuplicate \u2714 \u274c DuplicateDueToResubmission depends depends Duplicate \u274c \u274c where \u2714 indicates that the message is processed and \u274c indicates message is dropped. Longer version If message is NonDuplicate : Upstream\u2714, Downstream\u2714 (if requires confirmation) We always want to process unique messages up and if they need to, also downstream. If message is SoftDuplicate : Upstream\u2714, Downstream\u274c. We want to be aware of such messages on IoTHub but we skip sending downstream if they need confirmation because of possible collisions on the air. If message is marked as DuplicateDueToResubmission : if it requires confirmation the following check happens: stateDiagram-v2 direction LR state if_drop <<choice>> [*] --> Is_strategy_drop Is_strategy_drop --> if_drop if_drop --> True if_drop --> False True --> Upstream\u274c,Downstream\u2714 False --> Upstream\u2714,Downstream\u2714 if it does not require confirmation the following check happens: stateDiagram-v2 direction LR state if_drop <<choice>> [*] --> Is_strategy_drop Is_strategy_drop --> if_drop if_drop --> True if_drop --> False True --> Upstream\u274c,Downstream\u274c False --> Upstream_when_first_message\u2714,Downstream\u274c NB: For the first message (frame counter 1) we allow resending upstream because this could indicate a restarted device that simply sent the same measurement. The case that this happens for subsequent messages (framecounter > 1) within the retention period of the cache (1 minute) is unlikely and would more likely indicate a replay attack. These messages are dropped from the request validation logic. Since this message doesn't need confirmation, no downstream messages are sent in any case. Finally, if message is Duplicate : Upstream\u274c, Downstream\u274c We do not want to process the message further, no calls to the Azure Function or IoTHub happen. b. Join requests Here we are detecting requests as duplicates based on their AppEui (aka JoinEui), DevEui and DevNonce. If there is a cache hit (a request with the same values for these fields within the retention period of the cache) the request is considered a Duplicate and dropped immediately. We are not differentiating the cases of SoftDuplicate and DuplicateDueToResubmission here as we do for data messages. General notes Deduplication at this level is one of the first things that happen before a request is processed. We considered even moving this higher up the processing stack when we construct the LNS DTOs. The problem with this approach was that at that stage we don't yet have the deduplication strategy information. The strategy affects the decision making as we saw before and it is stored on the device twin which is available later on the processing stack. The frame counter strategy does not influence the way this deduplication works but influences the deduplication between network servers (below). This logic is tested with a combination of unit, integration and E2E tests. 2. Deduplication between different network servers At this deduplication we ensure that duplicate messages coming from different network servers are handled correctly. The categorization happens from an Azure Function where we need to send some metadata of the messages. If a device is not configured for a single gateway (i.e. no gateway is assigned) we reach out to the function to determine, if a particular message from a device was already processed. flowchart LR; Device-->LBS1-->LNS1-->Function-->Redis; Device-->LBS2-->LNS2-->Function-->Redis; Message A from Device 1 arrives at LNS 1 Message A from Device 1 arrives at LNS 2 LNS 1 calls the function The function receives a lock on redis and tries to read the state of the message - the key is composed out of the Dev EUI and the Gateway Id The last processed FcntUp is compared to the Message's FcntUp We mark the request to be duplicate=false in the following cases: The incoming FcntUp is > than the cached FcntUp The incoming FcntUp is == to the cached FcntUp and the Gateway Id matches (reprocessing) Other cases are considered duplicates and the result contains the processing gateway id Once the LNS receives the result, it does apply different actions based on the deduplication strategy selected for the device. Upstream Processing Note : all cases are describing the action, when receiving the information that the message is a duplicate. Drop : Stop processing. Mark : Mark the message \"DupMsg\": true. None : Process every message without marking. Downstream Processing The downstream processing is different in that it is not depending on the deduplication strategy. We only ever send a single downstream message, if we have to. Also this is driven by the function. In the same process, we determine, if we are the first gateway to process the message. Only that gateway will receive a fcnt down to confirm the message. All other gateways, will not receive a fcnt down.","title":"007. Deduplication of messages"},{"location":"adr/007_message_deduplication/#007-deduplication-of-messages","text":"Feature : #946 Date : 10 January 2022 Authors : Spyros Giannakakis, Patrick Schuler Status : Accepted","title":"007. Deduplication of messages"},{"location":"adr/007_message_deduplication/#introduction","text":"LoRaWan is a broadcast protocol. As such, a message sent from a device can be picked up by multiple concentrators which would then pass it upstream more than once. For some use-cases, sending upstream duplicate messages is not acceptable. With this ADR we provide an overview of the deduplication strategies employed in the Azure IoT Edge Starter Kit. The goal is also to provide insights as to how we arrived at the current solution.","title":"Introduction"},{"location":"adr/007_message_deduplication/#glossary","text":"(Leaf) device: a sensor that measures and transmits IoT telemetry data Concentrator or station - LoRa Basics Station (LBS): converts from/to LoRa messages (demodulation/modulation) Gateway or network server - LoRa Network Server (LNS): IoT Edge enabled device connected to IoTHub FrameCounter strategy: can be single or multi gateway which is also the default. In single mode a device is connected to a specific gateway. Any other gateway that receives messages from this device drops them immediately. Deduplication strategy: indicates how duplicate messages should be handled. Drop: drops messages without further processing upstream nor downstream Mark: marks messages as duplicates but allows them upstream to IoTHub. The main use-case for this is to triangulate the location of sensors based on the signal strength. None (default): allows duplicates to pass upstream without marking them.","title":"Glossary"},{"location":"adr/007_message_deduplication/#goals-of-the-deduplication","text":"Besides dropping duplicates correctly, we must: Avoid calling the Azure Function more than required to not incur extra costs or performance/scale overhead. Support existing features like Mark, resubmissions etc.","title":"Goals of the deduplication"},{"location":"adr/007_message_deduplication/#overview","text":"We employ deduplication on 2 levels: on a single network server and across multiple network servers.","title":"Overview"},{"location":"adr/007_message_deduplication/#1-deduplication-on-the-network-server-level","text":"At this level we rely on information we have locally on the network server to detect duplicates. No calls to external services need to be made for the detection. In scope for this deduplication are: data messages (requiring confirmation or not) join requests Class A and C devices For the detection, a in-memory cache is utilised with a sliding expiration of 1 minute. The value of the cache entry is always the concentrator from where we received the message. The key depends on the type of message (data or join message).","title":"1. Deduplication on the network server level"},{"location":"adr/007_message_deduplication/#a-data-messages","text":"The relevant fields used for duplicate detection are the DevEui of the device the message came from, Mic and frame counter from the message.","title":"a. Data messages"},{"location":"adr/007_message_deduplication/#duplicates-from-different-concentrators","text":"This deduplication ensures that messages coming from different concentrators connected to the same network server are handled correctly. The most basic topology showcasing this scenario is the following: flowchart LR; Device-->LBS1; Device-->LBS2; LBS1-->LNS; LBS2-->LNS; LNS receives message A from LBS1 for the first time. Message is marked as NonDuplicate and a cache entry is created. LNS receives again message A this time from LBS2. LNS checks its local cache. If it's a cache miss, the message is marked as a NonDuplicate and considered as a new telemetry. This can happen for example if the second message takes longer than the retention period to arrive. If it's a cache hit, the following happens: stateDiagram-v2 direction LR state if_drop <<choice>> [*] --> Is_strategy_drop Is_strategy_drop --> if_drop if_drop --> True if_drop --> False True --> Duplicate False --> SoftDuplicate","title":"Duplicates from different concentrators"},{"location":"adr/007_message_deduplication/#duplicates-from-the-same-concentrator","text":"Under special circumstances, a network server might receive the same message multiple times from the same concentrator. These circumstances can be: a message that needs confirmation that was not confirmed in due time (missed window) a restarted device that happens to send the same measurement replay attacks The most basic topology showcasing this scenario is the following: flowchart LR; Device-->LBS-->LNS; LNS receives message A from LBS for the first time. Message is marked as NonDuplicate and a cache entry is created. LNS receives again message A from the same LBS. LNS checks its local cache. If it's a cache miss, it's marked as a NonDuplicate as before. If it's a cache hit the message is marked as DuplicateDueToResubmission independently of which deduplication strategy is used.","title":"Duplicates from the same concentrator"},{"location":"adr/007_message_deduplication/#further-processing-of-messages-based-on-their-duplication-status","text":"","title":"Further processing of messages based on their duplication status"},{"location":"adr/007_message_deduplication/#short-version","text":"Status Upstream Downstream NonDuplicate \u2714 \u2714 SoftDuplicate \u2714 \u274c DuplicateDueToResubmission depends depends Duplicate \u274c \u274c where \u2714 indicates that the message is processed and \u274c indicates message is dropped.","title":"Short version"},{"location":"adr/007_message_deduplication/#longer-version","text":"If message is NonDuplicate : Upstream\u2714, Downstream\u2714 (if requires confirmation) We always want to process unique messages up and if they need to, also downstream. If message is SoftDuplicate : Upstream\u2714, Downstream\u274c. We want to be aware of such messages on IoTHub but we skip sending downstream if they need confirmation because of possible collisions on the air. If message is marked as DuplicateDueToResubmission : if it requires confirmation the following check happens: stateDiagram-v2 direction LR state if_drop <<choice>> [*] --> Is_strategy_drop Is_strategy_drop --> if_drop if_drop --> True if_drop --> False True --> Upstream\u274c,Downstream\u2714 False --> Upstream\u2714,Downstream\u2714 if it does not require confirmation the following check happens: stateDiagram-v2 direction LR state if_drop <<choice>> [*] --> Is_strategy_drop Is_strategy_drop --> if_drop if_drop --> True if_drop --> False True --> Upstream\u274c,Downstream\u274c False --> Upstream_when_first_message\u2714,Downstream\u274c NB: For the first message (frame counter 1) we allow resending upstream because this could indicate a restarted device that simply sent the same measurement. The case that this happens for subsequent messages (framecounter > 1) within the retention period of the cache (1 minute) is unlikely and would more likely indicate a replay attack. These messages are dropped from the request validation logic. Since this message doesn't need confirmation, no downstream messages are sent in any case. Finally, if message is Duplicate : Upstream\u274c, Downstream\u274c We do not want to process the message further, no calls to the Azure Function or IoTHub happen.","title":"Longer version"},{"location":"adr/007_message_deduplication/#b-join-requests","text":"Here we are detecting requests as duplicates based on their AppEui (aka JoinEui), DevEui and DevNonce. If there is a cache hit (a request with the same values for these fields within the retention period of the cache) the request is considered a Duplicate and dropped immediately. We are not differentiating the cases of SoftDuplicate and DuplicateDueToResubmission here as we do for data messages.","title":"b. Join requests"},{"location":"adr/007_message_deduplication/#general-notes","text":"Deduplication at this level is one of the first things that happen before a request is processed. We considered even moving this higher up the processing stack when we construct the LNS DTOs. The problem with this approach was that at that stage we don't yet have the deduplication strategy information. The strategy affects the decision making as we saw before and it is stored on the device twin which is available later on the processing stack. The frame counter strategy does not influence the way this deduplication works but influences the deduplication between network servers (below). This logic is tested with a combination of unit, integration and E2E tests.","title":"General notes"},{"location":"adr/007_message_deduplication/#2-deduplication-between-different-network-servers","text":"At this deduplication we ensure that duplicate messages coming from different network servers are handled correctly. The categorization happens from an Azure Function where we need to send some metadata of the messages. If a device is not configured for a single gateway (i.e. no gateway is assigned) we reach out to the function to determine, if a particular message from a device was already processed. flowchart LR; Device-->LBS1-->LNS1-->Function-->Redis; Device-->LBS2-->LNS2-->Function-->Redis; Message A from Device 1 arrives at LNS 1 Message A from Device 1 arrives at LNS 2 LNS 1 calls the function The function receives a lock on redis and tries to read the state of the message - the key is composed out of the Dev EUI and the Gateway Id The last processed FcntUp is compared to the Message's FcntUp We mark the request to be duplicate=false in the following cases: The incoming FcntUp is > than the cached FcntUp The incoming FcntUp is == to the cached FcntUp and the Gateway Id matches (reprocessing) Other cases are considered duplicates and the result contains the processing gateway id Once the LNS receives the result, it does apply different actions based on the deduplication strategy selected for the device.","title":"2. Deduplication between different network servers"},{"location":"adr/007_message_deduplication/#upstream-processing","text":"Note : all cases are describing the action, when receiving the information that the message is a duplicate. Drop : Stop processing. Mark : Mark the message \"DupMsg\": true. None : Process every message without marking.","title":"Upstream Processing"},{"location":"adr/007_message_deduplication/#downstream-processing","text":"The downstream processing is different in that it is not depending on the deduplication strategy. We only ever send a single downstream message, if we have to. Also this is driven by the function. In the same process, we determine, if we are the first gateway to process the message. Only that gateway will receive a fcnt down to confirm the message. All other gateways, will not receive a fcnt down.","title":"Downstream Processing"},{"location":"adr/008_cups_firmware_upgrade/","text":"008. CUPS Protocol Implementation - Firmware Upgrade Feature : #1189 Authors : Daniele Antonio Maggio, Maggie Salak Status : Accepted This ADR is an extension of 006. CUPS Protocol Implementation - Credential management and focuses of firmware upgrades. For details about the general CUPS protocol implementation please refer to the other document. Overview Firmware upgrades for LoRa Basics\u2122 Station need to be supported in the CUPS protocol implementation. More information on the protocol and parameters exchanged between the Station and the CUPS server which are relevant to firmware upgrades can be found in The CUPS protocol - documentation . In-scope This document focuses on: Defining a flow for executing firmware upgrades of the Basics Station Defining the changes needed in device twins for the concentrator station stored in IoT Hub for handling firmware upgrades Defining the changes required in the storage solution used for the CUPS protocol implementation Defining the changes needed in the Azure Function for supporting firmware upgrades Defining the changes needed in LoRaWan Network Server (LNS) for handling firmware upgrades Defining the changes needed in LoRa Device Provisioning CLI for allowing firmware upgrades Out-of-scope Generating of the signature key, CRC32 checksum of the signature and digest in the LoRa Device Provisioning CLI is considered a stretch and will not be added to the tool as a functionality for the time being. This document provides sample commands which can be used to generate required values in the appendix. Decisions Context The CUPS request described in The CUPS protocol - documentation contains the package field which indicates the current firmware version of the Basics Station. The value will need to be updated whenever a firmware upgrade of the Basics Station is performed by the user. Firmware upgrade flow When provisioning a device that will need firmware upgrades, the end user should generate a sig-0.key and store it on the device and in a centralized repository of their own choice (example on how to generate it can be found in the appendix). When a firmware upgrade needs to be provided to the device, the user should generate a digest of the executable file of the upgrade (as in examples mentioned above) and retrieve the CRC32 Checksum of the sig-0.key . Then 4 inputs (file, digest, checksum and new version) should be provided to the LoRa Device Provisioning CLI tool to properly upload the file to a blob storage and store the needed information in the concentrator twin (blob URL in storage, digest, checksum and the new version number). The Basics Station sends the CUPS request containing the currently used version (in the package field). The LNS compares the values from the device twin and the CUPS request, and determines if an upgrade is required. If that's the case, the LNS will download the upgrade file from storage and send a properly populated response to the Basics Station. The Basics Station will then execute the actual firmware upgrade. After the upgrade is complete, next time when the Network Server receives a CUPS request, the new version of the Station will be saved in reported properties of the device twin. sequenceDiagram autonumber User->>LoRa Device Provisioning CLI: Request Station upgrade LoRa Device Provisioning CLI->>Storage account: Upload firmware file LoRa Device Provisioning CLI->>IoT Hub: Update 'Concentrator' twin Concentrator->>Network Server: POST /update-info Network Server->>IoT Hub: Retrieve 'Concentrator' twin Network Server->>Network Server: Check if versions of the Station are different alt versions are the same Network Server->>Concentrator: CUPS response without firmware upgrade else versions are different Network Server->>Network Server: Verify if any of the `keys` from CUPS request match the `fwKeyChecksum` alt no match Network Server->>Network Server: Throw as this indicates a misconfiguration else one of the keys matches `fwKeyChecksum` Network Server->>Facade Function: Retrieve firmware upgrade file Facade Function->>Storage account: Download firmware file Network Server->>Concentrator: CUPS response with firmware upgrade fields populated end end IoT Hub related changes The only change is related to the concentrator device twin. In addition to the values already stored in the twin, the following need to be added: \"cups\" : { // ... \"package\" : \"1.0.1\" , \"fwUrl\" : \"https://...\" , \"fwKeyChecksum\" : 123456 , \"fwSignature\" : \"...\" } 'package' : desired package version of the Station (matching what will be extracted as version.txt file during update) 'fwUrl' : URL pointing to the storage location of the file required to run the upgrade 'fwKeyChecksum' : checksum of the key used to sign the digest of the firmware upgrade file 'fwSignature' : signature of the uploaded firmware upgrade file (as base64 encoded string) Storage related changes We will use the same storage solution as the one selected for the general CUPS protocol support (storage account). A new container named \"fwupgrades\" will be used to store the firmware upgrade files. The file names will be in the format \"{stationEui}-{package}\" (without any extension, as anyways these are going to be downloaded as update.bin from the Basics Station executable). Azure Function related changes A new endpoint will be added in the Facade Azure Function which will be used to fetch firmware upgrade files from the storage account. The function will be authenticating to the storage account with a connection string which is already being used for function runtime itself. The endpoint will accept the StationEui as input, then retrieve the concentrator twin from IoT Hub, retrieve the firmware file from the storage account and send it in the response (the file will be processed as a stream to avoid loading the contents into memory). This mechanism will have a theoretical limit of 100MB for the firmware upgrade (as we cannot process more with Azure Function). This should be enough given the size of the Basics Station executable (around 1MB at the time of writing this document). Changes in the LoRaWan Network Server When the Network Server receives a CUPS request, it should update the current version of the Station in the reported properties of the concentrator device twin, as long as the reported value is different from the current version. The implementation of CupsProtocolMessageProcessor should be extended for checking the package field from the concentrator device twin. In case there the value is different from the one received from the Basics Station in the CUPS request, we will first check whether any of the keys in the keys array from the CUPS request is equal to the fwKeyChecksum field that is stored in the twin. If there is no matching checksum, it means that the concentrator is missing the key required for calculating the digest and verifying the update file. When this happens we will throw an appropriate error. If there is a match for the fwKeyChecksum , the Network Server will trigger the download of the firmware upgrade file (using the Facade Function endpoint) and populate the CUPS response accordingly, so that the Station can then execute the upgrade. LoRa Device Provisioning CLI changes A new command will be added to the Device Provisioning CLI which will allow the user to trigger a firmware upgrade. The command will accept the follwing inputs: Station EUI new package version (e.g. 1.0.1 ) firmware upgrade file signature (digest of the file) CRC32 checksum of the key used for the signature The CLI tool will: Upload a blob with the firmware file to the storage account. Update concentrator device twin with the new blob URL, signature and CRC32 checksum of the key used to generate the signature and the new package version. Appendix Generating signature keys The following commands can be used to generate a signature key: openssl ecparam -name prime256v1 -genkey | openssl ec -out sig-0.pem openssl ec -in sig-0.pem -pubout -out sig-0.pub openssl ec -in sig-0.pub -inform PEM -outform DER -pubin | tail -c 64 > sig-0.key Calculating the CRC32 checksum of the signature key cat sig-0.key | gzip -1 | tail -c 8 | od -t ${ 1 :- u } 4 -N 4 -An --endian = little | xargs echo > sig-0.crc Calculating the digest of a firmware upgrade file Digest of an upgrade file ( upgrade.sh ) can be calculated using the previously generated signature key with the command: openssl dgst -sha512 -sign sig-0.pem update.sh > update.sh.sig-0.sha512","title":"008. CUPS Protocol Implementation - Firmware Upgrade"},{"location":"adr/008_cups_firmware_upgrade/#008-cups-protocol-implementation-firmware-upgrade","text":"Feature : #1189 Authors : Daniele Antonio Maggio, Maggie Salak Status : Accepted This ADR is an extension of 006. CUPS Protocol Implementation - Credential management and focuses of firmware upgrades. For details about the general CUPS protocol implementation please refer to the other document.","title":"008. CUPS Protocol Implementation - Firmware Upgrade"},{"location":"adr/008_cups_firmware_upgrade/#overview","text":"Firmware upgrades for LoRa Basics\u2122 Station need to be supported in the CUPS protocol implementation. More information on the protocol and parameters exchanged between the Station and the CUPS server which are relevant to firmware upgrades can be found in The CUPS protocol - documentation .","title":"Overview"},{"location":"adr/008_cups_firmware_upgrade/#in-scope","text":"This document focuses on: Defining a flow for executing firmware upgrades of the Basics Station Defining the changes needed in device twins for the concentrator station stored in IoT Hub for handling firmware upgrades Defining the changes required in the storage solution used for the CUPS protocol implementation Defining the changes needed in the Azure Function for supporting firmware upgrades Defining the changes needed in LoRaWan Network Server (LNS) for handling firmware upgrades Defining the changes needed in LoRa Device Provisioning CLI for allowing firmware upgrades","title":"In-scope"},{"location":"adr/008_cups_firmware_upgrade/#out-of-scope","text":"Generating of the signature key, CRC32 checksum of the signature and digest in the LoRa Device Provisioning CLI is considered a stretch and will not be added to the tool as a functionality for the time being. This document provides sample commands which can be used to generate required values in the appendix.","title":"Out-of-scope"},{"location":"adr/008_cups_firmware_upgrade/#decisions","text":"","title":"Decisions"},{"location":"adr/008_cups_firmware_upgrade/#context","text":"The CUPS request described in The CUPS protocol - documentation contains the package field which indicates the current firmware version of the Basics Station. The value will need to be updated whenever a firmware upgrade of the Basics Station is performed by the user.","title":"Context"},{"location":"adr/008_cups_firmware_upgrade/#firmware-upgrade-flow","text":"When provisioning a device that will need firmware upgrades, the end user should generate a sig-0.key and store it on the device and in a centralized repository of their own choice (example on how to generate it can be found in the appendix). When a firmware upgrade needs to be provided to the device, the user should generate a digest of the executable file of the upgrade (as in examples mentioned above) and retrieve the CRC32 Checksum of the sig-0.key . Then 4 inputs (file, digest, checksum and new version) should be provided to the LoRa Device Provisioning CLI tool to properly upload the file to a blob storage and store the needed information in the concentrator twin (blob URL in storage, digest, checksum and the new version number). The Basics Station sends the CUPS request containing the currently used version (in the package field). The LNS compares the values from the device twin and the CUPS request, and determines if an upgrade is required. If that's the case, the LNS will download the upgrade file from storage and send a properly populated response to the Basics Station. The Basics Station will then execute the actual firmware upgrade. After the upgrade is complete, next time when the Network Server receives a CUPS request, the new version of the Station will be saved in reported properties of the device twin. sequenceDiagram autonumber User->>LoRa Device Provisioning CLI: Request Station upgrade LoRa Device Provisioning CLI->>Storage account: Upload firmware file LoRa Device Provisioning CLI->>IoT Hub: Update 'Concentrator' twin Concentrator->>Network Server: POST /update-info Network Server->>IoT Hub: Retrieve 'Concentrator' twin Network Server->>Network Server: Check if versions of the Station are different alt versions are the same Network Server->>Concentrator: CUPS response without firmware upgrade else versions are different Network Server->>Network Server: Verify if any of the `keys` from CUPS request match the `fwKeyChecksum` alt no match Network Server->>Network Server: Throw as this indicates a misconfiguration else one of the keys matches `fwKeyChecksum` Network Server->>Facade Function: Retrieve firmware upgrade file Facade Function->>Storage account: Download firmware file Network Server->>Concentrator: CUPS response with firmware upgrade fields populated end end","title":"Firmware upgrade flow"},{"location":"adr/008_cups_firmware_upgrade/#iot-hub-related-changes","text":"The only change is related to the concentrator device twin. In addition to the values already stored in the twin, the following need to be added: \"cups\" : { // ... \"package\" : \"1.0.1\" , \"fwUrl\" : \"https://...\" , \"fwKeyChecksum\" : 123456 , \"fwSignature\" : \"...\" } 'package' : desired package version of the Station (matching what will be extracted as version.txt file during update) 'fwUrl' : URL pointing to the storage location of the file required to run the upgrade 'fwKeyChecksum' : checksum of the key used to sign the digest of the firmware upgrade file 'fwSignature' : signature of the uploaded firmware upgrade file (as base64 encoded string)","title":"IoT Hub related changes"},{"location":"adr/008_cups_firmware_upgrade/#storage-related-changes","text":"We will use the same storage solution as the one selected for the general CUPS protocol support (storage account). A new container named \"fwupgrades\" will be used to store the firmware upgrade files. The file names will be in the format \"{stationEui}-{package}\" (without any extension, as anyways these are going to be downloaded as update.bin from the Basics Station executable).","title":"Storage related changes"},{"location":"adr/008_cups_firmware_upgrade/#azure-function-related-changes","text":"A new endpoint will be added in the Facade Azure Function which will be used to fetch firmware upgrade files from the storage account. The function will be authenticating to the storage account with a connection string which is already being used for function runtime itself. The endpoint will accept the StationEui as input, then retrieve the concentrator twin from IoT Hub, retrieve the firmware file from the storage account and send it in the response (the file will be processed as a stream to avoid loading the contents into memory). This mechanism will have a theoretical limit of 100MB for the firmware upgrade (as we cannot process more with Azure Function). This should be enough given the size of the Basics Station executable (around 1MB at the time of writing this document).","title":"Azure Function related changes"},{"location":"adr/008_cups_firmware_upgrade/#changes-in-the-lorawan-network-server","text":"When the Network Server receives a CUPS request, it should update the current version of the Station in the reported properties of the concentrator device twin, as long as the reported value is different from the current version. The implementation of CupsProtocolMessageProcessor should be extended for checking the package field from the concentrator device twin. In case there the value is different from the one received from the Basics Station in the CUPS request, we will first check whether any of the keys in the keys array from the CUPS request is equal to the fwKeyChecksum field that is stored in the twin. If there is no matching checksum, it means that the concentrator is missing the key required for calculating the digest and verifying the update file. When this happens we will throw an appropriate error. If there is a match for the fwKeyChecksum , the Network Server will trigger the download of the firmware upgrade file (using the Facade Function endpoint) and populate the CUPS response accordingly, so that the Station can then execute the upgrade.","title":"Changes in the LoRaWan Network Server"},{"location":"adr/008_cups_firmware_upgrade/#lora-device-provisioning-cli-changes","text":"A new command will be added to the Device Provisioning CLI which will allow the user to trigger a firmware upgrade. The command will accept the follwing inputs: Station EUI new package version (e.g. 1.0.1 ) firmware upgrade file signature (digest of the file) CRC32 checksum of the key used for the signature The CLI tool will: Upload a blob with the firmware file to the storage account. Update concentrator device twin with the new blob URL, signature and CRC32 checksum of the key used to generate the signature and the new package version.","title":"LoRa Device Provisioning CLI changes"},{"location":"adr/008_cups_firmware_upgrade/#appendix","text":"","title":"Appendix"},{"location":"adr/008_cups_firmware_upgrade/#generating-signature-keys","text":"The following commands can be used to generate a signature key: openssl ecparam -name prime256v1 -genkey | openssl ec -out sig-0.pem openssl ec -in sig-0.pem -pubout -out sig-0.pub openssl ec -in sig-0.pub -inform PEM -outform DER -pubin | tail -c 64 > sig-0.key","title":"Generating signature keys"},{"location":"adr/008_cups_firmware_upgrade/#calculating-the-crc32-checksum-of-the-signature-key","text":"cat sig-0.key | gzip -1 | tail -c 8 | od -t ${ 1 :- u } 4 -N 4 -An --endian = little | xargs echo > sig-0.crc","title":"Calculating the CRC32 checksum of the signature key"},{"location":"adr/008_cups_firmware_upgrade/#calculating-the-digest-of-a-firmware-upgrade-file","text":"Digest of an upgrade file ( upgrade.sh ) can be calculated using the previously generated signature key with the command: openssl dgst -sha512 -sign sig-0.pem update.sh > update.sh.sig-0.sha512","title":"Calculating the digest of a firmware upgrade file"},{"location":"adr/009_discovery/","text":"009. LoRaWAN Network Server (LNS) discovery Feature : #1480 Authors : Bastian Burger, Daniele Antonio Maggio, Maggie Salak Status : Accepted Service (or LNS) discovery is part of the LNS protocol. When a LoRa Basics Station (LBS) connects for the first time to a LNS, it invokes the service discovery endpoint ( /router-info ). We want to provide the users with the option to (potentially) increase availability by automatically rebalancing connection attempts to different LNS. We can consider implementing the service discovery in two places, because: the LNS discovery endpoint is returned as a response as part of the CUPS protocol the LNS data endpoint is returned as a response of the service discovery endpoint invocation ( /router-info ) we could consider implementing the service discovery as part of either the CUPS protocol or the LNS protocol. Since LBS does not reconnect to the CUPS endpoint when a connection to a LNS is dropped, we are only left with the option of implementing service discovery as part of the LNS service discovery endpoint. This implies that the discovery service needs to support WebSockets. As of now, the /router-info endpoint is part of the LNS itself. Since we want to use it to protect against LNS outages, by definition it becomes clear that discovery needs to be isolated from the LNS and needs to be come a standalone, highly available service. In the following, we propose several properties of the discovery service. Decision We propose to add an ASP.NET Core Web Application to the OSS starter kit that exposes an endpoint for service discovery. The Web App can deployed anywhere (as a highly available cloud service per default, or as an on-premises service for more flexibility). With respect to configuration and health probe, we will implement two simple approaches initially, and expand the functionality in a second stage. In the initial version, we will not implement a health check. We will rely on the fact that if a LBS reconnects to the discovery service, the LNS was not available. By using a round-robin distribution mechanism based on in-memory state, we can guarantee reasonably well that the LBS will be connected to a different LNS in a second attempt. For configuring which LNS a LBS should/can connect to, we are going to tag the LNS twins and station twins with a \"location\" or \"network\" tag. All twins with the same tag are considered to be in the same network and in reach of each other. In a second stage, we will prioritize one of the more advanced health probe strategies and potentially introduce more supported configuration approaches. We will maintain the discovery endpoints on the LNS, to enable the scenario where a user does not want to use the standalone discovery service. Detailed analysis Availability First, we discuss the availability of the discovery service. Even in the presence of failures of a discovery service, there are fallback mechanisms the LBS can use to attempt a direct connection to a LNS it last connected to (via tc-bak/cups-bak files). Still, the service discovery endpoint needs to be as highly available as possible. We can achieve this by choosing a highly available cloud service that acts as the service discovery endpoint. We can delegate the responsibility to the user in case of an on-premises deployment of the discovery service for even more flexibility. An important restriction to consider at this point is that the service needs to support WebSockets. Since WebSockets are not yet supported with Azure Functions , we cannot use them. Configuration Due to the supported deployment models of the OSS starter kit, it is possible that only a subset of all LNS are reachable for a given LBS (due to network boundaries). Users need to configure which LBS can connect to which LNS. We have several, non-mutually exclusive options for this: Name Description Advantages Disadvantages Station twin We can hardcode the set of LNS to which each LBS can connect to in the station twin. - leverages Automatic device management at scale with Azure IoT Hub for configuration - similar strategy to existing configuration strategies (single place for configuration) - Potentially one registry operation per every discovery service request - Complex when not using automatic device management Tags We can rely on registry queries to identify LNS and stations that are in the same network - Simple configuration (via setting a tag) - Need to resolve the LNS DNS/IP based on the query results (need to add it to the LNS module twin/Edge device twin) Environment/configuration file We could statically configure the defined network boundaries as an environment variable/configuration file on the discovery service (e.g. have a JSON structure, which indicates a set of LBS/LNS that are within the same network boundaries) - Simple for developers - Needs a discovery service restart to pick up configuration changes - Configuration is spread out Furthermore, we must decide how to add support for distribution strategies (round-robin, random, or a more complex balancing strategy). These options are not mutually exclusive, but can be supported at the same time. We can start by using a single, simple distribution mechanism (random/round-robin based on in-memory state) and incrementally add support for different distribution strategies. Health checks There are potential approaches on how to detect whether a LNS is alive or not. A simple solution would be to not keep track of the health states of the LNS. If a LBS fails to connect to a LNS, it will query the discovery service again, and we can supply a different LNS (e.g. when using round-robin distribution). If we decide to keep track of the health of each LNS, there are several potential solutions for this: Name Description Advantages Disadvantages Bidirectional connection Bidirectional connection (e.g. WebSocket) is permanently open between the discovery service endpoint and each LNS. - Sensitive to transient connection drops - Not necessarily a good indicator of service health (LNS can be alive but not reach discovery service) D2C message LNS sends a periodic D2C message to indicate that it's still alive - Also tests D2C delivery capabilities - Tests D2C delivery capabilities (potential problems in offline scenario) Module twin status Discovery service relies on IoT Hub module twin for detecting module outages - Reuses the IoT Edge monitoring strategy From docs: he reported properties of a runtime module could be stale if an IoT Edge device gets disconnected from its IoT hub. Ping discovery service Each LNS pings the discovery service on a regular basis to indicate that it's still alive. - Time between crash of LNS and detection of crash State update LNS updates state on a regular basis, which can be queried by the discovery service, e.g. using Azure Storage blob lease management (and lease renewal) - Time between crash of LNS and detection of crash - Complexity Health endpoint on LNS Each LNS has a health-check endpoint, that can be queried by the discovery service - Does not necessarily work for on-premises deployments of LNS No health checks at all The discovery service relies on the implicit knowledge that if an LBS issues another request to the discovery service, the connection to the LNS failed - Simple - Depends on how long the station waits before back-off (and how many LNS are down) - Takes around two minutes (20 seconds per default on LBS 2.0.6) on a concentrator to reconnect to the discovery endpoint if the LNS is unavailable. We should keep in mind that we can also use a combination of the strategies and use an incremental approach again: start with a simple health detection strategy, and allow configuring a different health detection strategy. The selection of a health check strategy should take into account that the longer a LBS takes to connect to a LNS, the more messages are broadcast by the devices and the more messages can be lost. To investigate this further, we ran a spike where we simulated the LNS going down and then recovering after different delays, starting at 10 sec. In our experiment, the leaf device was configured to send unconfirmed messages every 5 sec. We found that in case the downtime was 1 min or shorter, we were able to recover all messages that were broadcasted in the meantime. If the downtime was over 1 min, all messages were lost. As part of the spike we also discovered that after LNS goes down, the LBS (v2.0.5) first tries to reconnect to the data ( router-data ) endpoint for approximately 2 min. The default timeout ( TC_TIMEOUT ) is 60 sec; the longer timeout that we saw in our experiments appears to be related to lower-level TCP timeouts. Only after around 2 min the LBS tries to connect to the discovery ( router-info ) endpoint. After reconnecting to the discovery endpoint, all upstream messages that were sent during the downtime are lost. We opened a bug describing this issue in the Basics Station repository. From the initial response on the bug it is clear that LBS is not expected to deliver messages sent during the downtime after reconnecting to the discovery endpoint. Auth The discovery service needs a certificate that has a chain that is allowed by the same tc.trust as all the LNS it uses for balancing connections. Furthermore, all LNS need to have a chain of trust that contains the tc.trust of all LBS that should support a connection to a given LNS. We will document this restriction. Orthogonal considerations Monitoring and metrics we need for the discovery service (e.g. distribution to different LNS [count], how many LNS deaths we detect, invalid station connection attempt, etc.)","title":"009. LoRaWAN Network Server (LNS) discovery"},{"location":"adr/009_discovery/#009-lorawan-network-server-lns-discovery","text":"Feature : #1480 Authors : Bastian Burger, Daniele Antonio Maggio, Maggie Salak Status : Accepted Service (or LNS) discovery is part of the LNS protocol. When a LoRa Basics Station (LBS) connects for the first time to a LNS, it invokes the service discovery endpoint ( /router-info ). We want to provide the users with the option to (potentially) increase availability by automatically rebalancing connection attempts to different LNS. We can consider implementing the service discovery in two places, because: the LNS discovery endpoint is returned as a response as part of the CUPS protocol the LNS data endpoint is returned as a response of the service discovery endpoint invocation ( /router-info ) we could consider implementing the service discovery as part of either the CUPS protocol or the LNS protocol. Since LBS does not reconnect to the CUPS endpoint when a connection to a LNS is dropped, we are only left with the option of implementing service discovery as part of the LNS service discovery endpoint. This implies that the discovery service needs to support WebSockets. As of now, the /router-info endpoint is part of the LNS itself. Since we want to use it to protect against LNS outages, by definition it becomes clear that discovery needs to be isolated from the LNS and needs to be come a standalone, highly available service. In the following, we propose several properties of the discovery service.","title":"009. LoRaWAN Network Server (LNS) discovery"},{"location":"adr/009_discovery/#decision","text":"We propose to add an ASP.NET Core Web Application to the OSS starter kit that exposes an endpoint for service discovery. The Web App can deployed anywhere (as a highly available cloud service per default, or as an on-premises service for more flexibility). With respect to configuration and health probe, we will implement two simple approaches initially, and expand the functionality in a second stage. In the initial version, we will not implement a health check. We will rely on the fact that if a LBS reconnects to the discovery service, the LNS was not available. By using a round-robin distribution mechanism based on in-memory state, we can guarantee reasonably well that the LBS will be connected to a different LNS in a second attempt. For configuring which LNS a LBS should/can connect to, we are going to tag the LNS twins and station twins with a \"location\" or \"network\" tag. All twins with the same tag are considered to be in the same network and in reach of each other. In a second stage, we will prioritize one of the more advanced health probe strategies and potentially introduce more supported configuration approaches. We will maintain the discovery endpoints on the LNS, to enable the scenario where a user does not want to use the standalone discovery service.","title":"Decision"},{"location":"adr/009_discovery/#detailed-analysis","text":"","title":"Detailed analysis"},{"location":"adr/009_discovery/#availability","text":"First, we discuss the availability of the discovery service. Even in the presence of failures of a discovery service, there are fallback mechanisms the LBS can use to attempt a direct connection to a LNS it last connected to (via tc-bak/cups-bak files). Still, the service discovery endpoint needs to be as highly available as possible. We can achieve this by choosing a highly available cloud service that acts as the service discovery endpoint. We can delegate the responsibility to the user in case of an on-premises deployment of the discovery service for even more flexibility. An important restriction to consider at this point is that the service needs to support WebSockets. Since WebSockets are not yet supported with Azure Functions , we cannot use them.","title":"Availability"},{"location":"adr/009_discovery/#configuration","text":"Due to the supported deployment models of the OSS starter kit, it is possible that only a subset of all LNS are reachable for a given LBS (due to network boundaries). Users need to configure which LBS can connect to which LNS. We have several, non-mutually exclusive options for this: Name Description Advantages Disadvantages Station twin We can hardcode the set of LNS to which each LBS can connect to in the station twin. - leverages Automatic device management at scale with Azure IoT Hub for configuration - similar strategy to existing configuration strategies (single place for configuration) - Potentially one registry operation per every discovery service request - Complex when not using automatic device management Tags We can rely on registry queries to identify LNS and stations that are in the same network - Simple configuration (via setting a tag) - Need to resolve the LNS DNS/IP based on the query results (need to add it to the LNS module twin/Edge device twin) Environment/configuration file We could statically configure the defined network boundaries as an environment variable/configuration file on the discovery service (e.g. have a JSON structure, which indicates a set of LBS/LNS that are within the same network boundaries) - Simple for developers - Needs a discovery service restart to pick up configuration changes - Configuration is spread out Furthermore, we must decide how to add support for distribution strategies (round-robin, random, or a more complex balancing strategy). These options are not mutually exclusive, but can be supported at the same time. We can start by using a single, simple distribution mechanism (random/round-robin based on in-memory state) and incrementally add support for different distribution strategies.","title":"Configuration"},{"location":"adr/009_discovery/#health-checks","text":"There are potential approaches on how to detect whether a LNS is alive or not. A simple solution would be to not keep track of the health states of the LNS. If a LBS fails to connect to a LNS, it will query the discovery service again, and we can supply a different LNS (e.g. when using round-robin distribution). If we decide to keep track of the health of each LNS, there are several potential solutions for this: Name Description Advantages Disadvantages Bidirectional connection Bidirectional connection (e.g. WebSocket) is permanently open between the discovery service endpoint and each LNS. - Sensitive to transient connection drops - Not necessarily a good indicator of service health (LNS can be alive but not reach discovery service) D2C message LNS sends a periodic D2C message to indicate that it's still alive - Also tests D2C delivery capabilities - Tests D2C delivery capabilities (potential problems in offline scenario) Module twin status Discovery service relies on IoT Hub module twin for detecting module outages - Reuses the IoT Edge monitoring strategy From docs: he reported properties of a runtime module could be stale if an IoT Edge device gets disconnected from its IoT hub. Ping discovery service Each LNS pings the discovery service on a regular basis to indicate that it's still alive. - Time between crash of LNS and detection of crash State update LNS updates state on a regular basis, which can be queried by the discovery service, e.g. using Azure Storage blob lease management (and lease renewal) - Time between crash of LNS and detection of crash - Complexity Health endpoint on LNS Each LNS has a health-check endpoint, that can be queried by the discovery service - Does not necessarily work for on-premises deployments of LNS No health checks at all The discovery service relies on the implicit knowledge that if an LBS issues another request to the discovery service, the connection to the LNS failed - Simple - Depends on how long the station waits before back-off (and how many LNS are down) - Takes around two minutes (20 seconds per default on LBS 2.0.6) on a concentrator to reconnect to the discovery endpoint if the LNS is unavailable. We should keep in mind that we can also use a combination of the strategies and use an incremental approach again: start with a simple health detection strategy, and allow configuring a different health detection strategy. The selection of a health check strategy should take into account that the longer a LBS takes to connect to a LNS, the more messages are broadcast by the devices and the more messages can be lost. To investigate this further, we ran a spike where we simulated the LNS going down and then recovering after different delays, starting at 10 sec. In our experiment, the leaf device was configured to send unconfirmed messages every 5 sec. We found that in case the downtime was 1 min or shorter, we were able to recover all messages that were broadcasted in the meantime. If the downtime was over 1 min, all messages were lost. As part of the spike we also discovered that after LNS goes down, the LBS (v2.0.5) first tries to reconnect to the data ( router-data ) endpoint for approximately 2 min. The default timeout ( TC_TIMEOUT ) is 60 sec; the longer timeout that we saw in our experiments appears to be related to lower-level TCP timeouts. Only after around 2 min the LBS tries to connect to the discovery ( router-info ) endpoint. After reconnecting to the discovery endpoint, all upstream messages that were sent during the downtime are lost. We opened a bug describing this issue in the Basics Station repository. From the initial response on the bug it is clear that LBS is not expected to deliver messages sent during the downtime after reconnecting to the discovery endpoint.","title":"Health checks"},{"location":"adr/009_discovery/#auth","text":"The discovery service needs a certificate that has a chain that is allowed by the same tc.trust as all the LNS it uses for balancing connections. Furthermore, all LNS need to have a chain of trust that contains the tc.trust of all LBS that should support a connection to a given LNS. We will document this restriction.","title":"Auth"},{"location":"adr/009_discovery/#orthogonal-considerations","text":"Monitoring and metrics we need for the discovery service (e.g. distribution to different LNS [count], how many LNS deaths we detect, invalid station connection attempt, etc.)","title":"Orthogonal considerations"},{"location":"adr/010_lns_affinity/","text":"010. LNS sticky affinity over multiple sessions Feature : #1475 Authors : Spyros Giannakakis, Daniele Antonio Maggio, Patrick Schuler Status : Accepted Problem statement Consider the topology: flowchart LR; Device-->LBS1-->LNS1--1-->IoTHub; Device-->LBS2-->LNS2--2-->IoTHub; IoT Hub limits active connections that an IoT device can have to one. Assuming that connection 1 is already open and a message from LNS2 arrives, IoT Hub will close connection 1 and open connection 2. Edge Hub on LNS1, will detect this and assume it's a transient network issue, therefore will try proactively to reconnect to IoT Hub. IoT Hub will now drop the connection 2 to re-establish the original connection 1. This connection \"ping-pong\" will continue happening, negatively impacting the scalability due to the high costs of setting up/disposing the connections. From our load tests we observed that in this scenario we were not even able to connect more than 120 devices to two LNSs, while in a single LNS topology we could scale up to 900 devices without issues. Out of scope Deduplication strategies Mark and None: these strategies rely on multiple LNSs sending message. Potentially we could consider other workarounds for the IoT Hub limitation of a single connection per device but we find it acceptable for the Mark and None strategies to not be as scalable as the Drop strategy and will only document this limitation for potential users to be aware of. LNS performs operations on behalf of a device/sensor and a concentrator/station. However since a concentrator can be connected to at most one LNS, there is no ping-pong happening with operations on stations. In-scope The problem can be manifested whenever we do operations against Iot Hub on behalf of edge devices. These can be: Twin reads Twin writes (updates/deletes) D2C messages C2D messages Roaming leaf devices (that potentially become out-of-range from an LNS) are kept in scope. Downstream messages for Class C devices via Direct Method Problematic IoT Hub operations on behalf of edge devices Background tasks Periodically we refresh the LoRaDeviceCache, which results in device twin reads that could switch the connection -> see handling of background tasks section Message flows Join -> see handling of Join requests section Data: if the device is not in LoRaDeviceCache, we fetch the device twin -> see main data flow section assuming we have the device twin (in the cache or fetched) in the main data flow we send upstream, downstream and write the new twin -> see main data flow section if a frame counter reset happened, we update the twin immediately -> see handling of resets section C2D message via Direct method -> see handling class C downstream messages section Version, LNS discovery and CUPS update endpoints are not affected by this issue. Solution The main idea is to give the current connection holder (as indicated from the Function), the edge to continue processing messages for this device. The performance of that gateway will not be impacted. The information whether the current LNS is the connection owner is stored locally. The LNS that is the connection owner will keep the connection open. Any other network servers receiving messages, will not maintain an active connection to IoT Hub. If the owning network server stops responding or gets out of reach, the ownership is transferred to the next winning network server. Handling of cache refresh When we create the (singleton) instance of the NetworkServer.LoRaDeviceCache, we start a background periodical task to ensure the device twins for all the devices that connected to that LNS are kept fresh. In the case where we need to get a device twin, this could trigger a connection ping-pong. Decision The preferred option for now is to refresh the twin and close the connection immediately. This could result in a connection switch but not a permanent connection ping pong. This will be revisited with either this issue about the frame counter drift (one of the solutions there is to fetch twin and close connection immediately) or this issue specific to cache refresh Alternatives Check against the local store whether we are the owning gateway. If we are, refresh the twin (and keep the connection open). If we are not: We adjust the LastSeen property but not actually refresh the entry in the cache. When the next data message for this devices comes in and an entry is in cache for such device, in the event that the Azure Function is marking our LNS as the new \"winning\" gateway, we have a stale twin in the cache that needs to be updated before validating the request (see main data flow ). Alternatively, we remove the device entry from the cache. This idea is discarded because if we were to do this, a \"get twin\" operation would be triggered as soon as the next data message is coming in from the device in question (for the resolution of devAddr). Handling of Join requests Join requests in isolation currently do not have the connection stealing issue, as they already rely on the Function for the DevNonce check. If the current LNS is not the preferred gateway, it drops the message immediately. Problem Join received from LNS1 and LNS2: LNS1 wins First data message received only on LNS2, Function should inform LNS1 that it's the losing one (information about the owning LNS needs to be \"shared\" between joins and data messages). Decision We decide to go with the simpler solution of closing the connection immediately after a Join and let the data flow re-establish it if needs to be. Disadvantage is that the first data message is more likely to miss the window due to having re-establish the connection. LNS also stores locally that it was the losing LNS and delays on a future re-join or future data messages. Alternative Do nothing and accept that a one-off connection stealing on the first Data message can happen. We do not close the connection after a Join. When the first data message arrives the Function checks somehow the preferred gateway for this device when it joined: if the data message comes from the same gateway it is allowed to process the message. If not, we should inform the previously owning LNS to drop the connection and allow the new LNS to process the message. This was not preferred as it has more complexity for unclear results. Main data message flow Currently, if LoRaDevice is not in the LNS cache, we search on the Function for all devices that have that DevAddr. Then we get all their twins which could result in a connection switch. Decision After loading all the twins for the LoRaDevice(s), we close the connections immediately. This is equivalent to how we handle Join requests and background cache tasks . Alternative Currently the DeviceGetter.GetDevice returns a list of devices that match the provided DevAddr. We considered changing the Function to return a single device instead of a list and only load the twin for this one on the LNS side. For this the Function should perform the Mic computation which means that we would need to send the payload to the cloud. This is a deal breaker for us. Further processing This section uses this topology: flowchart LR; Device-->LBS1-->LNS1-->Function; Device-->LBS2-->LNS2-->Function; LNS1-->IoTHub; LNS2-->IoTHub; where Device sends data message A and then B. Here is a rundown of what should happen assuming both LNSs have a fresh twin (via background refresh or via fetching it using DeviceGetter.GetDevice). Changes are marked in bold : Device sends first data message A. We assume that LNS1 gets the message first. LNS1 checks against its in-memory state and since an owner for the device connection was not elected yet, directly contacts the function without delay. The Function hasn't seen this DevEui either and therefore does not have an assigned LNS for it yet. LNS1 wins the race and gets immediately a response and processes the message upstream. LNS2 eventually receives message A, checks its local state and also contacts the Function immediately since it does not have prior info about this device. The Function responds to LNS2 that it lost the race to process this message. Since deduplication strategy is Drop, LNS2 drops the message immediately, therefore no connection to Iot Hub is opened and only LNS1 has the connection to Iot Hub. LNS2 updates its in memory state that it does not own the connection for this device . When message B gets send (with a higher frame counter ), assuming that this time LNS2 gets it first, it checks again its local state that indicates it's not owning the connection for the device and therefore delays itself X ms before contacting the Function *. Here we do not want to simply drop the message as LNS1 might not be available anymore (due to a crash, device not in range etc). This delay gives LNS1 a time advantage to reach the Function first and win the race again, failing back to the previous case of message A. The active connection stays with LNS1. If this delay is not sufficient for LNS1 to win the race, LNS2 will contact the Function which now awards LNS2 as the \"winning\" LNS. LNS2 can now process the message upstream. It also removes the \"losing flag\" from its in-memory store . The Function also proactively informs LNS1 that it's not anymore the winning LNS for this device. - The reason why we do this is to ensure that LNS1 knows that the connection ownership was transferred to another network server and it should drop the connection. This is for the case, where the upstream message does not reach LNS1 e.g. when the leaf device is not in its range any more. - For that we will use a Direct Method call to the LNS module, since modules do not yet support C2D messages . If LNS1 in the meantime gets message B and contacts the Function, it will let it know that it lost the race for this frame counter and must therefore drop the message, mark itself as the losing LNS and close the connection if it hasn't done so yet . Notes: The Function is not called in certain topologies e.g. when multiple LBSs are connected to the same LNS but these topologies are not relevant for the issue here as they employ a single connection per device by design). For the main flow above we consider only frame counter B > frame counter A. Resets are covered in the reset section . Resubmits (when frame counter B == frame counter A) are also a current issue and should be addressed in this issue . Handling of ABP relax frame counter reset A special case on the main data flow is when we detect a device reset after a message. Currently we save the twin immediately and then clear the Function cache. This twin write could result in a connection ping-pong. Decision We should first clear the cache in the Function. The Function is changed to return if we are the losing LNS. If we are the losing one, we drop the message here, mark ourselves as the losing gateway etc. Otherwise we process message normally and at the end update the twin as we currently do. Alternative Use the Function to do both operations: idea was discarded because of a connection switch update the device twin frame counter to 0. As frame counter is a reported property it needs to be changed via a DeviceClient that would cause a connection switch. Clear or update the cache entry with frame counter down and up to 0. Returns the result to the LNS: whether it was the winning or losing one LNS reacts as described in the main data flow section Handling Class C downstream messages For class C devices we can send C2D messages using a Direct Method that could (one-off) steal the active connection. When the Direct method is invoked via the portal on an LNS, we should check if we are the connection holder for that device and if not drop the message. Should we delay on the LNS itself or on the Function? We considered using a delay on the Function rather than on the LNS itself. We decided against this approach because of the following disadvantages: Observability: potentially we are messing up the measurements of the Function duration for the LNSs that are not owning the connection. Could be documented/worked-around. Keeps the HTTP connection between the LNS-Function open for more time. For the sake of completeness a scenario when it's better that the Function implements the delay is the following: LNS1 is the preferred LNS. LNS2 is out of range. LNS2 becomes in range and receives a message with a higher frame counter. It does not know that its not the winning LNS and contacts immediately the Function. The Function awards it the winning LNS and LNS1 loses the connection without having a chance to keep it. LNS2 would need to fetch the device twin so it is likely to lose the race to LNS1 but even if it does not we accept the possibility that there is potentially a one-off connection switch (but not a ping pong because LNS1 will stop retrying). A potential advantage of delaying on the LNS is that we can dynamically (based on how long we took in previous steps) choose the delay amount before contacting the Function, so that we have higher chances of not missing the window. Delay amount configuration The delay amount should be configurable to allow users to customize behavior for their scenarios. During load testing we tested with 400ms but smaller values should be tried as well. If 0ms are specified the stickiness feature is disabled which means potential connection switching. Other candidates considered Using direct mode (not Edge hub) Using direct mode is less problematic in terms of connection stealing but still had the issue. The idea was dropped because then we would miss the offline capabilities that Edge Hub offers us. Parent-child gateways We could utilize child-parent connections and parent multiple LNS under a single transparent gateway that has the active connection to IoT Hub. The problem there is that children can have only 1 parent and therefore we can not support roaming leaf devices that connect to different LNSs over time. Related changes Single point of connection handling on LoRaDevice Using a single device queue would also ensure by design that new code does not open more connections to IoT Hub accidentally. Independently of the resolution of the aforementioned issue, the changes on the Function side are still required.","title":"010. LNS sticky affinity over multiple sessions"},{"location":"adr/010_lns_affinity/#010-lns-sticky-affinity-over-multiple-sessions","text":"Feature : #1475 Authors : Spyros Giannakakis, Daniele Antonio Maggio, Patrick Schuler Status : Accepted","title":"010. LNS sticky affinity over multiple sessions"},{"location":"adr/010_lns_affinity/#problem-statement","text":"Consider the topology: flowchart LR; Device-->LBS1-->LNS1--1-->IoTHub; Device-->LBS2-->LNS2--2-->IoTHub; IoT Hub limits active connections that an IoT device can have to one. Assuming that connection 1 is already open and a message from LNS2 arrives, IoT Hub will close connection 1 and open connection 2. Edge Hub on LNS1, will detect this and assume it's a transient network issue, therefore will try proactively to reconnect to IoT Hub. IoT Hub will now drop the connection 2 to re-establish the original connection 1. This connection \"ping-pong\" will continue happening, negatively impacting the scalability due to the high costs of setting up/disposing the connections. From our load tests we observed that in this scenario we were not even able to connect more than 120 devices to two LNSs, while in a single LNS topology we could scale up to 900 devices without issues.","title":"Problem statement"},{"location":"adr/010_lns_affinity/#out-of-scope","text":"Deduplication strategies Mark and None: these strategies rely on multiple LNSs sending message. Potentially we could consider other workarounds for the IoT Hub limitation of a single connection per device but we find it acceptable for the Mark and None strategies to not be as scalable as the Drop strategy and will only document this limitation for potential users to be aware of. LNS performs operations on behalf of a device/sensor and a concentrator/station. However since a concentrator can be connected to at most one LNS, there is no ping-pong happening with operations on stations.","title":"Out of scope"},{"location":"adr/010_lns_affinity/#in-scope","text":"The problem can be manifested whenever we do operations against Iot Hub on behalf of edge devices. These can be: Twin reads Twin writes (updates/deletes) D2C messages C2D messages Roaming leaf devices (that potentially become out-of-range from an LNS) are kept in scope. Downstream messages for Class C devices via Direct Method","title":"In-scope"},{"location":"adr/010_lns_affinity/#problematic-iot-hub-operations-on-behalf-of-edge-devices","text":"Background tasks Periodically we refresh the LoRaDeviceCache, which results in device twin reads that could switch the connection -> see handling of background tasks section Message flows Join -> see handling of Join requests section Data: if the device is not in LoRaDeviceCache, we fetch the device twin -> see main data flow section assuming we have the device twin (in the cache or fetched) in the main data flow we send upstream, downstream and write the new twin -> see main data flow section if a frame counter reset happened, we update the twin immediately -> see handling of resets section C2D message via Direct method -> see handling class C downstream messages section Version, LNS discovery and CUPS update endpoints are not affected by this issue.","title":"Problematic IoT Hub operations on behalf of edge devices"},{"location":"adr/010_lns_affinity/#solution","text":"The main idea is to give the current connection holder (as indicated from the Function), the edge to continue processing messages for this device. The performance of that gateway will not be impacted. The information whether the current LNS is the connection owner is stored locally. The LNS that is the connection owner will keep the connection open. Any other network servers receiving messages, will not maintain an active connection to IoT Hub. If the owning network server stops responding or gets out of reach, the ownership is transferred to the next winning network server.","title":"Solution"},{"location":"adr/010_lns_affinity/#handling-of-cache-refresh","text":"When we create the (singleton) instance of the NetworkServer.LoRaDeviceCache, we start a background periodical task to ensure the device twins for all the devices that connected to that LNS are kept fresh. In the case where we need to get a device twin, this could trigger a connection ping-pong.","title":"Handling of cache refresh"},{"location":"adr/010_lns_affinity/#decision","text":"The preferred option for now is to refresh the twin and close the connection immediately. This could result in a connection switch but not a permanent connection ping pong. This will be revisited with either this issue about the frame counter drift (one of the solutions there is to fetch twin and close connection immediately) or this issue specific to cache refresh","title":"Decision"},{"location":"adr/010_lns_affinity/#alternatives","text":"Check against the local store whether we are the owning gateway. If we are, refresh the twin (and keep the connection open). If we are not: We adjust the LastSeen property but not actually refresh the entry in the cache. When the next data message for this devices comes in and an entry is in cache for such device, in the event that the Azure Function is marking our LNS as the new \"winning\" gateway, we have a stale twin in the cache that needs to be updated before validating the request (see main data flow ). Alternatively, we remove the device entry from the cache. This idea is discarded because if we were to do this, a \"get twin\" operation would be triggered as soon as the next data message is coming in from the device in question (for the resolution of devAddr).","title":"Alternatives"},{"location":"adr/010_lns_affinity/#handling-of-join-requests","text":"Join requests in isolation currently do not have the connection stealing issue, as they already rely on the Function for the DevNonce check. If the current LNS is not the preferred gateway, it drops the message immediately. Problem Join received from LNS1 and LNS2: LNS1 wins First data message received only on LNS2, Function should inform LNS1 that it's the losing one (information about the owning LNS needs to be \"shared\" between joins and data messages).","title":"Handling of Join requests"},{"location":"adr/010_lns_affinity/#decision_1","text":"We decide to go with the simpler solution of closing the connection immediately after a Join and let the data flow re-establish it if needs to be. Disadvantage is that the first data message is more likely to miss the window due to having re-establish the connection. LNS also stores locally that it was the losing LNS and delays on a future re-join or future data messages.","title":"Decision"},{"location":"adr/010_lns_affinity/#alternative","text":"Do nothing and accept that a one-off connection stealing on the first Data message can happen. We do not close the connection after a Join. When the first data message arrives the Function checks somehow the preferred gateway for this device when it joined: if the data message comes from the same gateway it is allowed to process the message. If not, we should inform the previously owning LNS to drop the connection and allow the new LNS to process the message. This was not preferred as it has more complexity for unclear results.","title":"Alternative"},{"location":"adr/010_lns_affinity/#main-data-message-flow","text":"Currently, if LoRaDevice is not in the LNS cache, we search on the Function for all devices that have that DevAddr. Then we get all their twins which could result in a connection switch.","title":"Main data message flow"},{"location":"adr/010_lns_affinity/#decision_2","text":"After loading all the twins for the LoRaDevice(s), we close the connections immediately. This is equivalent to how we handle Join requests and background cache tasks .","title":"Decision"},{"location":"adr/010_lns_affinity/#alternative_1","text":"Currently the DeviceGetter.GetDevice returns a list of devices that match the provided DevAddr. We considered changing the Function to return a single device instead of a list and only load the twin for this one on the LNS side. For this the Function should perform the Mic computation which means that we would need to send the payload to the cloud. This is a deal breaker for us.","title":"Alternative"},{"location":"adr/010_lns_affinity/#further-processing","text":"This section uses this topology: flowchart LR; Device-->LBS1-->LNS1-->Function; Device-->LBS2-->LNS2-->Function; LNS1-->IoTHub; LNS2-->IoTHub; where Device sends data message A and then B. Here is a rundown of what should happen assuming both LNSs have a fresh twin (via background refresh or via fetching it using DeviceGetter.GetDevice). Changes are marked in bold : Device sends first data message A. We assume that LNS1 gets the message first. LNS1 checks against its in-memory state and since an owner for the device connection was not elected yet, directly contacts the function without delay. The Function hasn't seen this DevEui either and therefore does not have an assigned LNS for it yet. LNS1 wins the race and gets immediately a response and processes the message upstream. LNS2 eventually receives message A, checks its local state and also contacts the Function immediately since it does not have prior info about this device. The Function responds to LNS2 that it lost the race to process this message. Since deduplication strategy is Drop, LNS2 drops the message immediately, therefore no connection to Iot Hub is opened and only LNS1 has the connection to Iot Hub. LNS2 updates its in memory state that it does not own the connection for this device . When message B gets send (with a higher frame counter ), assuming that this time LNS2 gets it first, it checks again its local state that indicates it's not owning the connection for the device and therefore delays itself X ms before contacting the Function *. Here we do not want to simply drop the message as LNS1 might not be available anymore (due to a crash, device not in range etc). This delay gives LNS1 a time advantage to reach the Function first and win the race again, failing back to the previous case of message A. The active connection stays with LNS1. If this delay is not sufficient for LNS1 to win the race, LNS2 will contact the Function which now awards LNS2 as the \"winning\" LNS. LNS2 can now process the message upstream. It also removes the \"losing flag\" from its in-memory store . The Function also proactively informs LNS1 that it's not anymore the winning LNS for this device. - The reason why we do this is to ensure that LNS1 knows that the connection ownership was transferred to another network server and it should drop the connection. This is for the case, where the upstream message does not reach LNS1 e.g. when the leaf device is not in its range any more. - For that we will use a Direct Method call to the LNS module, since modules do not yet support C2D messages . If LNS1 in the meantime gets message B and contacts the Function, it will let it know that it lost the race for this frame counter and must therefore drop the message, mark itself as the losing LNS and close the connection if it hasn't done so yet . Notes: The Function is not called in certain topologies e.g. when multiple LBSs are connected to the same LNS but these topologies are not relevant for the issue here as they employ a single connection per device by design). For the main flow above we consider only frame counter B > frame counter A. Resets are covered in the reset section . Resubmits (when frame counter B == frame counter A) are also a current issue and should be addressed in this issue .","title":"Further processing"},{"location":"adr/010_lns_affinity/#handling-of-abp-relax-frame-counter-reset","text":"A special case on the main data flow is when we detect a device reset after a message. Currently we save the twin immediately and then clear the Function cache. This twin write could result in a connection ping-pong.","title":"Handling of ABP relax frame counter reset"},{"location":"adr/010_lns_affinity/#decision_3","text":"We should first clear the cache in the Function. The Function is changed to return if we are the losing LNS. If we are the losing one, we drop the message here, mark ourselves as the losing gateway etc. Otherwise we process message normally and at the end update the twin as we currently do.","title":"Decision"},{"location":"adr/010_lns_affinity/#alternative_2","text":"Use the Function to do both operations: idea was discarded because of a connection switch update the device twin frame counter to 0. As frame counter is a reported property it needs to be changed via a DeviceClient that would cause a connection switch. Clear or update the cache entry with frame counter down and up to 0. Returns the result to the LNS: whether it was the winning or losing one LNS reacts as described in the main data flow section","title":"Alternative"},{"location":"adr/010_lns_affinity/#handling-class-c-downstream-messages","text":"For class C devices we can send C2D messages using a Direct Method that could (one-off) steal the active connection. When the Direct method is invoked via the portal on an LNS, we should check if we are the connection holder for that device and if not drop the message.","title":"Handling Class C downstream messages"},{"location":"adr/010_lns_affinity/#should-we-delay-on-the-lns-itself-or-on-the-function","text":"We considered using a delay on the Function rather than on the LNS itself. We decided against this approach because of the following disadvantages: Observability: potentially we are messing up the measurements of the Function duration for the LNSs that are not owning the connection. Could be documented/worked-around. Keeps the HTTP connection between the LNS-Function open for more time. For the sake of completeness a scenario when it's better that the Function implements the delay is the following: LNS1 is the preferred LNS. LNS2 is out of range. LNS2 becomes in range and receives a message with a higher frame counter. It does not know that its not the winning LNS and contacts immediately the Function. The Function awards it the winning LNS and LNS1 loses the connection without having a chance to keep it. LNS2 would need to fetch the device twin so it is likely to lose the race to LNS1 but even if it does not we accept the possibility that there is potentially a one-off connection switch (but not a ping pong because LNS1 will stop retrying). A potential advantage of delaying on the LNS is that we can dynamically (based on how long we took in previous steps) choose the delay amount before contacting the Function, so that we have higher chances of not missing the window.","title":"Should we delay on the LNS itself or on the Function?"},{"location":"adr/010_lns_affinity/#delay-amount-configuration","text":"The delay amount should be configurable to allow users to customize behavior for their scenarios. During load testing we tested with 400ms but smaller values should be tried as well. If 0ms are specified the stickiness feature is disabled which means potential connection switching.","title":"Delay amount configuration"},{"location":"adr/010_lns_affinity/#other-candidates-considered","text":"","title":"Other candidates considered"},{"location":"adr/010_lns_affinity/#using-direct-mode-not-edge-hub","text":"Using direct mode is less problematic in terms of connection stealing but still had the issue. The idea was dropped because then we would miss the offline capabilities that Edge Hub offers us.","title":"Using direct mode (not Edge hub)"},{"location":"adr/010_lns_affinity/#parent-child-gateways","text":"We could utilize child-parent connections and parent multiple LNS under a single transparent gateway that has the active connection to IoT Hub. The problem there is that children can have only 1 parent and therefore we can not support roaming leaf devices that connect to different LNSs over time.","title":"Parent-child gateways"},{"location":"adr/010_lns_affinity/#related-changes","text":"","title":"Related changes"},{"location":"adr/010_lns_affinity/#single-point-of-connection-handling-on-loradevice","text":"Using a single device queue would also ensure by design that new code does not open more connections to IoT Hub accidentally. Independently of the resolution of the aforementioned issue, the changes on the Function side are still required.","title":"Single point of connection handling on LoRaDevice"},{"location":"adr/011_device_request_queue/","text":"011. Device Request Queue Feature : #1479 Authors : Atif Aziz Status : Accepted Context LoRa devices, which can reach multiple LNSs, pose an interesting challenge for Edge Hub since Edge Hub wasn't designed for devices competing for gateways. When a device connection is made to IoT Hub, Edge Hub continues to maintain that connection in the open state (for network resiliency) until explicitly closed. Moreover, IoT Hub allows maintining only a single connection per device. When another is opened, the existing one is closed. If a device can reach multiple LNSs then Edge Hub and IoT Hub begin an aggressive ping-pong of connections being opened and closed. In other words, as each LNS or Edge Hub tries to open a connection for the same device, IoT Hub closes the connection for the other. But then the other tries to re-open the connection and the ping-pong continues. This problem needs addressing to avoid scalability limitations. The ping-pong can be prevented by electing a leader LNS for a device through the function race determination and as a fallback announcing the decision to others using a C2D message. An LNS receiving such a message will then close that connection so that Edge Hub doesn't continue to maintain the connection in the open state through retires. The handling of the message needs to know: It can close the connection right now, without interfering with a currently running operation, such as a message delivery where the message could be potentially dropped. There are no operations starting around the same time that would cause it to be opened again. The following cases can trigger operations from different threads: An OTAA join message; DeviceJoinLoader eventually loads the twins and stores them back up. A data message; DeviceLoaderSynchronizer loads the twins for multiple devices based on the DevAddr and adds them to the cache. C2D message for a class C device that needs to be delivered can trigger a load if the device is not in the cache. Cache refreshes can happen on a background thread for a device, causing the need for a connection. There are a number of complex and concurrent code paths in the current solution that make it hard to reason about when a device connection is in use, when it's safe to open/close without affecting another operation in flight and how various device-related operations (such as refreshing from the twin) can work in isolation, deterministically and without race conditions. If a single queue could be maintained for all device-related operations then it would become easier to order those operations, reason about them and make they don't cause connections to be opened when an LNS has lost the race against another. Several approaches were explored to understand the overall impact of refactoring, whether the changes to the current code base and design would be large or small and worth the benefits they bring. The approaches explored can be summed up as follows: Add a queue to LoRaDevice for all device-related operations. There is one that exists today but it is used to service uplink data requests only. The idea would be to extend it to encompass all other requests and operations. Turn the LNS implementation to be (logically) single-threaded so that not only does it make it easier to reason about the code (except perhaps with regards to re-entrancy), but it also enables use of very simple data structures without the need for locking. This is possible because the bulk of LNS is I/O bound. There is practically no CPU-intensive code that executes between each await. Simplify the entire flow and processing of a message into a simple request-response model that can be manipulated and reasoned about much more easily. That is, all methods receiving and processing a LoRaRequest return Task<DownlinkMessage> instead of void or Task . This allows all Task.Run uses to be moved to a single and central point when a message is received instead of being littered throughout the code base. The main message loop could also be made responsible for central error-handling/logging and sending of downlink messages when the processing of a request has completed. This would just require regular use of tasks. Next, all Task -based operations on LoRaDevice could be naturally and implicitly queued and then executed in a mutually exclusive manner. Decision All operations for a particular device requiring the IoT Hub connection are to be executed in a serial/exclusive fashion on the LoRaDevice itself. This will ensure that there is only one operation acting on the connection at any given time. Making each execution exclusive (think queue) gives a deterministic way of adding a close operation without affecting any other operations that may be in flight. Unfortunately, the initialization of a LoRaDevice cannot be addressed with the same approach since it requires a two-step initialization per its current design. That is, a LoRaDevice is minimally initialized when created so its InitializeAsync method can be called to fetch the twin information. Until that completes, a LoRaDevice is not considered technically ready for being put in the cache. Since a LoRaDevice cannot be discovered during its initialization, it cannot be synchronized with the other operations. To work around this, load operations will be synchronized in the LoRaDeviceRegistry to ensure there is only ever one operation loading the twins for a particular DevEUI. It was also decided that closing the connection after initialization is the easiest approach to delay the connection ownership decision to after the arrival of the first message. The approach to simplify the entire flow and processing of a message into a simple request-response model will be taken as a stretch goal so that the connection management can be implemented and tested earlier. A quick spike demonstrated that the changes to the main code base would be fairly contained and the largest impact is expected to be in adapting the tests (which could also be done with a stop-gap measure where the tests are adapted after the initial refactoring of the code base). Based on a spike of the changes the simple request-response model would require, it seems plausible to achieve the refactoring within (at most) two weekly sprints. It is expected that the bulk of the time will be spent in refactoring the test code. Consequences The chosen approach has the following benefits: Single use of Task.Run in LnsProtocolMessageProcessor . This reduces the number execution forks to consider as well as chances of exceptions going unobserved. Removes many abstractions like ILoRaDeviceRequestQueue and IMessageDispatcher , implementations like DeviceLoaderSynchronizer and ExternalGatewayLoRaRequestQueue , and potentially more. Easier to reason about the overall message flow. Use of the regular async-await programming model, including error-handling and cancellation that's built-in into tasks. Transparent use of queues through tasks in LoRaDevice to serialize execution. This subsumes the first approach (discussed in the introductory section) by having implicit rather explicit queuing (at the application-level). Greatest potential to simplify tests since assertions can rely on simply return values and exceptions, instead of success/failure notifications. It is not mutually exclusive with other approaches explored. For example, by simplifying to the request-response model, it would be even easier to have the LNS operate with a single logical thread if that could further help remove some complexity (without compromising scalability) like locks. The absence of an explicit queue could be make it more difficult for someone to understand the code and choices made if they are not familiar with the intricacies of how async-await operates.","title":"011. Device Request Queue"},{"location":"adr/011_device_request_queue/#011-device-request-queue","text":"Feature : #1479 Authors : Atif Aziz Status : Accepted","title":"011. Device Request Queue"},{"location":"adr/011_device_request_queue/#context","text":"LoRa devices, which can reach multiple LNSs, pose an interesting challenge for Edge Hub since Edge Hub wasn't designed for devices competing for gateways. When a device connection is made to IoT Hub, Edge Hub continues to maintain that connection in the open state (for network resiliency) until explicitly closed. Moreover, IoT Hub allows maintining only a single connection per device. When another is opened, the existing one is closed. If a device can reach multiple LNSs then Edge Hub and IoT Hub begin an aggressive ping-pong of connections being opened and closed. In other words, as each LNS or Edge Hub tries to open a connection for the same device, IoT Hub closes the connection for the other. But then the other tries to re-open the connection and the ping-pong continues. This problem needs addressing to avoid scalability limitations. The ping-pong can be prevented by electing a leader LNS for a device through the function race determination and as a fallback announcing the decision to others using a C2D message. An LNS receiving such a message will then close that connection so that Edge Hub doesn't continue to maintain the connection in the open state through retires. The handling of the message needs to know: It can close the connection right now, without interfering with a currently running operation, such as a message delivery where the message could be potentially dropped. There are no operations starting around the same time that would cause it to be opened again. The following cases can trigger operations from different threads: An OTAA join message; DeviceJoinLoader eventually loads the twins and stores them back up. A data message; DeviceLoaderSynchronizer loads the twins for multiple devices based on the DevAddr and adds them to the cache. C2D message for a class C device that needs to be delivered can trigger a load if the device is not in the cache. Cache refreshes can happen on a background thread for a device, causing the need for a connection. There are a number of complex and concurrent code paths in the current solution that make it hard to reason about when a device connection is in use, when it's safe to open/close without affecting another operation in flight and how various device-related operations (such as refreshing from the twin) can work in isolation, deterministically and without race conditions. If a single queue could be maintained for all device-related operations then it would become easier to order those operations, reason about them and make they don't cause connections to be opened when an LNS has lost the race against another. Several approaches were explored to understand the overall impact of refactoring, whether the changes to the current code base and design would be large or small and worth the benefits they bring. The approaches explored can be summed up as follows: Add a queue to LoRaDevice for all device-related operations. There is one that exists today but it is used to service uplink data requests only. The idea would be to extend it to encompass all other requests and operations. Turn the LNS implementation to be (logically) single-threaded so that not only does it make it easier to reason about the code (except perhaps with regards to re-entrancy), but it also enables use of very simple data structures without the need for locking. This is possible because the bulk of LNS is I/O bound. There is practically no CPU-intensive code that executes between each await. Simplify the entire flow and processing of a message into a simple request-response model that can be manipulated and reasoned about much more easily. That is, all methods receiving and processing a LoRaRequest return Task<DownlinkMessage> instead of void or Task . This allows all Task.Run uses to be moved to a single and central point when a message is received instead of being littered throughout the code base. The main message loop could also be made responsible for central error-handling/logging and sending of downlink messages when the processing of a request has completed. This would just require regular use of tasks. Next, all Task -based operations on LoRaDevice could be naturally and implicitly queued and then executed in a mutually exclusive manner.","title":"Context"},{"location":"adr/011_device_request_queue/#decision","text":"All operations for a particular device requiring the IoT Hub connection are to be executed in a serial/exclusive fashion on the LoRaDevice itself. This will ensure that there is only one operation acting on the connection at any given time. Making each execution exclusive (think queue) gives a deterministic way of adding a close operation without affecting any other operations that may be in flight. Unfortunately, the initialization of a LoRaDevice cannot be addressed with the same approach since it requires a two-step initialization per its current design. That is, a LoRaDevice is minimally initialized when created so its InitializeAsync method can be called to fetch the twin information. Until that completes, a LoRaDevice is not considered technically ready for being put in the cache. Since a LoRaDevice cannot be discovered during its initialization, it cannot be synchronized with the other operations. To work around this, load operations will be synchronized in the LoRaDeviceRegistry to ensure there is only ever one operation loading the twins for a particular DevEUI. It was also decided that closing the connection after initialization is the easiest approach to delay the connection ownership decision to after the arrival of the first message. The approach to simplify the entire flow and processing of a message into a simple request-response model will be taken as a stretch goal so that the connection management can be implemented and tested earlier. A quick spike demonstrated that the changes to the main code base would be fairly contained and the largest impact is expected to be in adapting the tests (which could also be done with a stop-gap measure where the tests are adapted after the initial refactoring of the code base). Based on a spike of the changes the simple request-response model would require, it seems plausible to achieve the refactoring within (at most) two weekly sprints. It is expected that the bulk of the time will be spent in refactoring the test code.","title":"Decision"},{"location":"adr/011_device_request_queue/#consequences","text":"The chosen approach has the following benefits: Single use of Task.Run in LnsProtocolMessageProcessor . This reduces the number execution forks to consider as well as chances of exceptions going unobserved. Removes many abstractions like ILoRaDeviceRequestQueue and IMessageDispatcher , implementations like DeviceLoaderSynchronizer and ExternalGatewayLoRaRequestQueue , and potentially more. Easier to reason about the overall message flow. Use of the regular async-await programming model, including error-handling and cancellation that's built-in into tasks. Transparent use of queues through tasks in LoRaDevice to serialize execution. This subsumes the first approach (discussed in the introductory section) by having implicit rather explicit queuing (at the application-level). Greatest potential to simplify tests since assertions can rely on simply return values and exceptions, instead of success/failure notifications. It is not mutually exclusive with other approaches explored. For example, by simplifying to the request-response model, it would be even easier to have the LNS operate with a single logical thread if that could further help remove some complexity (without compromising scalability) like locks. The absence of an explicit queue could be make it more difficult for someone to understand the code and choices made if they are not familiar with the intricacies of how async-await operates.","title":"Consequences"},{"location":"adr/012_decouple_from_edge/","text":"012. Decouple LoRaWAN Network Server from IoT Edge Feature : #1553 Authors : Daniele Antonio Maggio Status : Accepted (implemented starting with v2.2.0) Problem statement As of v2.1.0, the LoRaWAN Starter Kit makes use of Azure IoT Edge in order to host and manage LoRaWAN Network Server (LNS). When it comes to LNS, IoT Edge based deployments allow interesting features such as: centralized deployment through IoT Hub store and forward processing of leaf-device messages that need to be routed upstream management of configuration through module twins and desired property updates ability to \" invoke direct methods from IoT Hub \" on prem data processing With v2.0.0, the LoRaWAN Starter Kit moved from Packet Forwarder to a more reliable (WebSockets/TCP) and secure (mTLS capable) Basics Station . This change opens up to deployment models where the LNS is hosted on a different machine from the on-premises concentrator device which is forwarding the LoRa packets. As an example, LNS could still be hosted on-premises in a separate dedicated IoT Edge device. When it comes to scalability or high-availability, it's not always easy to provision additional IoT Edge based devices and, maybe, you could have some existing infrastructure that you might want to re-use (i.e. a Kubernetes cluster). In addition, if you want to use Azure for hosting and scaling the LoRaWAN Network Server, in order to handle messages from different sites/locations, IoT Edge is not the proper technology to put into the cloud. This ADR will focus on the needed changes that will allow to deploy a LoRaWAN Network Server without a strict dependency on Azure IoT Edge, while preserving functionalities like centralized configuration management and remote invocation of methods in LNS. In-scope Describe how to differentiate \"edge\" LNSs deployments from \"cloud\" ones in mixed scenarios Provide an alternative for deploying and managing configuration Provide additional information on abstracting and replacing ModuleClient related dependencies, such as: Direct methods (currently used for Clearing Cache, forcefully closing DeviceClient connections, handling class-c c2d messages) Twin updates (currently used for updating few configuration items, without restarting the entire LNS) Provide information on a \"Function\" endpoint for clearing cache of all \"cloud\" LNSs Describe a sample deployment scenario being enabled by decoupling Out of scope Key Vault integration for secrets management It would be great to make use of Azure Key Vault to securely store components like Azure Function authentication code or Server Certificate for Secure BasicsStation-LNS communications, but this document will not focus on this aspect. Changes required Before diving in the various required changes, let's understand the \"IoT Edge\" bindings that are there in the code. The main difference comes to \"ModuleConnectionHost\", which is responsible for: Instantiating a ModuleClient object to be used for interacting with module twins and receiving direct method invocations Setting a callback on \"desired property updates\" for dynamically configuring some configuration variables Setting a callback on \"direct method invocation\" for handling: Clearing LNS device registry cache Closing DeviceClient connections for avoiding \"ping-pong\" as described in ADR 010 Sending Cloud to Device (c2d) messages for Class-C devices Except for ModuleConnectionHost, the other difference is concerning the ability to \"proxy\" leaf-device messages through Edge Hub. By default the \"ENABLE_GATEWAY\" environment variable is set to true, we need to make sure that ENABLE_GATEWAY can't be set to true when not running as Edge module . Addressing and routing requests to a specific LNS The biggest concern in this section is regarding how the Azure Function is addressing and routing a specific LNS with the new deployment model. When running parallel instances of the LNS, it is crucial to identify a very specific instance for properly routing method invocations like cache clear, connection closes and class-c cloud-to-device messages sends. Mutually exclusive deployment modes The easiest possibility, is to deploy the Azure Function in such a way that it is mutually exclusive whether to target \"Edge\" or \"Cloud\" deployments. This would require the introduction of an environment variable, i.e. \"TARGET_CLOUD_LNS\", which would allow to inject different implementations of the IServiceClient interface, currently responsible for both handling direct method invocations and sending c2d messages (both class-a and class-c devices). The new \"cloud only\" implementation, would need to make use an alternative for invoking such methods. This is described in \"Direct method invocation\" section This alternative is discarded in favor of allowing mixed deployment modes in order to maximize the flexibility of this starter kit. All the following sections are therefore thought for a \"mixed-deployment\" scenario where both Edge LNS and Cloud LNS are running at the same time and targeting/being targeted by the same set of Azure Functions. Identifying whether a LNS is running in edge or cloud mode As of v2.1.0, the LNS code is able to understand whether it is running as IoT Edge Module or not. Currently, the availability of the \"IOTEDGE_APIVERSION\" environment variable is checked. This variable is injected by the \"Edge Agent\" component at the moment of module creation and startup, therefore if the variable is not there we can safely assume that the LNS is not running in a Edge environment. We need to be able to identify in the function, if a particular LNS is running standalone or deployed on edge , to be able to address the LNS through different channels (edge->IoT Hub, standalone->topic). It is therefore decided to identify if a LNS is running standalone or on edge by using a new \"CLOUD_DEPLOYMENT\" environment variable (defaults to false) While we do not expect \"IOTEDGE_APIVERSION\" to change in the immediate future and, even if we are adding another environment variable, the decision is taken in order to make the identification more reliable and not depending on IoT Edge. As an alternative we could still use \"IOTEDGE_APIVERSION\" and eventually react on future changes. Differentiating LNS instances in mixed-mode deployments When a leaf device sends a message, its twin gets updated from the LNS with the \"GatewayID\" variable content, currently being set to the \"IOTEDGE_DEVICEID\" environment variable (defaulting to an empty string when variable is not set in the environment) This is the way the \"Facade\" Azure function has to identify and target a specific LNS instance for closing device client connections or sending C2D messages for class-c devices. The decision is to: Prefix the \"GatewayID\" with \"cloud-\" for non-Edge deployments Use the \"Hostname\" environment variable as a default for GatewayID field An alternative considered is to identify the difference in deployment model by querying IoT Hub for availability of a \"IoT Edge\" capable device and cache that result. An advantage of such alternative is the fact that there's no need to use any prefix for GatewayID which would also not tamper the observability part. A disadvantage, though, comes from the request quota limits on IoT Hub Device Registry operations which could be cause of throttling and instability for other pieces of the LNS itself. Another alternative could be to extend the Function-exposed APIs by allowing an optional parameter that indicates the deployment model of the LNS. The parameter (i.e. \"cloudDeployment\") would default to \"false\" to let everything be retro-compatible with existing deployments. For cloud deployed LNS the parameter would be set to true. A disadvantage of this approach is that all the current and future APIs that will need to act like a \"direct method\" will need to take the difference into account and provide the option to specify this optional parameter. Direct method invocation As previously mentioned, IoT Edge is allowing the functionality of \"direct method invocations\" giving the possiblity to remotely invoke some functions on the LNS. When decoupling LNS from Azure IoT Edge, there are different possibilities for handling the scenarios covered by direct method invocation. We want an Azure IoT Edge device to still be using the direct method invocations provided by IoT Hub whereas the \"cloud\" deployments to use a new, different, mechanism. For \"cloud\" deployments, such mechanism consists in using Pub/Sub to publish the method invocation events on a topic, to which all the LNS instances are subscribing and filtering based on their \"hostname\". The decision is to: Abstract the logic for calling a \"direct method\" and provide two implementations, one based on existing IoT Hub code and another one based on Pub/Sub mechanism (while still abstracting the actual service used for Pub/Sub) Reuse Azure Cache for Redis instance that it's already being deployed in the solution as it allows the usage of Redis Pub/Sub functionality As a stretch goal, useful for high scale and testing scenarios, implement a new function for clearing cache of all the LNS subscribed to the topic An alternative to \"Azure Cache for Redis\" for the Pub/Sub functionality is to use \"Azure Service Bus\". While this would allow higher resiliency, the alternative has been discarded to avoid provisioning another additional service. One alternative to the Pub/Sub functionality instead, might be to expose REST endpoints on the LNS. The advantages of this alternative, are definitely the easy implementation and the potential simplification of \"manual\" invocation of such methods. At the same time, the disadvantage comes from the fact that, when scaling out, depending on the platform where the replicas of the LNS are hosted, you might have different ways to target exactly one replica; on Kubernetes, for instance, this might be achieved by using a service mesh, but this requires additional configuration Managing configuration and its changes All the configuration is fetched at the start time from the environment variables. IoT Edge allows you to specify those configuration variables as part of a template for automatic deployments for single devices or at scale Depending on the target cloud service, you might have different ways to manage configuration in a centralized way. If using Azure Kubernetes Service, a configmap to be applied to the desired cluster might work for you. If using Azure App Service, you might just set the environment variables in the configuration section of the application. While these solutions are great for \"static\" configuration (i.e.: those values that require a restart for being changed), the LNS is coded in such a way that some configuration might be changed dynamically without having to restart the entire network server. The decision is to rely on static environment variable configuration, requiring a restart of the module for any configuration change . Reasons for this decision are: small amount of \"dynamic\" variables in the system and their nature (i.e. Azure Function URL and Auth changes mean that a system re-deployment is taking place) allow to keep the number of deployed Azure services to a minimum, given the \"Starter Kit\" nature of this repository As an alternative, especially when it comes to dynamic configuration, it could be possible to make use of \" Azure App Configuration \". The service allows to centrally manage application settings and reload any dynamic configuration using poll model . This has been discarded because dynamic configuration is a nice-to-have, not strictly needed for decoupling LNS from Edge, and it requires the deployment and configuration of an additional service. Sample \"cloud\" deployment scenario The picture above highlights a possible scenario being enabled by decoupling LNS from IoT Edge. This scenario brings in the possibility of using one (or multiple) Azure Kubernetes Services cluster for running one (or multiple) instances of LoRaWAN Network Server. While keeping in mind that a LoRa Basics Station can be connected only to a single LNS instance at the same time, with such scenario it could be anyways possible to increase high availability or scalability. Ideally, the LoRa Basics Station could point to a \"vNext\" discovery service that will be able to balance the load across multiple Azure Kubernetes Service clusters, or in an \"active-passive\" cluster configuration, only point to the \"active\" one. In addition, the load of the potentially multiple LNS instances in the same single cluster could be balanced by routing based on the number of \"stations\" already connected to the server instances (by leveraging the already existing metric being exported in Prometheus format) Summary of the required and decided changes Identify whether LNS is running as IoT Edge Module or not by using a new \"CLOUD_DEPLOYMENT\" environment variable (defaults to false) Check that ENABLE_GATEWAY environment variable is not set to true when not running as Edge module Prefix the \"GatewayID\" depending on whether it is running \"standalone\" or on edge Keep configuration simple and require a reboot for changing configuration parameters Make use of Redis Pub/Sub functionality, in \"Cloud\" deployment mode, to handle remote invocation of methods In Facade Azure Function, differentiate the mechanism used for remotely invoke methods depending on the \"LNS device id\" In case of \"Cloud\" LNS deployment, publish invocation of methods as messages in Redis Pub/Sub (stretch) only for \"Cloud\" LNS deployments, implement a new function for clearing cache of all the LNS subscribed to the topic","title":"012. Decouple LoRaWAN Network Server from IoT Edge"},{"location":"adr/012_decouple_from_edge/#012-decouple-lorawan-network-server-from-iot-edge","text":"Feature : #1553 Authors : Daniele Antonio Maggio Status : Accepted (implemented starting with v2.2.0)","title":"012. Decouple LoRaWAN Network Server from IoT Edge"},{"location":"adr/012_decouple_from_edge/#problem-statement","text":"As of v2.1.0, the LoRaWAN Starter Kit makes use of Azure IoT Edge in order to host and manage LoRaWAN Network Server (LNS). When it comes to LNS, IoT Edge based deployments allow interesting features such as: centralized deployment through IoT Hub store and forward processing of leaf-device messages that need to be routed upstream management of configuration through module twins and desired property updates ability to \" invoke direct methods from IoT Hub \" on prem data processing With v2.0.0, the LoRaWAN Starter Kit moved from Packet Forwarder to a more reliable (WebSockets/TCP) and secure (mTLS capable) Basics Station . This change opens up to deployment models where the LNS is hosted on a different machine from the on-premises concentrator device which is forwarding the LoRa packets. As an example, LNS could still be hosted on-premises in a separate dedicated IoT Edge device. When it comes to scalability or high-availability, it's not always easy to provision additional IoT Edge based devices and, maybe, you could have some existing infrastructure that you might want to re-use (i.e. a Kubernetes cluster). In addition, if you want to use Azure for hosting and scaling the LoRaWAN Network Server, in order to handle messages from different sites/locations, IoT Edge is not the proper technology to put into the cloud. This ADR will focus on the needed changes that will allow to deploy a LoRaWAN Network Server without a strict dependency on Azure IoT Edge, while preserving functionalities like centralized configuration management and remote invocation of methods in LNS.","title":"Problem statement"},{"location":"adr/012_decouple_from_edge/#in-scope","text":"Describe how to differentiate \"edge\" LNSs deployments from \"cloud\" ones in mixed scenarios Provide an alternative for deploying and managing configuration Provide additional information on abstracting and replacing ModuleClient related dependencies, such as: Direct methods (currently used for Clearing Cache, forcefully closing DeviceClient connections, handling class-c c2d messages) Twin updates (currently used for updating few configuration items, without restarting the entire LNS) Provide information on a \"Function\" endpoint for clearing cache of all \"cloud\" LNSs Describe a sample deployment scenario being enabled by decoupling","title":"In-scope"},{"location":"adr/012_decouple_from_edge/#out-of-scope","text":"Key Vault integration for secrets management It would be great to make use of Azure Key Vault to securely store components like Azure Function authentication code or Server Certificate for Secure BasicsStation-LNS communications, but this document will not focus on this aspect.","title":"Out of scope"},{"location":"adr/012_decouple_from_edge/#changes-required","text":"Before diving in the various required changes, let's understand the \"IoT Edge\" bindings that are there in the code. The main difference comes to \"ModuleConnectionHost\", which is responsible for: Instantiating a ModuleClient object to be used for interacting with module twins and receiving direct method invocations Setting a callback on \"desired property updates\" for dynamically configuring some configuration variables Setting a callback on \"direct method invocation\" for handling: Clearing LNS device registry cache Closing DeviceClient connections for avoiding \"ping-pong\" as described in ADR 010 Sending Cloud to Device (c2d) messages for Class-C devices Except for ModuleConnectionHost, the other difference is concerning the ability to \"proxy\" leaf-device messages through Edge Hub. By default the \"ENABLE_GATEWAY\" environment variable is set to true, we need to make sure that ENABLE_GATEWAY can't be set to true when not running as Edge module .","title":"Changes required"},{"location":"adr/012_decouple_from_edge/#addressing-and-routing-requests-to-a-specific-lns","text":"The biggest concern in this section is regarding how the Azure Function is addressing and routing a specific LNS with the new deployment model. When running parallel instances of the LNS, it is crucial to identify a very specific instance for properly routing method invocations like cache clear, connection closes and class-c cloud-to-device messages sends.","title":"Addressing and routing requests to a specific LNS"},{"location":"adr/012_decouple_from_edge/#mutually-exclusive-deployment-modes","text":"The easiest possibility, is to deploy the Azure Function in such a way that it is mutually exclusive whether to target \"Edge\" or \"Cloud\" deployments. This would require the introduction of an environment variable, i.e. \"TARGET_CLOUD_LNS\", which would allow to inject different implementations of the IServiceClient interface, currently responsible for both handling direct method invocations and sending c2d messages (both class-a and class-c devices). The new \"cloud only\" implementation, would need to make use an alternative for invoking such methods. This is described in \"Direct method invocation\" section This alternative is discarded in favor of allowing mixed deployment modes in order to maximize the flexibility of this starter kit. All the following sections are therefore thought for a \"mixed-deployment\" scenario where both Edge LNS and Cloud LNS are running at the same time and targeting/being targeted by the same set of Azure Functions.","title":"Mutually exclusive deployment modes"},{"location":"adr/012_decouple_from_edge/#identifying-whether-a-lns-is-running-in-edge-or-cloud-mode","text":"As of v2.1.0, the LNS code is able to understand whether it is running as IoT Edge Module or not. Currently, the availability of the \"IOTEDGE_APIVERSION\" environment variable is checked. This variable is injected by the \"Edge Agent\" component at the moment of module creation and startup, therefore if the variable is not there we can safely assume that the LNS is not running in a Edge environment. We need to be able to identify in the function, if a particular LNS is running standalone or deployed on edge , to be able to address the LNS through different channels (edge->IoT Hub, standalone->topic). It is therefore decided to identify if a LNS is running standalone or on edge by using a new \"CLOUD_DEPLOYMENT\" environment variable (defaults to false) While we do not expect \"IOTEDGE_APIVERSION\" to change in the immediate future and, even if we are adding another environment variable, the decision is taken in order to make the identification more reliable and not depending on IoT Edge. As an alternative we could still use \"IOTEDGE_APIVERSION\" and eventually react on future changes.","title":"Identifying whether a LNS is running in edge or cloud mode"},{"location":"adr/012_decouple_from_edge/#differentiating-lns-instances-in-mixed-mode-deployments","text":"When a leaf device sends a message, its twin gets updated from the LNS with the \"GatewayID\" variable content, currently being set to the \"IOTEDGE_DEVICEID\" environment variable (defaulting to an empty string when variable is not set in the environment) This is the way the \"Facade\" Azure function has to identify and target a specific LNS instance for closing device client connections or sending C2D messages for class-c devices. The decision is to: Prefix the \"GatewayID\" with \"cloud-\" for non-Edge deployments Use the \"Hostname\" environment variable as a default for GatewayID field An alternative considered is to identify the difference in deployment model by querying IoT Hub for availability of a \"IoT Edge\" capable device and cache that result. An advantage of such alternative is the fact that there's no need to use any prefix for GatewayID which would also not tamper the observability part. A disadvantage, though, comes from the request quota limits on IoT Hub Device Registry operations which could be cause of throttling and instability for other pieces of the LNS itself. Another alternative could be to extend the Function-exposed APIs by allowing an optional parameter that indicates the deployment model of the LNS. The parameter (i.e. \"cloudDeployment\") would default to \"false\" to let everything be retro-compatible with existing deployments. For cloud deployed LNS the parameter would be set to true. A disadvantage of this approach is that all the current and future APIs that will need to act like a \"direct method\" will need to take the difference into account and provide the option to specify this optional parameter.","title":"Differentiating LNS instances in mixed-mode deployments"},{"location":"adr/012_decouple_from_edge/#direct-method-invocation","text":"As previously mentioned, IoT Edge is allowing the functionality of \"direct method invocations\" giving the possiblity to remotely invoke some functions on the LNS. When decoupling LNS from Azure IoT Edge, there are different possibilities for handling the scenarios covered by direct method invocation. We want an Azure IoT Edge device to still be using the direct method invocations provided by IoT Hub whereas the \"cloud\" deployments to use a new, different, mechanism. For \"cloud\" deployments, such mechanism consists in using Pub/Sub to publish the method invocation events on a topic, to which all the LNS instances are subscribing and filtering based on their \"hostname\". The decision is to: Abstract the logic for calling a \"direct method\" and provide two implementations, one based on existing IoT Hub code and another one based on Pub/Sub mechanism (while still abstracting the actual service used for Pub/Sub) Reuse Azure Cache for Redis instance that it's already being deployed in the solution as it allows the usage of Redis Pub/Sub functionality As a stretch goal, useful for high scale and testing scenarios, implement a new function for clearing cache of all the LNS subscribed to the topic An alternative to \"Azure Cache for Redis\" for the Pub/Sub functionality is to use \"Azure Service Bus\". While this would allow higher resiliency, the alternative has been discarded to avoid provisioning another additional service. One alternative to the Pub/Sub functionality instead, might be to expose REST endpoints on the LNS. The advantages of this alternative, are definitely the easy implementation and the potential simplification of \"manual\" invocation of such methods. At the same time, the disadvantage comes from the fact that, when scaling out, depending on the platform where the replicas of the LNS are hosted, you might have different ways to target exactly one replica; on Kubernetes, for instance, this might be achieved by using a service mesh, but this requires additional configuration","title":"Direct method invocation"},{"location":"adr/012_decouple_from_edge/#managing-configuration-and-its-changes","text":"All the configuration is fetched at the start time from the environment variables. IoT Edge allows you to specify those configuration variables as part of a template for automatic deployments for single devices or at scale Depending on the target cloud service, you might have different ways to manage configuration in a centralized way. If using Azure Kubernetes Service, a configmap to be applied to the desired cluster might work for you. If using Azure App Service, you might just set the environment variables in the configuration section of the application. While these solutions are great for \"static\" configuration (i.e.: those values that require a restart for being changed), the LNS is coded in such a way that some configuration might be changed dynamically without having to restart the entire network server. The decision is to rely on static environment variable configuration, requiring a restart of the module for any configuration change . Reasons for this decision are: small amount of \"dynamic\" variables in the system and their nature (i.e. Azure Function URL and Auth changes mean that a system re-deployment is taking place) allow to keep the number of deployed Azure services to a minimum, given the \"Starter Kit\" nature of this repository As an alternative, especially when it comes to dynamic configuration, it could be possible to make use of \" Azure App Configuration \". The service allows to centrally manage application settings and reload any dynamic configuration using poll model . This has been discarded because dynamic configuration is a nice-to-have, not strictly needed for decoupling LNS from Edge, and it requires the deployment and configuration of an additional service.","title":"Managing configuration and its changes"},{"location":"adr/012_decouple_from_edge/#sample-cloud-deployment-scenario","text":"The picture above highlights a possible scenario being enabled by decoupling LNS from IoT Edge. This scenario brings in the possibility of using one (or multiple) Azure Kubernetes Services cluster for running one (or multiple) instances of LoRaWAN Network Server. While keeping in mind that a LoRa Basics Station can be connected only to a single LNS instance at the same time, with such scenario it could be anyways possible to increase high availability or scalability. Ideally, the LoRa Basics Station could point to a \"vNext\" discovery service that will be able to balance the load across multiple Azure Kubernetes Service clusters, or in an \"active-passive\" cluster configuration, only point to the \"active\" one. In addition, the load of the potentially multiple LNS instances in the same single cluster could be balanced by routing based on the number of \"stations\" already connected to the server instances (by leveraging the already existing metric being exported in Prometheus format)","title":"Sample \"cloud\" deployment scenario"},{"location":"adr/012_decouple_from_edge/#summary-of-the-required-and-decided-changes","text":"Identify whether LNS is running as IoT Edge Module or not by using a new \"CLOUD_DEPLOYMENT\" environment variable (defaults to false) Check that ENABLE_GATEWAY environment variable is not set to true when not running as Edge module Prefix the \"GatewayID\" depending on whether it is running \"standalone\" or on edge Keep configuration simple and require a reboot for changing configuration parameters Make use of Redis Pub/Sub functionality, in \"Cloud\" deployment mode, to handle remote invocation of methods In Facade Azure Function, differentiate the mechanism used for remotely invoke methods depending on the \"LNS device id\" In case of \"Cloud\" LNS deployment, publish invocation of methods as messages in Redis Pub/Sub (stretch) only for \"Cloud\" LNS deployments, implement a new function for clearing cache of all the LNS subscribed to the topic","title":"Summary of the required and decided changes"},{"location":"samples/arduino/","text":"Arduino Demo Code Please make sure the device twin tags are set correctly in IoT Hub, otherwise the sample won't work. Necessary tags are at the start of every sample file.ino. This samples were tested with the Seeeduino LoRaWan boards . The LoRaWan libraries (referenced thru \"LoRaWan.h\" in the ino files) is coming when you select the platform as a Seeduino LoRaWan board. If you are using another LoRaWan library, you will have to adjust this code as so far, all LoRaWan libraries are different from one manufacturer to another on Arduino platform. That said, adaptation shouldn't be too difficult and equivalent functions has to exist in all libraries. When using the initial template to provision the devices, make sure to get the devices key in the devices' twins or in the ARM deployment logs (go to the deployment resource group and then to deployments/devices/createIothubDevices) This samples were tested with the Seeeduino LoRaWan boards. Samples are organized by regions as LoRaWan uses different frequences based on your geography. Please make sure you're using the sample from the correct geography. TransmissionTestOTAALoRa - This is the most basic example. The sample perform an OTAA authentication and send a message to the gateway every 5 seconds. The sample also display on the serial interface any cloud to device message. TransmissionTestABPLoRa - Same functionality as 1. but it uses ABP instead of OTAA. GPSOTAALoRa - This sample sends GPS latitude and longitude information every 30 seconds using the onboard GPS. It uses OTAA activation. It uses OTAA activation to authenticate. 34 TemperatureOTAALoRa - This sample use the Grove temperature sensor to send temperature information every 30 seconds. It uses OTAA activation to authenticate. The sample also display on the serial interface any cloud to device message.","title":"Arduino Demo Code"},{"location":"samples/arduino/#arduino-demo-code","text":"Please make sure the device twin tags are set correctly in IoT Hub, otherwise the sample won't work. Necessary tags are at the start of every sample file.ino. This samples were tested with the Seeeduino LoRaWan boards . The LoRaWan libraries (referenced thru \"LoRaWan.h\" in the ino files) is coming when you select the platform as a Seeduino LoRaWan board. If you are using another LoRaWan library, you will have to adjust this code as so far, all LoRaWan libraries are different from one manufacturer to another on Arduino platform. That said, adaptation shouldn't be too difficult and equivalent functions has to exist in all libraries. When using the initial template to provision the devices, make sure to get the devices key in the devices' twins or in the ARM deployment logs (go to the deployment resource group and then to deployments/devices/createIothubDevices) This samples were tested with the Seeeduino LoRaWan boards. Samples are organized by regions as LoRaWan uses different frequences based on your geography. Please make sure you're using the sample from the correct geography. TransmissionTestOTAALoRa - This is the most basic example. The sample perform an OTAA authentication and send a message to the gateway every 5 seconds. The sample also display on the serial interface any cloud to device message. TransmissionTestABPLoRa - Same functionality as 1. but it uses ABP instead of OTAA. GPSOTAALoRa - This sample sends GPS latitude and longitude information every 30 seconds using the onboard GPS. It uses OTAA activation. It uses OTAA activation to authenticate. 34 TemperatureOTAALoRa - This sample use the Grove temperature sensor to send temperature information every 30 seconds. It uses OTAA activation to authenticate. The sample also display on the serial interface any cloud to device message.","title":"Arduino Demo Code"},{"location":"samples/decoders/decoder/","text":"DecoderSample This sample allows you to create and run your own LoRa message decoder in an independent container running on your LoRa gateway without having to edit the main LoRa Engine. This description shows you how to get started. Customizing To add a new decoder, simply copy or reuse the sample DecoderValueSensor method from the LoraDecoders class in LoraDecoder.cs . You can name the method whatever you like and can create as many decoders as you need by adding new, individual methods to the LoraDecoders class. The payload sent to the decoder is passed as string devEui , byte[] payload and uint fport . After writing the code that decodes your message, your method should return a string containing valid JSON containing the response to be sent upstream. internal static class LoraDecoders { private static string DecoderValueSensor ( string devEUI , byte [] payload , byte fport ) { // EITHER: Convert a payload containing a string back to string format for further processing var result = Encoding . UTF8 . GetString ( payload ); // OR: Convert a payload containing binary data to HEX string for further processing var result_binary = ConversionHelper . ByteArrayToString ( payload ); // Write code that decodes the payload here. // Return a JSON string containing the decoded data return JsonConvert . SerializeObject ( new { value = result }); } } You can test the decoder on your machine by debugging the SensorDecoderModule project in Visual Studio. When creating a debugging configuration in Visual Studio Code or a launchSettings.json file in Visual Studio, the default address that the webserver will try to use is http://localhost:5000 or https://localhost:5001 . You can override this with any port of your choice. On launching the debugger you will see a webbrowser with a 404 Not Found error as there is no default document to be served in this Web API app. You will also manually need to base64-encode and URL-encode the payload before adding it to the URL parameters. For example, to test a payload of ABCDE12345 , you: Convert it to a base64 encoded string: QUJDREUxMjM0NQ== Convert the result to a valid URL parameter: QUJDREUxMjM0NQ%3D%3D Add this to your test URL. For the built-in sample decoder DecoderValueSensor with Visual Studio (Code)'s default settings this would be: http://localhost:5000/api/DecoderValueSensor?devEui=0000000000000000&fport=1&payload=QUJDREUxMjM0NQ%3D%3D You can call your decoder at: http://localhost:yourPort/api/<decodername>?devEui=0000000000000000&fport=1&payload=<QUJDREUxMjM0NQ%3D%3D> You should see the result as JSON string. When running the solution in a container, the Kestrel webserver from .NET Core uses the HTTP default port 80 of the container and does not need to bind it to a port on the host machine as Docker allows for container-to-container communication. IoT Edge automatically creates the required Docker Network Bridge . Preparing and Testing the Docker Image Create a docker image from your finished solution based on the target architecture and host it in an Azure Container Registry , on DockerHub or in any other container registry of your choice. We are using the Azure IoT Edge for Visual Studio Code extension to build and push the Docker image. Make sure you are logged in to the Azure Container Registry you are using. Run docker login <mycontainerregistry>.azurecr.io on your development machine. Edit the file module.json to contain your container registry address, image name and version number: We provide the Dockerfiles for the following architectures: Dockerfile.amd64 Dockerfile.arm32v7 To build the Docker image, right-click on the module.json file and select \"Build IoT Edge Module Image\" or \"Build and Push IoT Edge Module Image\". Select the architecture you want to build for (ARM32v7 or AMD64) from the drop-down menu. To temporarily test the container running you decoder using a webbrowser or Postman, you can manually start it in Docker and bind the container's port 80 to a free port on your host machine, like for example 8881. docker run --rm -it -p 8881 :80 --name decodersample <container registry>/<image>:<tag> ```` You can then use a browser to navigate to: http://localhost:8881/api/DecoderValueSensor?devEui=0000000000000000&fport=1&payload=QUJDREUxMjM0NQ%3D%3D ### Deploying to IoT Edge If required, add credentials to access your container registry to the IoT Edge device by adding them to IoT Hub &rarr; IoT Edge &rarr; Your Device &rarr; Set Modules &rarr; Container Registry settings. ![Decoder Sample - Edge Module Container Registry Permission](../../images/decodersample-edgepermission.png) Configure your IoT Edge gateway device to include the custom container. IoT Hub &rarr; IoT Edge &rarr; Your Device &rarr; Set Modules &rarr; Deployment Modules &rarr; Add &rarr; IoT Edge Module. Set the module Name and Image URI, pointing to your image created above. **Make sure to choose all lowercase letters for the Module Name as the container will be unreachable otherwise!** ![Decoder Sample - Edge Module](../../images/decodersample-edgemodule.png) To activate the decoder for a LoRa device, navigate to your IoT Hub &rarr; IoT Devices &rarr; Device Details &rarr; Device Twin and set the ```SensorDecoder``` value in the desired properties to: http:// /api/ ``` Again make sure to chosse all lowercase letters for the module name to make sure it is reachable. In case the custom decoder is unreachable, throws an error or return invalid JSON, the error message will be shown in your device's messages in IoT Hub.","title":"Decoder"},{"location":"samples/decoders/decoder/#decodersample","text":"This sample allows you to create and run your own LoRa message decoder in an independent container running on your LoRa gateway without having to edit the main LoRa Engine. This description shows you how to get started.","title":"DecoderSample"},{"location":"samples/decoders/decoder/#customizing","text":"To add a new decoder, simply copy or reuse the sample DecoderValueSensor method from the LoraDecoders class in LoraDecoder.cs . You can name the method whatever you like and can create as many decoders as you need by adding new, individual methods to the LoraDecoders class. The payload sent to the decoder is passed as string devEui , byte[] payload and uint fport . After writing the code that decodes your message, your method should return a string containing valid JSON containing the response to be sent upstream. internal static class LoraDecoders { private static string DecoderValueSensor ( string devEUI , byte [] payload , byte fport ) { // EITHER: Convert a payload containing a string back to string format for further processing var result = Encoding . UTF8 . GetString ( payload ); // OR: Convert a payload containing binary data to HEX string for further processing var result_binary = ConversionHelper . ByteArrayToString ( payload ); // Write code that decodes the payload here. // Return a JSON string containing the decoded data return JsonConvert . SerializeObject ( new { value = result }); } } You can test the decoder on your machine by debugging the SensorDecoderModule project in Visual Studio. When creating a debugging configuration in Visual Studio Code or a launchSettings.json file in Visual Studio, the default address that the webserver will try to use is http://localhost:5000 or https://localhost:5001 . You can override this with any port of your choice. On launching the debugger you will see a webbrowser with a 404 Not Found error as there is no default document to be served in this Web API app. You will also manually need to base64-encode and URL-encode the payload before adding it to the URL parameters. For example, to test a payload of ABCDE12345 , you: Convert it to a base64 encoded string: QUJDREUxMjM0NQ== Convert the result to a valid URL parameter: QUJDREUxMjM0NQ%3D%3D Add this to your test URL. For the built-in sample decoder DecoderValueSensor with Visual Studio (Code)'s default settings this would be: http://localhost:5000/api/DecoderValueSensor?devEui=0000000000000000&fport=1&payload=QUJDREUxMjM0NQ%3D%3D You can call your decoder at: http://localhost:yourPort/api/<decodername>?devEui=0000000000000000&fport=1&payload=<QUJDREUxMjM0NQ%3D%3D> You should see the result as JSON string. When running the solution in a container, the Kestrel webserver from .NET Core uses the HTTP default port 80 of the container and does not need to bind it to a port on the host machine as Docker allows for container-to-container communication. IoT Edge automatically creates the required Docker Network Bridge .","title":"Customizing"},{"location":"samples/decoders/decoder/#preparing-and-testing-the-docker-image","text":"Create a docker image from your finished solution based on the target architecture and host it in an Azure Container Registry , on DockerHub or in any other container registry of your choice. We are using the Azure IoT Edge for Visual Studio Code extension to build and push the Docker image. Make sure you are logged in to the Azure Container Registry you are using. Run docker login <mycontainerregistry>.azurecr.io on your development machine. Edit the file module.json to contain your container registry address, image name and version number: We provide the Dockerfiles for the following architectures: Dockerfile.amd64 Dockerfile.arm32v7 To build the Docker image, right-click on the module.json file and select \"Build IoT Edge Module Image\" or \"Build and Push IoT Edge Module Image\". Select the architecture you want to build for (ARM32v7 or AMD64) from the drop-down menu. To temporarily test the container running you decoder using a webbrowser or Postman, you can manually start it in Docker and bind the container's port 80 to a free port on your host machine, like for example 8881. docker run --rm -it -p 8881 :80 --name decodersample <container registry>/<image>:<tag> ```` You can then use a browser to navigate to: http://localhost:8881/api/DecoderValueSensor?devEui=0000000000000000&fport=1&payload=QUJDREUxMjM0NQ%3D%3D ### Deploying to IoT Edge If required, add credentials to access your container registry to the IoT Edge device by adding them to IoT Hub &rarr; IoT Edge &rarr; Your Device &rarr; Set Modules &rarr; Container Registry settings. ![Decoder Sample - Edge Module Container Registry Permission](../../images/decodersample-edgepermission.png) Configure your IoT Edge gateway device to include the custom container. IoT Hub &rarr; IoT Edge &rarr; Your Device &rarr; Set Modules &rarr; Deployment Modules &rarr; Add &rarr; IoT Edge Module. Set the module Name and Image URI, pointing to your image created above. **Make sure to choose all lowercase letters for the Module Name as the container will be unreachable otherwise!** ![Decoder Sample - Edge Module](../../images/decodersample-edgemodule.png) To activate the decoder for a LoRa device, navigate to your IoT Hub &rarr; IoT Devices &rarr; Device Details &rarr; Device Twin and set the ```SensorDecoder``` value in the desired properties to: http:// /api/ ``` Again make sure to chosse all lowercase letters for the module name to make sure it is reachable. In case the custom decoder is unreachable, throws an error or return invalid JSON, the error message will be shown in your device's messages in IoT Hub.","title":"Preparing and Testing the Docker Image"},{"location":"samples/decoders/universal/","text":"Universal Decoder This project gives access to decoders in the TTN repo through a HTTP REST interface compliant with the LoraWan implementation in this repository. Codecs provided by TTN are stored in a well defined folder structure . The universal decoder copies the codec files into its docker image at build time for later use from the web application. As currently codecs are not implemented as node modules (see open issue ), these files were patched accordingly after being copied so that they can be imported and reused. Quick start Install node dependencies and copy/patch codecs from the TTN repository: npm install npm run codecs Create docker image (replace amd64 with the architecture of your choice) docker build . -f Dockerfile.amd64 -t universaldecoder Run docker image: docker run --rm -d -p 8080 :8080 universaldecoder Call the built-in DecoderValueSensor decoder at the following url. You should see the result as JSON string. http://localhost:8080/api/DecoderValueSensor?devEui=0000000000000000&fport=1&payload=QUJDREUxMjM0NQ%3D%3D Finally list all available decoders with the following url: http://localhost:8080/decoders You can finally call any other supported decoder at: http://localhost:8080/api/<decoder>?devEui=0000000000000000&fport=<fport>&payload=<payload> Local development Start local server npm start You can access the universal decoder at the url available in the output of the previous command. Run tests npm test Universal Decoder REST API The url accepted by the universal decoder follows the pattern: /api/<decoder>?devEui=<devEui>&fport=<fport>&payload=<payload> decoder This path parameter identifies the TTN decoder that will be used. You can get a list of all available decoders by calling the /decoders endpoint. devEui LoRaWan unique end-device identifier. fport LoRaWan Port field as integer value. payload Base64 and URL encoded payload to decode. For example, to test a payload of ABCDE12345 , you: Convert it to a base64 encoded string: QUJDREUxMjM0NQ== Convert the result to a valid URL parameter: QUJDREUxMjM0NQ%3D%3D Add this to your URL as the payload query parameter. Deploying to Azure IoT Edge Push docker image to registry Create a docker image from your finished solution based on the target architecture and host it in an Azure Container Registry , on DockerHub or in any other container registry of your choice. Install the Azure IoT Edge for Visual Studio Code extension to build and push the Docker image. Make sure you are logged in to the Azure Container Registry you are using. Run docker login <mycontainerregistry>.azurecr.io on your development machine, or az acr login -n mycontainerregistry if the Azure CLI is available. Edit the file module.json to contain your container registry address, image name and version number: We provide the Dockerfiles for the following architectures: Dockerfile.amd64 Dockerfile.arm32v7 Dockerfile.arm64v8 To build the Docker image, right-click on the module.json file and select \"Build IoT Edge Module Image\" or \"Build and Push IoT Edge Module Image\". Select the architecture you want to build for from the drop-down menu. To temporarily test the container running you decoder using a webbrowser or Postman, you can manually start it in Docker and bind the container's port 8080 to a free port on your host machine (8080 is usually good). docker run --rm -it -p 8080 :8080 --name universaldecoder <container registry>/<image>:<tag> ```` Call the built-in ` DecoderValueSensor ` decoder at the following url: http://localhost:8080/api/DecoderValueSensor?devEui=0000000000000000&fport=1&payload=QUJDREUxMjM0NQ%3D%3D ### Deploy to IoT Edge If required, add credentials to access your container registry to the IoT Edge device by adding them to IoT Hub &rarr; IoT Edge &rarr; Your Device &rarr; Set Modules &rarr; Container Registry settings. ![Decoder Sample - Edge Module Container Registry Permission](../../images/decodersample-edgepermission.png) Configure your IoT Edge gateway device to include the custom container. IoT Hub &rarr; IoT Edge &rarr; Your Device &rarr; Set Modules &rarr; Deployment Modules &rarr; Add &rarr; IoT Edge Module. Set the module Name and Image URI, pointing to your image created above. **Make sure to choose all lowercase letters for the Module Name as the container will be unreachable otherwise!** ![Decoder Sample - Edge Module](../../images/decodersample-edgemodule.png) To activate the decoder for a LoRa device, navigate to your IoT Hub &rarr; IoT Devices &rarr; Device Details &rarr; Device Twin and set the ```SensorDecoder``` value in the desired properties to: http://universaldecoder:8080/api/ A list of all available decoders can be retrieved by calling the endpoint: http://universaldecoder:8080/decoders ``` Again make sure to choose all lowercase letters for the module name to make sure it is reachable. In case the custom decoder is unreachable, throws an error or return invalid JSON, the error message will be shown in your device's messages in IoT Hub.","title":"Universal Decoder"},{"location":"samples/decoders/universal/#universal-decoder","text":"This project gives access to decoders in the TTN repo through a HTTP REST interface compliant with the LoraWan implementation in this repository. Codecs provided by TTN are stored in a well defined folder structure . The universal decoder copies the codec files into its docker image at build time for later use from the web application. As currently codecs are not implemented as node modules (see open issue ), these files were patched accordingly after being copied so that they can be imported and reused.","title":"Universal Decoder"},{"location":"samples/decoders/universal/#quick-start","text":"Install node dependencies and copy/patch codecs from the TTN repository: npm install npm run codecs Create docker image (replace amd64 with the architecture of your choice) docker build . -f Dockerfile.amd64 -t universaldecoder Run docker image: docker run --rm -d -p 8080 :8080 universaldecoder Call the built-in DecoderValueSensor decoder at the following url. You should see the result as JSON string. http://localhost:8080/api/DecoderValueSensor?devEui=0000000000000000&fport=1&payload=QUJDREUxMjM0NQ%3D%3D Finally list all available decoders with the following url: http://localhost:8080/decoders You can finally call any other supported decoder at: http://localhost:8080/api/<decoder>?devEui=0000000000000000&fport=<fport>&payload=<payload>","title":"Quick start"},{"location":"samples/decoders/universal/#local-development","text":"","title":"Local development"},{"location":"samples/decoders/universal/#start-local-server","text":"npm start You can access the universal decoder at the url available in the output of the previous command.","title":"Start local server"},{"location":"samples/decoders/universal/#run-tests","text":"npm test","title":"Run tests"},{"location":"samples/decoders/universal/#universal-decoder-rest-api","text":"The url accepted by the universal decoder follows the pattern: /api/<decoder>?devEui=<devEui>&fport=<fport>&payload=<payload>","title":"Universal Decoder REST API"},{"location":"samples/decoders/universal/#decoder","text":"This path parameter identifies the TTN decoder that will be used. You can get a list of all available decoders by calling the /decoders endpoint.","title":"decoder"},{"location":"samples/decoders/universal/#deveui","text":"LoRaWan unique end-device identifier.","title":"devEui"},{"location":"samples/decoders/universal/#fport","text":"LoRaWan Port field as integer value.","title":"fport"},{"location":"samples/decoders/universal/#payload","text":"Base64 and URL encoded payload to decode. For example, to test a payload of ABCDE12345 , you: Convert it to a base64 encoded string: QUJDREUxMjM0NQ== Convert the result to a valid URL parameter: QUJDREUxMjM0NQ%3D%3D Add this to your URL as the payload query parameter.","title":"payload"},{"location":"samples/decoders/universal/#deploying-to-azure-iot-edge","text":"","title":"Deploying to Azure IoT Edge"},{"location":"samples/decoders/universal/#push-docker-image-to-registry","text":"Create a docker image from your finished solution based on the target architecture and host it in an Azure Container Registry , on DockerHub or in any other container registry of your choice. Install the Azure IoT Edge for Visual Studio Code extension to build and push the Docker image. Make sure you are logged in to the Azure Container Registry you are using. Run docker login <mycontainerregistry>.azurecr.io on your development machine, or az acr login -n mycontainerregistry if the Azure CLI is available. Edit the file module.json to contain your container registry address, image name and version number: We provide the Dockerfiles for the following architectures: Dockerfile.amd64 Dockerfile.arm32v7 Dockerfile.arm64v8 To build the Docker image, right-click on the module.json file and select \"Build IoT Edge Module Image\" or \"Build and Push IoT Edge Module Image\". Select the architecture you want to build for from the drop-down menu. To temporarily test the container running you decoder using a webbrowser or Postman, you can manually start it in Docker and bind the container's port 8080 to a free port on your host machine (8080 is usually good). docker run --rm -it -p 8080 :8080 --name universaldecoder <container registry>/<image>:<tag> ```` Call the built-in ` DecoderValueSensor ` decoder at the following url: http://localhost:8080/api/DecoderValueSensor?devEui=0000000000000000&fport=1&payload=QUJDREUxMjM0NQ%3D%3D ### Deploy to IoT Edge If required, add credentials to access your container registry to the IoT Edge device by adding them to IoT Hub &rarr; IoT Edge &rarr; Your Device &rarr; Set Modules &rarr; Container Registry settings. ![Decoder Sample - Edge Module Container Registry Permission](../../images/decodersample-edgepermission.png) Configure your IoT Edge gateway device to include the custom container. IoT Hub &rarr; IoT Edge &rarr; Your Device &rarr; Set Modules &rarr; Deployment Modules &rarr; Add &rarr; IoT Edge Module. Set the module Name and Image URI, pointing to your image created above. **Make sure to choose all lowercase letters for the Module Name as the container will be unreachable otherwise!** ![Decoder Sample - Edge Module](../../images/decodersample-edgemodule.png) To activate the decoder for a LoRa device, navigate to your IoT Hub &rarr; IoT Devices &rarr; Device Details &rarr; Device Twin and set the ```SensorDecoder``` value in the desired properties to: http://universaldecoder:8080/api/ A list of all available decoders can be retrieved by calling the endpoint: http://universaldecoder:8080/decoders ``` Again make sure to choose all lowercase letters for the module name to make sure it is reachable. In case the custom decoder is unreachable, throws an error or return invalid JSON, the error message will be shown in your device's messages in IoT Hub.","title":"Push docker image to registry"},{"location":"spikes/azure-sphere/","text":"What is Azure Sphere Azure Sphere is a security service combining hardware, an OS, and cloud services to secure IoT applications. Together these three components ensure The Seven Properties of Highly Secure Devices . Pricing : one time purchase of hardware only (no recurring fees) Advantages for the starter kit Automated management of the underlying OS and the images for the concentrators. Although some features are already supported e.g. password-less authentication or error reporting, we could benefit from additional built-in features, e.g: hardware security automated security updates to address newly discovered vulnerabilities Cost savings: considering the maintenance required for the concentrators, the additional or more expensive hardware could be justified or even be cheaper in the long term. Disadvantages Requires specific hardware with limited choices so far (some also out of stock) There is a LoRaWAN concentrator built from Miromico However it only works with the Packet Forwarder for now. Miromico are aware of this limitation but we are not sure when they plan to support LBS. Introduces another layer that needs to be considered. In order for the concentrators to receive over-the-air updates, they need Internet connectivity which could be a potential attack vector. Currently concentrators only need to connect to an LNS. Integration with other Azure services Azure Sphere can be used together with IoT Hub or IoT Central : you need to register the Sphere tenant certificate to the IoT Hub It can also be used together with IoT Edge : an Azure IoT Edge device would act as a transparent gateway. On Azure Sphere Vs RTOS : Sphere focuses on security while RTOS is more generic/requires more manual maintenance/setting-up. The two can be combined though Process for the concentrators A brief recap of the steps as they are listed in the quickstart with some additional notes: Get the hardware (either a new device or \"guardian module\" that is \"attached\" to existing hardware) Install SDK/CLI + VS extension and connect the Sphere device to the PC Create a \"tenant\" Note this is different than a Active Directory tenant Register the tenant's certificate to IoT Hub Claim the device : one-time operation that can not be undone Configure networking Using existing devices A guardian module is add-on hardware that incorporates an Azure Sphere chip and physically attaches to a port on a \"brownfield\" device\u2014that is, an existing device that may already be in use. Docs List of hardware includes only 2 devices (see guardian devices) . Connectivity upstream to the cloud can be Ethernet, wifi or cellular downstream can be serial, ethernet, wireless Resources - activity IoT show episode discussing Azure Sphere on the Miromico LoRaWAN gateway Releases happen on a monthly cadence - last release on Jan 26 was cancelled but otherwise seems actively developed. Community Stack Overflow questions Azure Q&A","title":"What is Azure Sphere"},{"location":"spikes/azure-sphere/#what-is-azure-sphere","text":"Azure Sphere is a security service combining hardware, an OS, and cloud services to secure IoT applications. Together these three components ensure The Seven Properties of Highly Secure Devices . Pricing : one time purchase of hardware only (no recurring fees)","title":"What is Azure Sphere"},{"location":"spikes/azure-sphere/#advantages-for-the-starter-kit","text":"Automated management of the underlying OS and the images for the concentrators. Although some features are already supported e.g. password-less authentication or error reporting, we could benefit from additional built-in features, e.g: hardware security automated security updates to address newly discovered vulnerabilities Cost savings: considering the maintenance required for the concentrators, the additional or more expensive hardware could be justified or even be cheaper in the long term.","title":"Advantages for the starter kit"},{"location":"spikes/azure-sphere/#disadvantages","text":"Requires specific hardware with limited choices so far (some also out of stock) There is a LoRaWAN concentrator built from Miromico However it only works with the Packet Forwarder for now. Miromico are aware of this limitation but we are not sure when they plan to support LBS. Introduces another layer that needs to be considered. In order for the concentrators to receive over-the-air updates, they need Internet connectivity which could be a potential attack vector. Currently concentrators only need to connect to an LNS.","title":"Disadvantages"},{"location":"spikes/azure-sphere/#integration-with-other-azure-services","text":"Azure Sphere can be used together with IoT Hub or IoT Central : you need to register the Sphere tenant certificate to the IoT Hub It can also be used together with IoT Edge : an Azure IoT Edge device would act as a transparent gateway. On Azure Sphere Vs RTOS : Sphere focuses on security while RTOS is more generic/requires more manual maintenance/setting-up. The two can be combined though","title":"Integration with other Azure services"},{"location":"spikes/azure-sphere/#process-for-the-concentrators","text":"A brief recap of the steps as they are listed in the quickstart with some additional notes: Get the hardware (either a new device or \"guardian module\" that is \"attached\" to existing hardware) Install SDK/CLI + VS extension and connect the Sphere device to the PC Create a \"tenant\" Note this is different than a Active Directory tenant Register the tenant's certificate to IoT Hub Claim the device : one-time operation that can not be undone Configure networking","title":"Process for the concentrators"},{"location":"spikes/azure-sphere/#using-existing-devices","text":"A guardian module is add-on hardware that incorporates an Azure Sphere chip and physically attaches to a port on a \"brownfield\" device\u2014that is, an existing device that may already be in use. Docs List of hardware includes only 2 devices (see guardian devices) . Connectivity upstream to the cloud can be Ethernet, wifi or cellular downstream can be serial, ethernet, wireless","title":"Using existing devices"},{"location":"spikes/azure-sphere/#resources-activity","text":"IoT show episode discussing Azure Sphere on the Miromico LoRaWAN gateway Releases happen on a monthly cadence - last release on Jan 26 was cancelled but otherwise seems actively developed. Community Stack Overflow questions Azure Q&A","title":"Resources - activity"},{"location":"spikes/distributed_tracing/","text":"Distributed Tracing with IoT Edge Challenge Processing of telemetry data coming from an edge device may include multiple running pieces. For example: sensor->module 1->module-2>IoT Hub->function 1->microservice 1->microservice 2->storage. While diagnosing and troubleshooting a problem such as \"the data didn't arrive to the storage\" or even worse \"the data arrived but it's not what was expected\", it's hard to \"trace\" how the data was traveling and what was happening at every single station. Hence distributed \"tracing\". As a matter of fact, in many cases we know how the data was traveling as the flows are mostly straight forward, but we don't know what was happening at every point in the flow when this specific data was processed. This is the real challenge. In IoT world the solution is getting more complicated as the flow consists of two parts: device and the cloud. While the flow steps in the cloud always have a direct access to the cloud tracing services (App Insights) and can flush their tracing data just on-the-fly, the steps happening in the device don't have this privilege as they are often offline and connection to the cloud service is very limited/restricted. Besides the standard use-case of sending telemetry data from devices to the cloud, there are other scenarios which would also benefit from distributed tracing functionality: Device-to-cloud file upload Cloud-to-device messages Cloud-to-device direct method invocation Direct access to external/cloud services from the device IoT Hub offering There is a single resource that touches distributed tracing with IoT Hub: Trace Azure IoT device-to-cloud messages with distributed tracing . The preview IoT Hub feature which is described in the guidance is supposed to do the following: On message arrival from a device, IoT Hub generates a globally unique \"correlationId\" IoT Hub logs to Log Analytics/Event Hub a record under \"DistributedTracing\" category signaling that a message has arrived with DiagnosticIoTHubD2C operation. When IoT Hub writes the message to internal/built-in Event Hub it logs a record under \"DistributedTracing\" category to signal that event with DiagnosticIoTHubIngress operation. When there is a routing configured for the message and the message is written to an endpoint, IoT Hub logs a record under \"DistributedTracing\" category to signal that event with DiagnosticIoTHubEgress operation. All this is supposed to work only if a device uses C SDK for the communication or constructs a message manually handling all required properties. To summarize: The \"distributed tracing\" feature logs three steps of a message processing inside IoT Hub. These three log records are tied by generated \"correlationId\". This feature doesn't work . The guidance is referring to outdated/archived repo samples that are broken too . But even if it worked, it would cover only a tiny piece in the whole flow - internal IoT Hub message processing, which is not that interesting after all. The picture is way bigger. Approach Instrument custom modules on IoT Edge device with OpenTelemetry to report tracing. Instrument IoT Hub module with OpenTelemetry to report tracing. Since all communication on the device is routed through IoT Hub module this will give a lot of tracing data even without instrumenting other modules on the device. It will also help with use-cases like c2d, upload files, etc. The key component to route OpenTelemetry tracing data to the observability backend (e.g. App Insights, Jaeger, Zipkin, etc.) is OpenTelemetry Collector which may work on the device as a module and in the cloud as an Azure Function or K8s microservice. All modules on the device should export tracing data to OpenTelemetry Collector Module via OpenTelemetry Protocol Exporter (e.g. with OTLP exporter ). This decouples the module code from the details on how/where the tracing data is going to be used. On the devices that are mostly/normally online, the OpenTelemetry Collector Module is configured to receive traces with OTLP Receiver and to export traces to Azure Monitor (App Insights) via Azure Monitor Exporter for OpenTelemetry Collector Alternatively, the devices that are always online (can't work otherwise) and have a stable connection with the cloud (like in LoRaWan case) may have custom modules export tracing data directly to App Insights with Azure Monitor OpenTelemetry exporter . In this case they don't need to have OpenTelemetry Collector Module on the device. On the devices that may be normally offline, the OpenTelemetry Collector Module is configured to export traces to Azure Blob Storage module (an OpenTelemetry Collector exporter for that should be implemented in this repo ). Once the module is online the traces will be replicated automatically to the storage account in the cloud. On the cloud side there is an OpenTelemetry Collector instance running and receiving traces from the storage with Azure Storage receiver (to be implemented in this repo ) and exports traces to Azure Monitor via Azure Monitor Exporter for OpenTelemetry Collector . Alternatively, for the devices that are mostly offline and/or not supposed to report much to the cloud, the tracing data can be forwarded by OpenTelemetry Collector Module to an open source observability backend (e.g. Jaeger, Zipkin) using one of available exporters . Alternatively, until Azure Storage receiver for OpenTelemetry Collector is implemented, a cloud workflow could be used to import traces from Azure Storage to the OpenTelemetry Collector. A cloud workflow typically consists of Event Hub listening for traces arrival to the storage and an Azure function triggering on that event. The function uses OTLP to export traces to the collector. All services in the cloud, that are included in the flow may export OpenTelemetry traces to Azure Monitor with the direct exporter from the code or they may use OTLP to export traces to the OpenTelemetry Collector instance in the cloud. The latter covers cases when services are not implemented with one of supported by Azure Monitor languages , for example GoLang. All steps in the flow (modules on the device and services in the cloud) should leverage OpenTelemetry Tracing API components such as Span Attributes to store deviceid, sensorid, gateway, etc. and Span Events to store essential logs that should be exported with tracing data. D2C and C2D messages should contain tracing span context injected in the message system properties. It can be extracted and used by receiving modules and backend services to continue the trace . This may require using Context propagation techniques . Resources Trace Azure IoT device-to-cloud messages with distributed tracing E2E diagnostic provision CLI E2E diagnostic event hub function OpenTelemetry and Tracing OpenTelemetry Collector Azure Monitor Exporter for OpenTelemetry Collector OpenTelemetry .Net API Sending telemetry to Azure Monitor","title":"Distributed Tracing with IoT Edge"},{"location":"spikes/distributed_tracing/#distributed-tracing-with-iot-edge","text":"","title":"Distributed Tracing with IoT Edge"},{"location":"spikes/distributed_tracing/#challenge","text":"Processing of telemetry data coming from an edge device may include multiple running pieces. For example: sensor->module 1->module-2>IoT Hub->function 1->microservice 1->microservice 2->storage. While diagnosing and troubleshooting a problem such as \"the data didn't arrive to the storage\" or even worse \"the data arrived but it's not what was expected\", it's hard to \"trace\" how the data was traveling and what was happening at every single station. Hence distributed \"tracing\". As a matter of fact, in many cases we know how the data was traveling as the flows are mostly straight forward, but we don't know what was happening at every point in the flow when this specific data was processed. This is the real challenge. In IoT world the solution is getting more complicated as the flow consists of two parts: device and the cloud. While the flow steps in the cloud always have a direct access to the cloud tracing services (App Insights) and can flush their tracing data just on-the-fly, the steps happening in the device don't have this privilege as they are often offline and connection to the cloud service is very limited/restricted. Besides the standard use-case of sending telemetry data from devices to the cloud, there are other scenarios which would also benefit from distributed tracing functionality: Device-to-cloud file upload Cloud-to-device messages Cloud-to-device direct method invocation Direct access to external/cloud services from the device","title":"Challenge"},{"location":"spikes/distributed_tracing/#iot-hub-offering","text":"There is a single resource that touches distributed tracing with IoT Hub: Trace Azure IoT device-to-cloud messages with distributed tracing . The preview IoT Hub feature which is described in the guidance is supposed to do the following: On message arrival from a device, IoT Hub generates a globally unique \"correlationId\" IoT Hub logs to Log Analytics/Event Hub a record under \"DistributedTracing\" category signaling that a message has arrived with DiagnosticIoTHubD2C operation. When IoT Hub writes the message to internal/built-in Event Hub it logs a record under \"DistributedTracing\" category to signal that event with DiagnosticIoTHubIngress operation. When there is a routing configured for the message and the message is written to an endpoint, IoT Hub logs a record under \"DistributedTracing\" category to signal that event with DiagnosticIoTHubEgress operation. All this is supposed to work only if a device uses C SDK for the communication or constructs a message manually handling all required properties. To summarize: The \"distributed tracing\" feature logs three steps of a message processing inside IoT Hub. These three log records are tied by generated \"correlationId\". This feature doesn't work . The guidance is referring to outdated/archived repo samples that are broken too . But even if it worked, it would cover only a tiny piece in the whole flow - internal IoT Hub message processing, which is not that interesting after all. The picture is way bigger.","title":"IoT Hub offering"},{"location":"spikes/distributed_tracing/#approach","text":"Instrument custom modules on IoT Edge device with OpenTelemetry to report tracing. Instrument IoT Hub module with OpenTelemetry to report tracing. Since all communication on the device is routed through IoT Hub module this will give a lot of tracing data even without instrumenting other modules on the device. It will also help with use-cases like c2d, upload files, etc. The key component to route OpenTelemetry tracing data to the observability backend (e.g. App Insights, Jaeger, Zipkin, etc.) is OpenTelemetry Collector which may work on the device as a module and in the cloud as an Azure Function or K8s microservice. All modules on the device should export tracing data to OpenTelemetry Collector Module via OpenTelemetry Protocol Exporter (e.g. with OTLP exporter ). This decouples the module code from the details on how/where the tracing data is going to be used. On the devices that are mostly/normally online, the OpenTelemetry Collector Module is configured to receive traces with OTLP Receiver and to export traces to Azure Monitor (App Insights) via Azure Monitor Exporter for OpenTelemetry Collector Alternatively, the devices that are always online (can't work otherwise) and have a stable connection with the cloud (like in LoRaWan case) may have custom modules export tracing data directly to App Insights with Azure Monitor OpenTelemetry exporter . In this case they don't need to have OpenTelemetry Collector Module on the device. On the devices that may be normally offline, the OpenTelemetry Collector Module is configured to export traces to Azure Blob Storage module (an OpenTelemetry Collector exporter for that should be implemented in this repo ). Once the module is online the traces will be replicated automatically to the storage account in the cloud. On the cloud side there is an OpenTelemetry Collector instance running and receiving traces from the storage with Azure Storage receiver (to be implemented in this repo ) and exports traces to Azure Monitor via Azure Monitor Exporter for OpenTelemetry Collector . Alternatively, for the devices that are mostly offline and/or not supposed to report much to the cloud, the tracing data can be forwarded by OpenTelemetry Collector Module to an open source observability backend (e.g. Jaeger, Zipkin) using one of available exporters . Alternatively, until Azure Storage receiver for OpenTelemetry Collector is implemented, a cloud workflow could be used to import traces from Azure Storage to the OpenTelemetry Collector. A cloud workflow typically consists of Event Hub listening for traces arrival to the storage and an Azure function triggering on that event. The function uses OTLP to export traces to the collector. All services in the cloud, that are included in the flow may export OpenTelemetry traces to Azure Monitor with the direct exporter from the code or they may use OTLP to export traces to the OpenTelemetry Collector instance in the cloud. The latter covers cases when services are not implemented with one of supported by Azure Monitor languages , for example GoLang. All steps in the flow (modules on the device and services in the cloud) should leverage OpenTelemetry Tracing API components such as Span Attributes to store deviceid, sensorid, gateway, etc. and Span Events to store essential logs that should be exported with tracing data. D2C and C2D messages should contain tracing span context injected in the message system properties. It can be extracted and used by receiving modules and backend services to continue the trace . This may require using Context propagation techniques .","title":"Approach"},{"location":"spikes/distributed_tracing/#resources","text":"Trace Azure IoT device-to-cloud messages with distributed tracing E2E diagnostic provision CLI E2E diagnostic event hub function OpenTelemetry and Tracing OpenTelemetry Collector Azure Monitor Exporter for OpenTelemetry Collector OpenTelemetry .Net API Sending telemetry to Azure Monitor","title":"Resources"},{"location":"spikes/moduleclient_upstream_messages/","text":"ModuleClient for upstream telemetry as an alternative to DeviceClient Challenge In LoRaWAN Starter Kit, each sensor has its own identity in IoT Hub device registry. This allows kit users to use such identities for both sending telemetry messages and storing a state in device twin for LoRa specific properties (i.e.: session keys, frame counter, dwell time settings et cetera). During load tests it was noticed that, if a device is in reach of multiple LoRaWAN Network Servers, the related edgeHub modules are fighting each other for acquiring and keeping the connection open for all the operations mentioned above. When trying to handle approximately more than one hundred of leaf devices like this, a slow-down of the solution was noticed, in addition with some dropped upstream messages. We think it is very critical to not drop any upstream message, therefore we should try to find some alternatives. Approach The approach being considered in this document is still making use of Microsoft.Azure.Devices.Client.DeviceClient for twin operations and C2D messages only, while routing telemetry data through the LoRaWAN Network Server Microsoft.Azure.Devices.Client.ModuleClient . This idea is trying to reduce dramatically the amount of links needed for sending telemetry upstream, by enqueueing telemetry messages on the LNS IoT Edge module outputs. Load test result Connected_Factory_Load_Test_Scenario was chosen as test for understanding the behaviour of the proposed approach. After modifying the 2.0.0 code base with the required changes, the test bench was setup with 1500 leaf devices, running in 2 factories, with 1 LNS per factory and 2 concentrators per LNS. IoT Hub was sized to 1x S3 unit, in order to not be throttled on twin operations. While executing the test, we were able to observe that no upstream message was dropped. Nevertheless, the \"connection ping-pong\" caused other issues like delays in twin updates, causing some delays/retries for OTAA join requests, and inability of sending acknowledgment on time for the expected receive windows (20% of the acknowledgements was dropped). Conclusions Advantages This approach is fairly easy to implement and requires very small change in current code base Using a ModuleClient is allowing to have a higher guarantee of delivering the telemetry messages The connection ping-pong of DeviceClients, is partially mitigated. Even though the ping-pong is still there, this is not impacting the crucial telemetry operations Disadvantages The \"identity\" of the device which generated the message is lost. In IoT Hub, messages would be received from the LNS IoT Edge module of the IoT Edge gateway where the solution is running. While it's theoretically still possible to identify the originating device (i.e. by setting a message property), this would be a breaking change requiring a substantial change in all the applications currently consuming the data in IoT Hub. This solution, per-se, is not enough to completely solve the connection ping-pong issue, therefore additional measures should be taken (i.e. LNS affinity)","title":"ModuleClient for upstream telemetry as an alternative to DeviceClient"},{"location":"spikes/moduleclient_upstream_messages/#moduleclient-for-upstream-telemetry-as-an-alternative-to-deviceclient","text":"","title":"ModuleClient for upstream telemetry as an alternative to DeviceClient"},{"location":"spikes/moduleclient_upstream_messages/#challenge","text":"In LoRaWAN Starter Kit, each sensor has its own identity in IoT Hub device registry. This allows kit users to use such identities for both sending telemetry messages and storing a state in device twin for LoRa specific properties (i.e.: session keys, frame counter, dwell time settings et cetera). During load tests it was noticed that, if a device is in reach of multiple LoRaWAN Network Servers, the related edgeHub modules are fighting each other for acquiring and keeping the connection open for all the operations mentioned above. When trying to handle approximately more than one hundred of leaf devices like this, a slow-down of the solution was noticed, in addition with some dropped upstream messages. We think it is very critical to not drop any upstream message, therefore we should try to find some alternatives.","title":"Challenge"},{"location":"spikes/moduleclient_upstream_messages/#approach","text":"The approach being considered in this document is still making use of Microsoft.Azure.Devices.Client.DeviceClient for twin operations and C2D messages only, while routing telemetry data through the LoRaWAN Network Server Microsoft.Azure.Devices.Client.ModuleClient . This idea is trying to reduce dramatically the amount of links needed for sending telemetry upstream, by enqueueing telemetry messages on the LNS IoT Edge module outputs.","title":"Approach"},{"location":"spikes/moduleclient_upstream_messages/#load-test-result","text":"Connected_Factory_Load_Test_Scenario was chosen as test for understanding the behaviour of the proposed approach. After modifying the 2.0.0 code base with the required changes, the test bench was setup with 1500 leaf devices, running in 2 factories, with 1 LNS per factory and 2 concentrators per LNS. IoT Hub was sized to 1x S3 unit, in order to not be throttled on twin operations. While executing the test, we were able to observe that no upstream message was dropped. Nevertheless, the \"connection ping-pong\" caused other issues like delays in twin updates, causing some delays/retries for OTAA join requests, and inability of sending acknowledgment on time for the expected receive windows (20% of the acknowledgements was dropped).","title":"Load test result"},{"location":"spikes/moduleclient_upstream_messages/#conclusions","text":"","title":"Conclusions"},{"location":"spikes/moduleclient_upstream_messages/#advantages","text":"This approach is fairly easy to implement and requires very small change in current code base Using a ModuleClient is allowing to have a higher guarantee of delivering the telemetry messages The connection ping-pong of DeviceClients, is partially mitigated. Even though the ping-pong is still there, this is not impacting the crucial telemetry operations","title":"Advantages"},{"location":"spikes/moduleclient_upstream_messages/#disadvantages","text":"The \"identity\" of the device which generated the message is lost. In IoT Hub, messages would be received from the LNS IoT Edge module of the IoT Edge gateway where the solution is running. While it's theoretically still possible to identify the originating device (i.e. by setting a message property), this would be a breaking change requiring a substantial change in all the applications currently consuming the data in IoT Hub. This solution, per-se, is not enough to completely solve the connection ping-pong issue, therefore additional measures should be taken (i.e. LNS affinity)","title":"Disadvantages"},{"location":"tools/arduino-samples/","text":"Arduino Samples Arduino samples can be found on the Arduino folder in the repository root. This code is built to be used for the Seeduino LoRaWan but can serve as reference for other platforms. We have region based examples for OTAA and ABP scenarios. Please follow the documentation to set up the device Accessing the library files locally There are multiple scenarios where we would want to have the libraries be modified (listed here below). To access the local installation, open your Arduino IDE, go to File -> Preferences and click on the line after \"more preference can be edited directly in the file\". Go next to the path packages/Seeeduino/hardware/samd/1.8.2/libraries/LoRaWan and open LoRaWan.cpp and LoRaWan.h in a text editor. CN library changes To run our China samples some changes to the library need to be done as described below. paste the following in the LoRaWan.h file: void setChannelON ( unsigned char channel ); void setChannelOFF ( unsigned char channel ); and respectively in the LoRaWan.cpp file: void LoRaWanClass::setChannelON ( unsigned char channel ) { char cmd [ 32 ]; memset ( cmd , 0 , 32 ); sprintf ( cmd , \"AT+CH=%d, ON \\r\\n \" , channel , ( short ) channel ); sendCommand ( cmd ); #if _DEBUG_SERIAL_ loraDebugPrint ( DEFAULT_DEBUGTIME ); #endif delay ( DEFAULT_TIMEWAIT ); } void LoRaWanClass::setChannelOFF ( unsigned char channel ) { char cmd [ 32 ]; memset ( cmd , 0 , 32 ); sprintf ( cmd , \"AT+CH=%d, OFF \\r\\n \" , channel , ( short ) channel ); sendCommand ( cmd ); #if _DEBUG_SERIAL_ loraDebugPrint ( DEFAULT_DEBUGTIME ); #endif delay ( DEFAULT_TIMEWAIT ); } Activate Arduino debug mode The following changes on the library can be done to enable debug mode on the seeduino device. This will get aditional details on the device transmission and operations. paste the following in the LoRaWan.h file: void setDebug (); and respectively in the LoRaWan.cpp file: void LoRaWanClass::setDebug () { sendCommand ( \"AT+LOG=DEBUG \\r\\n \" ); }","title":"Arduino Samples"},{"location":"tools/arduino-samples/#arduino-samples","text":"Arduino samples can be found on the Arduino folder in the repository root. This code is built to be used for the Seeduino LoRaWan but can serve as reference for other platforms. We have region based examples for OTAA and ABP scenarios. Please follow the documentation to set up the device","title":"Arduino Samples"},{"location":"tools/arduino-samples/#accessing-the-library-files-locally","text":"There are multiple scenarios where we would want to have the libraries be modified (listed here below). To access the local installation, open your Arduino IDE, go to File -> Preferences and click on the line after \"more preference can be edited directly in the file\". Go next to the path packages/Seeeduino/hardware/samd/1.8.2/libraries/LoRaWan and open LoRaWan.cpp and LoRaWan.h in a text editor.","title":"Accessing the library files locally"},{"location":"tools/arduino-samples/#cn-library-changes","text":"To run our China samples some changes to the library need to be done as described below. paste the following in the LoRaWan.h file: void setChannelON ( unsigned char channel ); void setChannelOFF ( unsigned char channel ); and respectively in the LoRaWan.cpp file: void LoRaWanClass::setChannelON ( unsigned char channel ) { char cmd [ 32 ]; memset ( cmd , 0 , 32 ); sprintf ( cmd , \"AT+CH=%d, ON \\r\\n \" , channel , ( short ) channel ); sendCommand ( cmd ); #if _DEBUG_SERIAL_ loraDebugPrint ( DEFAULT_DEBUGTIME ); #endif delay ( DEFAULT_TIMEWAIT ); } void LoRaWanClass::setChannelOFF ( unsigned char channel ) { char cmd [ 32 ]; memset ( cmd , 0 , 32 ); sprintf ( cmd , \"AT+CH=%d, OFF \\r\\n \" , channel , ( short ) channel ); sendCommand ( cmd ); #if _DEBUG_SERIAL_ loraDebugPrint ( DEFAULT_DEBUGTIME ); #endif delay ( DEFAULT_TIMEWAIT ); }","title":"CN library changes"},{"location":"tools/arduino-samples/#activate-arduino-debug-mode","text":"The following changes on the library can be done to enable debug mode on the seeduino device. This will get aditional details on the device transmission and operations. paste the following in the LoRaWan.h file: void setDebug (); and respectively in the LoRaWan.cpp file: void LoRaWanClass::setDebug () { sendCommand ( \"AT+LOG=DEBUG \\r\\n \" ); }","title":"Activate Arduino debug mode"},{"location":"tools/certificate-generation/","text":"Basic Station Certificates Generation This starter kit is providing a BasicStation Certificates Generation tool for helping its users to generate LoRaWAN Network Server certificates and Basics Station certificates for testing secure communication between a Basics Station client and the CUPS/LNS Protocol Endpoint in Network Server. The starter kit, and, therefore also this tool, are expecting the same certificate sets for both CUPS and LNS endpoints. Only for testing In a production environment, you should not use certificates provided by this tool, but generate and sign certificates with a trusted root authority. Generate a server certificate As an example, if you want to generate a server certificate for a LoRaWAN Network Server hosted at mytest.endpoint.com and secure the output .PFX with a passphrase, you will need to issue the following script in the Tools\\BasicStation-Certificates-Generation folder of the Starter Kit: ./certificate-generate.sh server mytest.endpoint.com chosenPfxPassword IMPORTANT when running the Basic Station client with Server Authentication enabled, the common name of the Server Certificate should exactly match the hostname specified in cups.uri/tc.uri. Even though this is decreasing security, it is possible to disable SNI by setting the ' TLS_SNI ' environment variable to false when executing the Basic Station client (or provided LoRaBasicsStationModule) The previous command will both generate a self-signed certificate authority (located in the 'ca' folder) and a mytest.endpoint.com.pfx (located in 'server' folder) You can now follow previous sections instructions on how to import this certificate in the provided LoRaWanNetworkSrvModule. Generate a client certificate As an example, if you want to generate a client certificate for a Basic Station with DevEUI 'AABBCCFFFE001122', you will need to issue the following command ./certificate-generate.sh client AABBCCFFFE001122 IMPORTANT for client authentication to successfully work, the Common Name of the certificate should exactly match the DevEUI of the Basic Station. The previous command will generate the following files in the 'client' subfolder: AABBCCFFFE001122.crt (the client certificate in DER format) AABBCCFFFE001122.key (the client certificate key in DER format) AABBCCFFFE001122.trust (the root certificate in DER format) AABBCCFFFE001122.bundle (the concatenation of the three above mentioned files, useful if you want to use CUPS) As soon as certificates are generated, you can now follow previous sections instructions on how to import this certificate in the provided LoRaBasicsStationModule or you can just copy the needed files to your Basic Station compatible concentrator.","title":"Basic Station Certificates Generation"},{"location":"tools/certificate-generation/#basic-station-certificates-generation","text":"This starter kit is providing a BasicStation Certificates Generation tool for helping its users to generate LoRaWAN Network Server certificates and Basics Station certificates for testing secure communication between a Basics Station client and the CUPS/LNS Protocol Endpoint in Network Server. The starter kit, and, therefore also this tool, are expecting the same certificate sets for both CUPS and LNS endpoints. Only for testing In a production environment, you should not use certificates provided by this tool, but generate and sign certificates with a trusted root authority.","title":"Basic Station Certificates Generation"},{"location":"tools/certificate-generation/#generate-a-server-certificate","text":"As an example, if you want to generate a server certificate for a LoRaWAN Network Server hosted at mytest.endpoint.com and secure the output .PFX with a passphrase, you will need to issue the following script in the Tools\\BasicStation-Certificates-Generation folder of the Starter Kit: ./certificate-generate.sh server mytest.endpoint.com chosenPfxPassword IMPORTANT when running the Basic Station client with Server Authentication enabled, the common name of the Server Certificate should exactly match the hostname specified in cups.uri/tc.uri. Even though this is decreasing security, it is possible to disable SNI by setting the ' TLS_SNI ' environment variable to false when executing the Basic Station client (or provided LoRaBasicsStationModule) The previous command will both generate a self-signed certificate authority (located in the 'ca' folder) and a mytest.endpoint.com.pfx (located in 'server' folder) You can now follow previous sections instructions on how to import this certificate in the provided LoRaWanNetworkSrvModule.","title":"Generate a server certificate"},{"location":"tools/certificate-generation/#generate-a-client-certificate","text":"As an example, if you want to generate a client certificate for a Basic Station with DevEUI 'AABBCCFFFE001122', you will need to issue the following command ./certificate-generate.sh client AABBCCFFFE001122 IMPORTANT for client authentication to successfully work, the Common Name of the certificate should exactly match the DevEUI of the Basic Station. The previous command will generate the following files in the 'client' subfolder: AABBCCFFFE001122.crt (the client certificate in DER format) AABBCCFFFE001122.key (the client certificate key in DER format) AABBCCFFFE001122.trust (the root certificate in DER format) AABBCCFFFE001122.bundle (the concatenation of the three above mentioned files, useful if you want to use CUPS) As soon as certificates are generated, you can now follow previous sections instructions on how to import this certificate in the provided LoRaBasicsStationModule or you can just copy the needed files to your Basic Station compatible concentrator.","title":"Generate a client certificate"},{"location":"tools/cups-firmware-file-preparation/","text":"CUPS - Firmware update file preparation The 'firmware update file preparation' bash script is helping Azure IoT Edge LoRaWAN Starter Kit users to generate the files needed for executing a firmware upgrade. More information on how to execute a firmware update can be found in 'Firmware upgrade' section of this documentation. Usage: ./firmwarePrep.sh stationEui firmwareUpgradeFilePath Arguments: stationEui (REQUIRED) EUI of the target Basics Station firmwareUpgradeFilePath (REQUIRED) The path of the binary to be executed on Basics Station for upgrading the firmware The tool will generate three output files being: A sig-0.key to be placed on the Basics Station A sig-0.crc containing the checksum of the sig-0.key. This is required to understand which key generated the digest of the firmware upgrade file. This value has to be saved in the IoT Hub Device Twin for the Station, using the Device Provisioning tool. A fwUpdate.digest file containing the base64 encoding of the digest computed for the firmware upgrade file. This value has to be saved in the IoT Hub Device Twin for the Station, using the Device Provisioning tool.","title":"CUPS - Firmware update file preparation"},{"location":"tools/cups-firmware-file-preparation/#cups-firmware-update-file-preparation","text":"The 'firmware update file preparation' bash script is helping Azure IoT Edge LoRaWAN Starter Kit users to generate the files needed for executing a firmware upgrade. More information on how to execute a firmware update can be found in 'Firmware upgrade' section of this documentation. Usage: ./firmwarePrep.sh stationEui firmwareUpgradeFilePath Arguments: stationEui (REQUIRED) EUI of the target Basics Station firmwareUpgradeFilePath (REQUIRED) The path of the binary to be executed on Basics Station for upgrading the firmware The tool will generate three output files being: A sig-0.key to be placed on the Basics Station A sig-0.crc containing the checksum of the sig-0.key. This is required to understand which key generated the digest of the firmware upgrade file. This value has to be saved in the IoT Hub Device Twin for the Station, using the Device Provisioning tool. A fwUpdate.digest file containing the base64 encoding of the digest computed for the firmware upgrade file. This value has to be saved in the IoT Hub Device Twin for the Station, using the Device Provisioning tool.","title":"CUPS - Firmware update file preparation"},{"location":"tools/device-provisioning/","text":"LoRa Device Provisioning This is a Command Line Interface Provisioning Tool to list, query, verify add, update, and remove LoRaWAN leaf devices and LoRaWAN Basic Station devices configured in Azure IoT Hub for the Azure IoT Edge LoRaWAN Gateway project located at: http://aka.ms/lora Building You can create an platform specific executable by running dotnet publish -c Release -r win10-x64 dotnet publish -c Release -r linux-x64 dotnet publish -c Release -r osx-x64 See the .NET Core RID Catalog for a list of valid runtime identifiers. Running You can run the tool from the command line using .NET Core by executing the dotnet run command from the project folder dotnet run -- ( add verbs and parameters here ) or dotnet loradeviceprovisioning.dll from the bin folder. dotnet .\\ bin \\ Release \\ net6 . 0 \\ loradeviceprovisioning . dll -- ( add verbs and parameters here ) Setting up The tool can be configured through command line arguments and an appsettings.json file. Required command line arguments are specific to the command the user wants to run and are described later in this document. iothub-connection-string argument is required for all commands and needs to contain a connection string for the Azure IoT Hub you want to work with. The connection string needs to belong to a shared access policy with registry read , registry write and service connect permissions enabled. You can use the default policy named iothubowner . appsettings.json file only contains the Network Id ( NetId ) value which can be optionally overridden, in case your solution does not use the default Network Id 000001. To set your custom Network Id, create a local appsettings.local.json file with your own NetId value. Since just the last byte from this 3 hex string byte array (6 characters) are used to create a valid DevAddr for ABP LoRa devices, the setting can be either the full 3 bytes (000000 to FFFFFF) or just the shortened, last byte (0 to FF). Both appsettings files need to be in the same directory as the cli-lora-device-provisioning binary ( loradeviceprovisioning.dll or loradeviceprovisioning.exe ). { \"NetId\" : \"000001\" } The NetId value can also be overridden with a command line argument (using --netid option). To learn more about what each of the settings in the LoRa device twin does, refer to the Quick Start Guide . Supported commands The following verbs/commands are supported: verb description list List devices in IoT Hub. query Query a device twin. verify Verify a single device in IoT Hub. bulkverify Bulk verify all devices in IoT Hub. add Add a new device to IoT Hub. update Update an existing device in IoT Hub. remove Remove an existing device from IoT Hub. rotate-certificate Update a client certificate for a Basics Station. revoke Revoke a client certificate installed on a Basics Station. upgrade-firmware Trigger a firmware upgrade of a Basics Station. help Display more information on a specific command. version Display version information. list List the devices in IoT Hub and show their device twin. Example: dotnet run -- list - -iothub-connection-string < connection_string > The list verb supports the following parameters: parameter required description --iothub-connection-string yes Connection string of the IoT Hub. --page no Devices per page. Default is 10. --total no Maximum number of devices to list. Default is all. --help no Display this help screen. --version no Display version information. query Show the device twin for an existing device in IoT Hub by it's DevEUI / Device Id. Example: dotnet run -- query - -deveui 33CCC86800430010 - -iothub-connection-string < connection_string > The query verb supports the following parameters: parameter required description --deveui yes DevEUI / Device Id. --iothub-connection-string yes Connection string of the IoT Hub. --help no Display this help screen. --version no Display version information. verify Verify an existing device in IoT Hub by it's DevEUI / Device Id. Example: dotnet run -- verify - -deveui 33CCC86800430010 - -iothub-connection-string < connection_string > The verify verb supports the following parameters: parameter required description --deveui yes DevEUI / Device Id. --iothub-connection-string yes Connection string of the IoT Hub. --netid no Network ID (Only for ABP devices): A 3 bit hex string. Will default to 000001 or NetId set in settings file if left blank. --help no Display this help screen. --version no Display version information. bulkverify Bulk verify all devices in IoT Hub. Only shows the devices that have configuration errors and displays a summary in the end how many devcies are properly configured and how many contain errors. Example: dotnet run -- bulkverify - -page 10 - -iothub-connection-string < connection_string > The bulkverify verb supports the following parameters: parameter required description --iothub-connection-string yes Connection string of the IoT Hub. --page no Errors per page. Default is all. --help no Display this help screen. --version no Display version information. add Add a new device to IoT Hub. The data entered will be verified and only created in IoT Hub if it's valid. All required fields that are not provided will be automatically populated with valid, randomly generated by the tool. The only mandatory field is type which has to be set to either ABP or OTAA or concentrator . To learn more about what each of the settings in the LoRa device twin does, refer to the Quick Start Guide . Example: dotnet run -- add - -type abp - -deveui 33CCC86800430010 - -decoder http :// decodermodule / api / customdecoder - -iothub-connection-string < connection_string > The add verb supports the following parameters: parameter required description --type yes Device type: Must be ABP, OTAA or Concentrator. --region yes for 'Concentrator' type devices Must be the name of one of the regions in the DefaultRouterConfig folder. --stationeui yes for 'Concentrator' type devices A 16 bit hex string ('AABBCCDDEEFFGGHH'). --iothub-connection-string yes Connection string of the IoT Hub. --no-cups no No CUPS: Only applicable to 'Concentrator' type devices. If set to true indicates that the concentrator does not use CUPS. --certificate-bundle-location no Certificate bundle location: Required if --no-cups set to false. Points to the location of the (UTF-8-encoded) certificate bundle file. --client-certificate-thumbprint no Client certificate thumbprint: Required if --no-cups set to false. A list of client certificate thumbprints (separated by a space) that should be accepted by the CUPS/LNS endpoints. --tc-uri no LoRaWAN Network Server URI: Required if --no-cups set to false. The URI of the LNS endpoint. Protocol must be set to wss:// --cups-uri no LoRaWAN Network Server URI: Required if --no-cups set to false. The URI of the CUPS endpoint. Protocol must be set to https:// --deveui no DevEUI / Device Id: A 16 bit hex string. Will be randomly generated if left blank. --appskey no AppSKey (Only for ABP devices): A 16 bit hex string. Will be randomly generated if left blank. --nwkskey no NwkSKey (Only for ABP devices): A 16 bit hex string. Will be randomly generated if left blank. --devaddr no DevAddr (Only for ABP devices): A 4 bit hex string. Will be randomly generated if left blank. --netid no Network ID (Only for ABP devices): A 3 bit hex string. Will default to 000001 or NetId set in settings file if left blank. --abprelaxmode no ABPRelaxMode (ABP relaxed framecounter, only for ABP devices): True or false. --appeui no AppEUI (only for OTAA devices): A 16 bit hex string. Will be randomly generated if left blank. --appkey no AppKey (only for OTAA devices): A 16 bit hex string. Will be randomly generated if left blank. --gatewayid no GatewayID: A hostname. --decoder no SensorDecoder: The name of an integrated decoder function or the URI to a decoder in a custom decoder module in the format: http://modulename/api/decodername. --classtype no ClassType: \"A\" (default) or \"C\". --downlinkenabled no DownlinkEnabled: True or false. --preferredwindow no PreferredWindow (Preferred receive window): 1 or 2. --deduplication no Deduplication: None (default), Drop or Mark. --rx2datarate no Rx2DataRate (Receive window 2 data rate, currently only supported for OTAA devices): Any of the allowed data rates. EU: SF12BW125, SF11BW125, SF10BW125, SF8BW125, SF7BW125, SF7BW250 or 50. US: SF10BW125, SF9BW125, SF8BW125, SF7BW125, SF8BW500, SF12BW500, SF11BW500, SF10BW500, SF9BW500, SF8BW500, SF8BW500. --rx1droffset no Rx1DrOffset (Receive window 1 data rate offset, currently only supported for OTAA devices): 0 through 15. --rxdelay no RxDelay (Delay in seconds for sending downstream messages, currently only supported for OTAA devices): 0 through 15. --keepalivetimeout no KeepAliveTimeout (KeepAliveTimeout (Timeout in seconds before device client connection is closed): 0 or 60 and above. --supports32bitfcnt no Supports32BitFCnt (Support for 32bit frame counter): True or false. --fcntupstart no FCntUpStart (Frame counter up start value): 0 through 4294967295. --fcntdownstart no FCntDownStart (Frame counter down start value): 0 through 4294967295. --fcntresetcounter no FCntResetCounter (Frame counter reset counter value): 0 through 4294967295. --help no Display this help screen. --version no Display version information. update Update the twin information for an existing device. To remove an existing value that is currently set on the twin, pass it the value null . To learn more about what each of the settings in the LoRa device twin does, refer to the Quick Start Guide . Example: dotnet run -- update - -deveui 33CCC86800430010 - -decoder null - -iothub-connection-string < connection_string > The update verb supports the following parameters: parameter required description --deveui yes DevEUI / Device Id: A 16 bit hex string. --iothub-connection-string yes Connection string of the IoT Hub. --appskey no AppSKey (Only for ABP devices): A 16 bit hex string. --nwkskey no NwkSKey (Only for ABP devices): A 16 bit hex string. --devaddr no DevAddr (Only for ABP devices): A 4 bit hex string. --netid no Network ID (Only for ABP devices): A 3 bit hex string. Will default to 000001 or NetId set in settings file if left blank. --abprelaxmode no ABPRelaxMode (ABP relaxed framecounter, only for ABP devices): True or false. --appeui no AppEUI (only for OTAA devices): A 16 bit hex string. --appkey no AppKey (only for OTAA devices): A 16 bit hex string. --gatewayid no GatewayID: A hostname. --decoder no SensorDecoder: The name of an integrated decoder function or the URI to a decoder in a custom decoder module in the format: http://modulename/api/decodername . --classtype no ClassType: \"A\" (default) or \"C\". --downlinkenabled no DownlinkEnabled: True or false. --preferredwindow no PreferredWindow (Preferred receive window): 1 or 2. --deduplication no Deduplication: None (default), Drop or Mark. --rx2datarate no Rx2DataRate (Receive window 2 data rate, currently only supported for OTAA devices): Any of the allowed data rates. EU: SF12BW125, SF11BW125, SF10BW125, SF8BW125, SF7BW125, SF7BW250 or 50. US: SF10BW125, SF9BW125, SF8BW125, SF7BW125, SF8BW500, SF12BW500, SF11BW500, SF10BW500, SF9BW500, SF8BW500, SF8BW500. --rx1droffset no Rx1DrOffset (Receive window 1 data rate offset, currently only supported for OTAA devices): 0 through 15. --rxdelay no RxDelay (Delay in seconds for sending downstream messages, currently only supported for OTAA devices): 0 through 15. --keepalivetimeout no KeepAliveTimeout (KeepAliveTimeout (Timeout in seconds before device client connection is closed): 0 or 60 and above. --supports32bitfcnt no Supports32BitFCnt (Support for 32bit frame counter): True or false. --fcntupstart no FCntUpStart (Frame counter up start value): 0 through 4294967295. --fcntdownstart no FCntDownStart (Frame counter down start value): 0 through 4294967295. --fcntresetcounter no FCntResetCounter (Frame counter reset counter value): 0 through 4294967295. --help no Display this help screen. --version no Display version information. remove Remove an existing device from IoT Hub by it's DevEUI / Device Id. Example: dotnet run -- remove - -deveui 33CCC86800430010 - -iothub-connection-string < connection_string > The query verb supports the following parameters: parameter required description --deveui yes DevEUI / Device Id. --iothub-connection-string yes Connection string of the IoT Hub. --help no Display this help screen. --version no Display version information. rotate-certificate Triggers an update of a client certificate installed on the Basics Station. Example: dotnet run -- rotate-certificate - -stationeui 33CCC86800430010 - -certificate-bundle-location < bundle_location > - -client-certificate-thumbprint < thumbprint > - -iothub-connection-string < iothub_connection_string > - -storage-connection-string < storage_connection_string > parameter required description --stationeui yes Station EUI --certificate-bundle-location yes Location of the (UTF-8-encoded) certificate bundle file --client-certificate-thumbprint yes Client certificate thumbprint that should be accepted by the CUPS/LNS endpoints --iothub-connection-string yes Connection string of the IoT Hub --storage-connection-string yes Connection string of the Storage account revoke Revokes a client certificate installed on the Basics Station. Example: dotnet run -- revoke --stationeui 33CCC86800430010 --client-certificate-thumbprint <thumbprint> --iothub-connection-string <iothub_connection_string> parameter required description --stationeui yes Station EUI --client-certificate-thumbprint yes Client certificate thumbprint that should be revoked --iothub-connection-string yes Connection string of the IoT Hub upgrade-firmware Triggers a firmware upgrade of a Basics Station. To learn more about executing firmware upgrades, please refer to the Firmware upgrade user guide. Example: powershell dotnet run -- upgrade-firmware --stationeui <station_eui> --package <package_version> --firmware-location <firmware_file_path> --digest-location <digest_file_path> --checksum-location <checksum_file_path> --iothub-connection-string <iothub_connection_string> --storage-connection-string <storage_connection_string> The upgrade-firmware verb accepts the following parameters: parameter required description --stationeui yes Station EUI --package yes New package version (e.g. 1.0.1 ) --firmware-location yes Local file path of the firmware upgrade executable --digest-location yes Local file path of the file containing a digest of the firmware upgrade --checksum-location yes Local file path of the file containing a CRC32 checksum of the key used to generate the digest --iothub-connection-string yes Connection string of the IoT Hub. --storage-connection-string yes Connection string of the Storage account. --help no Display this help screen --version no Display version information","title":"LoRa Device Provisioning"},{"location":"tools/device-provisioning/#lora-device-provisioning","text":"This is a Command Line Interface Provisioning Tool to list, query, verify add, update, and remove LoRaWAN leaf devices and LoRaWAN Basic Station devices configured in Azure IoT Hub for the Azure IoT Edge LoRaWAN Gateway project located at: http://aka.ms/lora","title":"LoRa Device Provisioning"},{"location":"tools/device-provisioning/#building","text":"You can create an platform specific executable by running dotnet publish -c Release -r win10-x64 dotnet publish -c Release -r linux-x64 dotnet publish -c Release -r osx-x64 See the .NET Core RID Catalog for a list of valid runtime identifiers.","title":"Building"},{"location":"tools/device-provisioning/#running","text":"You can run the tool from the command line using .NET Core by executing the dotnet run command from the project folder dotnet run -- ( add verbs and parameters here ) or dotnet loradeviceprovisioning.dll from the bin folder. dotnet .\\ bin \\ Release \\ net6 . 0 \\ loradeviceprovisioning . dll -- ( add verbs and parameters here )","title":"Running"},{"location":"tools/device-provisioning/#setting-up","text":"The tool can be configured through command line arguments and an appsettings.json file. Required command line arguments are specific to the command the user wants to run and are described later in this document. iothub-connection-string argument is required for all commands and needs to contain a connection string for the Azure IoT Hub you want to work with. The connection string needs to belong to a shared access policy with registry read , registry write and service connect permissions enabled. You can use the default policy named iothubowner . appsettings.json file only contains the Network Id ( NetId ) value which can be optionally overridden, in case your solution does not use the default Network Id 000001. To set your custom Network Id, create a local appsettings.local.json file with your own NetId value. Since just the last byte from this 3 hex string byte array (6 characters) are used to create a valid DevAddr for ABP LoRa devices, the setting can be either the full 3 bytes (000000 to FFFFFF) or just the shortened, last byte (0 to FF). Both appsettings files need to be in the same directory as the cli-lora-device-provisioning binary ( loradeviceprovisioning.dll or loradeviceprovisioning.exe ). { \"NetId\" : \"000001\" } The NetId value can also be overridden with a command line argument (using --netid option). To learn more about what each of the settings in the LoRa device twin does, refer to the Quick Start Guide .","title":"Setting up"},{"location":"tools/device-provisioning/#supported-commands","text":"The following verbs/commands are supported: verb description list List devices in IoT Hub. query Query a device twin. verify Verify a single device in IoT Hub. bulkverify Bulk verify all devices in IoT Hub. add Add a new device to IoT Hub. update Update an existing device in IoT Hub. remove Remove an existing device from IoT Hub. rotate-certificate Update a client certificate for a Basics Station. revoke Revoke a client certificate installed on a Basics Station. upgrade-firmware Trigger a firmware upgrade of a Basics Station. help Display more information on a specific command. version Display version information.","title":"Supported commands"},{"location":"tools/device-provisioning/#list","text":"List the devices in IoT Hub and show their device twin. Example: dotnet run -- list - -iothub-connection-string < connection_string > The list verb supports the following parameters: parameter required description --iothub-connection-string yes Connection string of the IoT Hub. --page no Devices per page. Default is 10. --total no Maximum number of devices to list. Default is all. --help no Display this help screen. --version no Display version information.","title":"list"},{"location":"tools/device-provisioning/#query","text":"Show the device twin for an existing device in IoT Hub by it's DevEUI / Device Id. Example: dotnet run -- query - -deveui 33CCC86800430010 - -iothub-connection-string < connection_string > The query verb supports the following parameters: parameter required description --deveui yes DevEUI / Device Id. --iothub-connection-string yes Connection string of the IoT Hub. --help no Display this help screen. --version no Display version information.","title":"query"},{"location":"tools/device-provisioning/#verify","text":"Verify an existing device in IoT Hub by it's DevEUI / Device Id. Example: dotnet run -- verify - -deveui 33CCC86800430010 - -iothub-connection-string < connection_string > The verify verb supports the following parameters: parameter required description --deveui yes DevEUI / Device Id. --iothub-connection-string yes Connection string of the IoT Hub. --netid no Network ID (Only for ABP devices): A 3 bit hex string. Will default to 000001 or NetId set in settings file if left blank. --help no Display this help screen. --version no Display version information.","title":"verify"},{"location":"tools/device-provisioning/#bulkverify","text":"Bulk verify all devices in IoT Hub. Only shows the devices that have configuration errors and displays a summary in the end how many devcies are properly configured and how many contain errors. Example: dotnet run -- bulkverify - -page 10 - -iothub-connection-string < connection_string > The bulkverify verb supports the following parameters: parameter required description --iothub-connection-string yes Connection string of the IoT Hub. --page no Errors per page. Default is all. --help no Display this help screen. --version no Display version information.","title":"bulkverify"},{"location":"tools/device-provisioning/#add","text":"Add a new device to IoT Hub. The data entered will be verified and only created in IoT Hub if it's valid. All required fields that are not provided will be automatically populated with valid, randomly generated by the tool. The only mandatory field is type which has to be set to either ABP or OTAA or concentrator . To learn more about what each of the settings in the LoRa device twin does, refer to the Quick Start Guide . Example: dotnet run -- add - -type abp - -deveui 33CCC86800430010 - -decoder http :// decodermodule / api / customdecoder - -iothub-connection-string < connection_string > The add verb supports the following parameters: parameter required description --type yes Device type: Must be ABP, OTAA or Concentrator. --region yes for 'Concentrator' type devices Must be the name of one of the regions in the DefaultRouterConfig folder. --stationeui yes for 'Concentrator' type devices A 16 bit hex string ('AABBCCDDEEFFGGHH'). --iothub-connection-string yes Connection string of the IoT Hub. --no-cups no No CUPS: Only applicable to 'Concentrator' type devices. If set to true indicates that the concentrator does not use CUPS. --certificate-bundle-location no Certificate bundle location: Required if --no-cups set to false. Points to the location of the (UTF-8-encoded) certificate bundle file. --client-certificate-thumbprint no Client certificate thumbprint: Required if --no-cups set to false. A list of client certificate thumbprints (separated by a space) that should be accepted by the CUPS/LNS endpoints. --tc-uri no LoRaWAN Network Server URI: Required if --no-cups set to false. The URI of the LNS endpoint. Protocol must be set to wss:// --cups-uri no LoRaWAN Network Server URI: Required if --no-cups set to false. The URI of the CUPS endpoint. Protocol must be set to https:// --deveui no DevEUI / Device Id: A 16 bit hex string. Will be randomly generated if left blank. --appskey no AppSKey (Only for ABP devices): A 16 bit hex string. Will be randomly generated if left blank. --nwkskey no NwkSKey (Only for ABP devices): A 16 bit hex string. Will be randomly generated if left blank. --devaddr no DevAddr (Only for ABP devices): A 4 bit hex string. Will be randomly generated if left blank. --netid no Network ID (Only for ABP devices): A 3 bit hex string. Will default to 000001 or NetId set in settings file if left blank. --abprelaxmode no ABPRelaxMode (ABP relaxed framecounter, only for ABP devices): True or false. --appeui no AppEUI (only for OTAA devices): A 16 bit hex string. Will be randomly generated if left blank. --appkey no AppKey (only for OTAA devices): A 16 bit hex string. Will be randomly generated if left blank. --gatewayid no GatewayID: A hostname. --decoder no SensorDecoder: The name of an integrated decoder function or the URI to a decoder in a custom decoder module in the format: http://modulename/api/decodername. --classtype no ClassType: \"A\" (default) or \"C\". --downlinkenabled no DownlinkEnabled: True or false. --preferredwindow no PreferredWindow (Preferred receive window): 1 or 2. --deduplication no Deduplication: None (default), Drop or Mark. --rx2datarate no Rx2DataRate (Receive window 2 data rate, currently only supported for OTAA devices): Any of the allowed data rates. EU: SF12BW125, SF11BW125, SF10BW125, SF8BW125, SF7BW125, SF7BW250 or 50. US: SF10BW125, SF9BW125, SF8BW125, SF7BW125, SF8BW500, SF12BW500, SF11BW500, SF10BW500, SF9BW500, SF8BW500, SF8BW500. --rx1droffset no Rx1DrOffset (Receive window 1 data rate offset, currently only supported for OTAA devices): 0 through 15. --rxdelay no RxDelay (Delay in seconds for sending downstream messages, currently only supported for OTAA devices): 0 through 15. --keepalivetimeout no KeepAliveTimeout (KeepAliveTimeout (Timeout in seconds before device client connection is closed): 0 or 60 and above. --supports32bitfcnt no Supports32BitFCnt (Support for 32bit frame counter): True or false. --fcntupstart no FCntUpStart (Frame counter up start value): 0 through 4294967295. --fcntdownstart no FCntDownStart (Frame counter down start value): 0 through 4294967295. --fcntresetcounter no FCntResetCounter (Frame counter reset counter value): 0 through 4294967295. --help no Display this help screen. --version no Display version information.","title":"add"},{"location":"tools/device-provisioning/#update","text":"Update the twin information for an existing device. To remove an existing value that is currently set on the twin, pass it the value null . To learn more about what each of the settings in the LoRa device twin does, refer to the Quick Start Guide . Example: dotnet run -- update - -deveui 33CCC86800430010 - -decoder null - -iothub-connection-string < connection_string > The update verb supports the following parameters: parameter required description --deveui yes DevEUI / Device Id: A 16 bit hex string. --iothub-connection-string yes Connection string of the IoT Hub. --appskey no AppSKey (Only for ABP devices): A 16 bit hex string. --nwkskey no NwkSKey (Only for ABP devices): A 16 bit hex string. --devaddr no DevAddr (Only for ABP devices): A 4 bit hex string. --netid no Network ID (Only for ABP devices): A 3 bit hex string. Will default to 000001 or NetId set in settings file if left blank. --abprelaxmode no ABPRelaxMode (ABP relaxed framecounter, only for ABP devices): True or false. --appeui no AppEUI (only for OTAA devices): A 16 bit hex string. --appkey no AppKey (only for OTAA devices): A 16 bit hex string. --gatewayid no GatewayID: A hostname. --decoder no SensorDecoder: The name of an integrated decoder function or the URI to a decoder in a custom decoder module in the format: http://modulename/api/decodername . --classtype no ClassType: \"A\" (default) or \"C\". --downlinkenabled no DownlinkEnabled: True or false. --preferredwindow no PreferredWindow (Preferred receive window): 1 or 2. --deduplication no Deduplication: None (default), Drop or Mark. --rx2datarate no Rx2DataRate (Receive window 2 data rate, currently only supported for OTAA devices): Any of the allowed data rates. EU: SF12BW125, SF11BW125, SF10BW125, SF8BW125, SF7BW125, SF7BW250 or 50. US: SF10BW125, SF9BW125, SF8BW125, SF7BW125, SF8BW500, SF12BW500, SF11BW500, SF10BW500, SF9BW500, SF8BW500, SF8BW500. --rx1droffset no Rx1DrOffset (Receive window 1 data rate offset, currently only supported for OTAA devices): 0 through 15. --rxdelay no RxDelay (Delay in seconds for sending downstream messages, currently only supported for OTAA devices): 0 through 15. --keepalivetimeout no KeepAliveTimeout (KeepAliveTimeout (Timeout in seconds before device client connection is closed): 0 or 60 and above. --supports32bitfcnt no Supports32BitFCnt (Support for 32bit frame counter): True or false. --fcntupstart no FCntUpStart (Frame counter up start value): 0 through 4294967295. --fcntdownstart no FCntDownStart (Frame counter down start value): 0 through 4294967295. --fcntresetcounter no FCntResetCounter (Frame counter reset counter value): 0 through 4294967295. --help no Display this help screen. --version no Display version information.","title":"update"},{"location":"tools/device-provisioning/#remove","text":"Remove an existing device from IoT Hub by it's DevEUI / Device Id. Example: dotnet run -- remove - -deveui 33CCC86800430010 - -iothub-connection-string < connection_string > The query verb supports the following parameters: parameter required description --deveui yes DevEUI / Device Id. --iothub-connection-string yes Connection string of the IoT Hub. --help no Display this help screen. --version no Display version information.","title":"remove"},{"location":"tools/device-provisioning/#rotate-certificate","text":"Triggers an update of a client certificate installed on the Basics Station. Example: dotnet run -- rotate-certificate - -stationeui 33CCC86800430010 - -certificate-bundle-location < bundle_location > - -client-certificate-thumbprint < thumbprint > - -iothub-connection-string < iothub_connection_string > - -storage-connection-string < storage_connection_string > parameter required description --stationeui yes Station EUI --certificate-bundle-location yes Location of the (UTF-8-encoded) certificate bundle file --client-certificate-thumbprint yes Client certificate thumbprint that should be accepted by the CUPS/LNS endpoints --iothub-connection-string yes Connection string of the IoT Hub --storage-connection-string yes Connection string of the Storage account","title":"rotate-certificate"},{"location":"tools/device-provisioning/#revoke","text":"Revokes a client certificate installed on the Basics Station. Example: dotnet run -- revoke --stationeui 33CCC86800430010 --client-certificate-thumbprint <thumbprint> --iothub-connection-string <iothub_connection_string> parameter required description --stationeui yes Station EUI --client-certificate-thumbprint yes Client certificate thumbprint that should be revoked --iothub-connection-string yes Connection string of the IoT Hub","title":"revoke"},{"location":"tools/device-provisioning/#upgrade-firmware","text":"Triggers a firmware upgrade of a Basics Station. To learn more about executing firmware upgrades, please refer to the Firmware upgrade user guide. Example: powershell dotnet run -- upgrade-firmware --stationeui <station_eui> --package <package_version> --firmware-location <firmware_file_path> --digest-location <digest_file_path> --checksum-location <checksum_file_path> --iothub-connection-string <iothub_connection_string> --storage-connection-string <storage_connection_string> The upgrade-firmware verb accepts the following parameters: parameter required description --stationeui yes Station EUI --package yes New package version (e.g. 1.0.1 ) --firmware-location yes Local file path of the firmware upgrade executable --digest-location yes Local file path of the file containing a digest of the firmware upgrade --checksum-location yes Local file path of the file containing a CRC32 checksum of the key used to generate the digest --iothub-connection-string yes Connection string of the IoT Hub. --storage-connection-string yes Connection string of the Storage account. --help no Display this help screen --version no Display version information","title":"upgrade-firmware"},{"location":"user-guide/adaptive-data-rate/","text":"Adaptive Data Rate The solution supports Adaptive Data Rate (ADR) device management as specified in LoRa spec v1.1 . The main goal of the ADR is to optimize the network for maximum capacity ensuring devices always transmit with their best settings possible (highest data rate, lowest power), you can find more ADR information on this page . Adaptive Data rate is always initiated and set on the device side. ADR should never be used with moving devices. Our solution currently implements the Semtech proposed Algorithm for ADR and has been tested against EU868 region plan. In this algorithm the data rate and transmission power calculation is done as follows: Signal-to-noise ratio (SNR) is calculated based on the maximum SNR detected over the recent transmissions, the required SNR for the given region (which depends on the spreading factor of the current data rate) and SNR margin (always equal to 5dB). The calculated SNR determines the number of steps that will be executed for the calculation of new data rate and transmission power. In each step we try to increment the data rate, as long as it's lower than the maximum data rate supported for the region (DR5 in case of EU868). We then increment the TX power index as long as it's lower than the highest TX power index for the region. To determine the maximum TX power index we use the TX power table which is documented in LoRaWAN Regional Parameters specification . The table defines the mapping of TX power indices (0 - 7 in case of EU868) to EIRP (Equivalent Isotropically Radiated Power) in dB. The highest EIRP is mapped to the lowest TX power index, hence in order to achieve a lower transmission power we increment the TX power index in each step of the algorithm. Once the remaining steps are equal to 0, the new data rate and TX power index calculated this way are returned. In the case where the number of steps calculated in the beginning is negative the algorithm decrements the TX power index (as long as it's greater than 0) but it does not try to lower the data rate, because the end-devices implement automatic data rate decay. The algorithm can only actively increase the data rate.","title":"Adaptive Data Rate"},{"location":"user-guide/adaptive-data-rate/#adaptive-data-rate","text":"The solution supports Adaptive Data Rate (ADR) device management as specified in LoRa spec v1.1 . The main goal of the ADR is to optimize the network for maximum capacity ensuring devices always transmit with their best settings possible (highest data rate, lowest power), you can find more ADR information on this page . Adaptive Data rate is always initiated and set on the device side. ADR should never be used with moving devices. Our solution currently implements the Semtech proposed Algorithm for ADR and has been tested against EU868 region plan. In this algorithm the data rate and transmission power calculation is done as follows: Signal-to-noise ratio (SNR) is calculated based on the maximum SNR detected over the recent transmissions, the required SNR for the given region (which depends on the spreading factor of the current data rate) and SNR margin (always equal to 5dB). The calculated SNR determines the number of steps that will be executed for the calculation of new data rate and transmission power. In each step we try to increment the data rate, as long as it's lower than the maximum data rate supported for the region (DR5 in case of EU868). We then increment the TX power index as long as it's lower than the highest TX power index for the region. To determine the maximum TX power index we use the TX power table which is documented in LoRaWAN Regional Parameters specification . The table defines the mapping of TX power indices (0 - 7 in case of EU868) to EIRP (Equivalent Isotropically Radiated Power) in dB. The highest EIRP is mapped to the lowest TX power index, hence in order to achieve a lower transmission power we increment the TX power index in each step of the algorithm. Once the remaining steps are equal to 0, the new data rate and TX power index calculated this way are returned. In the case where the number of steps calculated in the beginning is negative the algorithm decrements the TX power index (as long as it's greater than 0) but it does not try to lower the data rate, because the end-devices implement automatic data rate decay. The algorithm can only actively increase the data rate.","title":"Adaptive Data Rate"},{"location":"user-guide/architecture/","text":"Architecture and Concepts Background LoRaWAN is a type of wireless wide-area networking that is designed to allow long-range communication at a low bit rate among low-power connected objects, such as sensors operated on a battery. Network topology is of star-of-stars type, with the leaf sensors sending data to gateways for forwarding telemetry to and receiving commands from backing Internet services. Nowadays, even for simple scenarios like having 10 devices connected to a single LoRaWan gateway (hardware with antenna), you need to connect your gateway to a Network Server and then work through connectors provided by the server vendor to integrate your LoRa gateways and devices with the back end. These setups can be connected to Azure IoT Hub quite easily. As a matter of fact such scenarios exist . Customers looking for an operated network with national or international reach (e.g. fleet operators, logistics) will tend to choose this setup accepting the potentially higher complexity and dependency on the network operator. However, customers looking for any of the following are expected to prefer a setup where the LoRaWAN network servers runs directly on the gateway/Azure IoT Edge: Primarily coverage on their own ground (e.g. manufacturing plants, smart buildings, facilities, ports). Capabilities that Azure IoT edge brings to the table: Local processing on the gateway. Offline capabilities of the gateway. Gateway management. Homogenous management of devices and gateways independent of connectivity technology. High Level Architecture Below is a high level diagram of how the framework works, for more details refer to the dev guide .","title":"Architecture and Concepts"},{"location":"user-guide/architecture/#architecture-and-concepts","text":"","title":"Architecture and Concepts"},{"location":"user-guide/architecture/#background","text":"LoRaWAN is a type of wireless wide-area networking that is designed to allow long-range communication at a low bit rate among low-power connected objects, such as sensors operated on a battery. Network topology is of star-of-stars type, with the leaf sensors sending data to gateways for forwarding telemetry to and receiving commands from backing Internet services. Nowadays, even for simple scenarios like having 10 devices connected to a single LoRaWan gateway (hardware with antenna), you need to connect your gateway to a Network Server and then work through connectors provided by the server vendor to integrate your LoRa gateways and devices with the back end. These setups can be connected to Azure IoT Hub quite easily. As a matter of fact such scenarios exist . Customers looking for an operated network with national or international reach (e.g. fleet operators, logistics) will tend to choose this setup accepting the potentially higher complexity and dependency on the network operator. However, customers looking for any of the following are expected to prefer a setup where the LoRaWAN network servers runs directly on the gateway/Azure IoT Edge: Primarily coverage on their own ground (e.g. manufacturing plants, smart buildings, facilities, ports). Capabilities that Azure IoT edge brings to the table: Local processing on the gateway. Offline capabilities of the gateway. Gateway management. Homogenous management of devices and gateways independent of connectivity technology.","title":"Background"},{"location":"user-guide/architecture/#high-level-architecture","text":"Below is a high level diagram of how the framework works, for more details refer to the dev guide .","title":"High Level Architecture"},{"location":"user-guide/as923/","text":"Region AS923 If you configure a concentrator with an AS923 (sub-)region, you need to follow these steps in addition to how you would typically configure a concentrator for such a region. Since in AS923, dwell time limitations may apply, you need to be aware what the local regulations are with respect to dwell time limitations. Per default, the Network Server will assume that dwell time restrictions apply. For every concentrator in that region, you must configure the device twin to include the actual dwell time limitations that apply in the location of the concentrator. You can do this by adding the following block to the desired properties of the concentrator twin: { ... , \"properties\" : { \"desired\" : { \"routerConfig\" : { ... }, \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } } } } The configuration values will be translated into a TxParamSetupReq MAC command (for an explanation refer to the LoRa specification) and as such be communicated automatically to every device that connects to the concentrator, based on whether that device already responded to the TxParamSetupReq MAC command with a TxParamSetupAns . In case a device did not acknowledge such a MAC command, or if the last acknowledged TxParamSetupReq does not match the desired TX params, it will automatically send downlink MAC commands to the device until it receives a TxParamSetupAns . Warning If a device is associated with multiple concentrators, it's important that all of these concentrators have the same desiredTxParams properties. If they do not have the same desiredTxParams this will lead to unpredictable and unexpected behavior. Consider using Automatic IoT device and module management to manage consistent configuration between multiple concentrators. The Network Server will apply the following effective dwell time settings in this order: If a device acknowledged a TxParamSetupReq , the Network Server will always apply dwell time settings based on the last reported properties of the device. If the last acknowledged dwell time settings (reported properties) do not match what is configured on the LoRa device, make sure to update the reported properties of the device to match the actual TX params. If a device has not yet acknowledged (or received) a TxParamSetupReq , the Network Server will apply the regional dwell time defaults (dwell time limits are on, as specified in LoRaWAN regional parameter specification) for downlink transmissions until the device acknowledges a received TxParamSetupReq MAC command. Warning If you associate a device with multiple Network Servers, make sure to refresh the caches (refer to the Quickstart for an explanation on how to refresh caches) of these Network Servers after the device acknowledged the updated dwell time settings.","title":"Region AS923"},{"location":"user-guide/as923/#region-as923","text":"If you configure a concentrator with an AS923 (sub-)region, you need to follow these steps in addition to how you would typically configure a concentrator for such a region. Since in AS923, dwell time limitations may apply, you need to be aware what the local regulations are with respect to dwell time limitations. Per default, the Network Server will assume that dwell time restrictions apply. For every concentrator in that region, you must configure the device twin to include the actual dwell time limitations that apply in the location of the concentrator. You can do this by adding the following block to the desired properties of the concentrator twin: { ... , \"properties\" : { \"desired\" : { \"routerConfig\" : { ... }, \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } } } } The configuration values will be translated into a TxParamSetupReq MAC command (for an explanation refer to the LoRa specification) and as such be communicated automatically to every device that connects to the concentrator, based on whether that device already responded to the TxParamSetupReq MAC command with a TxParamSetupAns . In case a device did not acknowledge such a MAC command, or if the last acknowledged TxParamSetupReq does not match the desired TX params, it will automatically send downlink MAC commands to the device until it receives a TxParamSetupAns . Warning If a device is associated with multiple concentrators, it's important that all of these concentrators have the same desiredTxParams properties. If they do not have the same desiredTxParams this will lead to unpredictable and unexpected behavior. Consider using Automatic IoT device and module management to manage consistent configuration between multiple concentrators. The Network Server will apply the following effective dwell time settings in this order: If a device acknowledged a TxParamSetupReq , the Network Server will always apply dwell time settings based on the last reported properties of the device. If the last acknowledged dwell time settings (reported properties) do not match what is configured on the LoRa device, make sure to update the reported properties of the device to match the actual TX params. If a device has not yet acknowledged (or received) a TxParamSetupReq , the Network Server will apply the regional dwell time defaults (dwell time limits are on, as specified in LoRaWAN regional parameter specification) for downlink transmissions until the device acknowledges a received TxParamSetupReq MAC command. Warning If you associate a device with multiple Network Servers, make sure to refresh the caches (refer to the Quickstart for an explanation on how to refresh caches) of these Network Servers after the device acknowledged the updated dwell time settings.","title":"Region AS923"},{"location":"user-guide/caching/","text":"Caching Function The function is utilizing a Redis cache to store device related information. It is composed of multiple cache entries: LoRaDeviceCache Stores an instance of type DeviceCacheInfo by DevEUI to keep track of FCntUp, FCntDown, GatewayId per LoRaWAN Network Server (LNS). The cache is used to have a distributed lock in a multi gateway scenario. The info per gateway is stored using the DevEUI to determine what GW is allowed to process a particular message and respond to the sending device. All the values in this cache are LoRaWAN related and don't require any other information than what we get from the device and the gateway handling a particular message. This cache needs to be reset, when a device re-joins. public class DeviceCacheInfo { public uint FCntUp { get ; set ; } public uint FCntDown { get ; set ; } public string GatewayId { get ; set ; } } iotedge-lorawan-starterkit/DeviceCacheInfo.cs at dev \u00b7 Azure/iotedge-lorawan-starterkit (github.com) LoRaDevAddrCache The LoRaDevAddrCache contains important information from the IoT Hub we require for different scenarios. Most of the information is stored in device twins that are loaded and synchronized on a predefined schedule. Twins queries have strict limits in terms of reads/device and module Understand Azure IoT Hub quotas and throttling | Microsoft Docs . Therefore this cache was put in the middle to handle the higher load we would generate to read out the information stored in IoT Hub. The cache is organized as a HSET - HSET \u2013 Redis - The key being the DevAddr and individual DevEUI as the field as multiple devices can have the same DevAddr. The values are DevAddrCacheInfo . public class DevAddrCacheInfo : IoTHubDeviceInfo { public string GatewayId { get ; set ; } public DateTime LastUpdatedTwins { get ; set ; } public string NwkSKey { get ; set ; } } public class IoTHubDeviceInfo { public string DevAddr { get ; set ; } public string DevEUI { get ; set ; } public string PrimaryKey { get ; set ; } } iotedge-lorawan-starterkit/DevAddrCacheInfo.cs at dev \u00b7 Azure/iotedge-lorawan-starterkit (github.com) This cache is automatically being populated on a schedule. We have a function trigger SyncDevAddrCache that is triggered on a regular basis (currently every 5min) to validate what synchronization is required. If the system does warm up, it will trigger a full reload. The full reload fetches all devices from the registry and synchronizes the relevant values from the twins. The sync process, does not synchronize the private key of the device from IoT hub (they will be loaded on request). The full reload will be performed at most once every 24h (unless the redis cache is completely cleared). The incremental updates do make sure we only load the delta using the timestamps on the desired and reported property: var query = $\"SELECT * FROM devices where properties.desired.$metadata.$lastUpdated >= '{lastUpdate}' OR properties.reported.$metadata.DevAddr.$lastUpdated >= '{lastUpdate}'\" ; Join related caching When we receive OTAA requests, we manage the potential of conflicting with multiple gateways as well with the redis cache. We maintain 2 caches: devnonce The devnonce keeps track of nonce values sent by the device for a join request. It makes sure the same join request is only handled once by one Gateway. The key is composed of the [DevEUI]:[DevNonce] values. It's evicted after 5min it was added to the cache. Join-info The Join-info cache contains information required when a new device joins the network. The cache is keyed by [DevEUI]:joininfo and is valid for 60min after initial creation. public class JoinInfo { public string PrimaryKey { get ; set ; } public string DesiredGateway { get ; set ; } } iotedge-lorawan-starterkit/JoinInfo.cs at dev \u00b7 Azure/iotedge-lorawan-starterkit (github.com) The DesiredGateway is used to set if a specific gateway needs to process requests coming from a device. If the value is not set, the first one to win the race, will handle the join. The PrimaryKey is used to create the device connection from the edge gateway to IoT Hub. Edge Gateway Device Cache Every device sending messages to the edge, is validated if it belongs to our network and our gateway. If it is our gateway, we build up a local representation of the device in memory including a connection to IoT Hub. The devices are cached for a specific amount of time in the LoRaDeviceRegistry . The LoRaDeviceRegistry stores the LoRaDevice with 3 entries: We maintain a dictionary by DevAddr that contains an entry per DevEUI for a particular device - valid for 2 days The device is stored directly using the DevEUI for fast lookup using deveui:[DevEUI] - no expiration When a DevAddr entry (1) is not ready, we initialize a DeviceLoaderSynchronizer to fetch matching devices from the function API. The loader itself is put in cache, to be able to handle requests, while we are in the process of loading them. - valid for 30s. Class C device cases use the DevEUI directly for downstream message sending (2). All other cases make use of the first cache by DevAddr. The Device Cache can be forcefully invalidated - Quickstart - Cache Clearing . Connections We maintain connections to the IoT hub for all devices that belong to us for which we received messages. The connection is cached per device in the LoRaDeviceClientConnectionManager . We do establish the connection to IoT hub with the PrimaryKey of the device using the standard DeviceClient Class (Microsoft.Azure.Devices.Client) - Azure for .NET Developers | Microsoft Docs . Connections are closed when the LoRaDevice is disposed.","title":"Caching"},{"location":"user-guide/caching/#caching","text":"","title":"Caching"},{"location":"user-guide/caching/#function","text":"The function is utilizing a Redis cache to store device related information. It is composed of multiple cache entries:","title":"Function"},{"location":"user-guide/caching/#loradevicecache","text":"Stores an instance of type DeviceCacheInfo by DevEUI to keep track of FCntUp, FCntDown, GatewayId per LoRaWAN Network Server (LNS). The cache is used to have a distributed lock in a multi gateway scenario. The info per gateway is stored using the DevEUI to determine what GW is allowed to process a particular message and respond to the sending device. All the values in this cache are LoRaWAN related and don't require any other information than what we get from the device and the gateway handling a particular message. This cache needs to be reset, when a device re-joins. public class DeviceCacheInfo { public uint FCntUp { get ; set ; } public uint FCntDown { get ; set ; } public string GatewayId { get ; set ; } } iotedge-lorawan-starterkit/DeviceCacheInfo.cs at dev \u00b7 Azure/iotedge-lorawan-starterkit (github.com)","title":"LoRaDeviceCache"},{"location":"user-guide/caching/#loradevaddrcache","text":"The LoRaDevAddrCache contains important information from the IoT Hub we require for different scenarios. Most of the information is stored in device twins that are loaded and synchronized on a predefined schedule. Twins queries have strict limits in terms of reads/device and module Understand Azure IoT Hub quotas and throttling | Microsoft Docs . Therefore this cache was put in the middle to handle the higher load we would generate to read out the information stored in IoT Hub. The cache is organized as a HSET - HSET \u2013 Redis - The key being the DevAddr and individual DevEUI as the field as multiple devices can have the same DevAddr. The values are DevAddrCacheInfo . public class DevAddrCacheInfo : IoTHubDeviceInfo { public string GatewayId { get ; set ; } public DateTime LastUpdatedTwins { get ; set ; } public string NwkSKey { get ; set ; } } public class IoTHubDeviceInfo { public string DevAddr { get ; set ; } public string DevEUI { get ; set ; } public string PrimaryKey { get ; set ; } } iotedge-lorawan-starterkit/DevAddrCacheInfo.cs at dev \u00b7 Azure/iotedge-lorawan-starterkit (github.com) This cache is automatically being populated on a schedule. We have a function trigger SyncDevAddrCache that is triggered on a regular basis (currently every 5min) to validate what synchronization is required. If the system does warm up, it will trigger a full reload. The full reload fetches all devices from the registry and synchronizes the relevant values from the twins. The sync process, does not synchronize the private key of the device from IoT hub (they will be loaded on request). The full reload will be performed at most once every 24h (unless the redis cache is completely cleared). The incremental updates do make sure we only load the delta using the timestamps on the desired and reported property: var query = $\"SELECT * FROM devices where properties.desired.$metadata.$lastUpdated >= '{lastUpdate}' OR properties.reported.$metadata.DevAddr.$lastUpdated >= '{lastUpdate}'\" ;","title":"LoRaDevAddrCache"},{"location":"user-guide/caching/#join-related-caching","text":"When we receive OTAA requests, we manage the potential of conflicting with multiple gateways as well with the redis cache. We maintain 2 caches:","title":"Join related caching"},{"location":"user-guide/caching/#devnonce","text":"The devnonce keeps track of nonce values sent by the device for a join request. It makes sure the same join request is only handled once by one Gateway. The key is composed of the [DevEUI]:[DevNonce] values. It's evicted after 5min it was added to the cache.","title":"devnonce"},{"location":"user-guide/caching/#join-info","text":"The Join-info cache contains information required when a new device joins the network. The cache is keyed by [DevEUI]:joininfo and is valid for 60min after initial creation. public class JoinInfo { public string PrimaryKey { get ; set ; } public string DesiredGateway { get ; set ; } } iotedge-lorawan-starterkit/JoinInfo.cs at dev \u00b7 Azure/iotedge-lorawan-starterkit (github.com) The DesiredGateway is used to set if a specific gateway needs to process requests coming from a device. If the value is not set, the first one to win the race, will handle the join. The PrimaryKey is used to create the device connection from the edge gateway to IoT Hub.","title":"Join-info"},{"location":"user-guide/caching/#edge-gateway","text":"","title":"Edge Gateway"},{"location":"user-guide/caching/#device-cache","text":"Every device sending messages to the edge, is validated if it belongs to our network and our gateway. If it is our gateway, we build up a local representation of the device in memory including a connection to IoT Hub. The devices are cached for a specific amount of time in the LoRaDeviceRegistry . The LoRaDeviceRegistry stores the LoRaDevice with 3 entries: We maintain a dictionary by DevAddr that contains an entry per DevEUI for a particular device - valid for 2 days The device is stored directly using the DevEUI for fast lookup using deveui:[DevEUI] - no expiration When a DevAddr entry (1) is not ready, we initialize a DeviceLoaderSynchronizer to fetch matching devices from the function API. The loader itself is put in cache, to be able to handle requests, while we are in the process of loading them. - valid for 30s. Class C device cases use the DevEUI directly for downstream message sending (2). All other cases make use of the first cache by DevAddr. The Device Cache can be forcefully invalidated - Quickstart - Cache Clearing .","title":"Device Cache"},{"location":"user-guide/caching/#connections","text":"We maintain connections to the IoT hub for all devices that belong to us for which we received messages. The connection is cached per device in the LoRaDeviceClientConnectionManager . We do establish the connection to IoT hub with the PrimaryKey of the device using the standard DeviceClient Class (Microsoft.Azure.Devices.Client) - Azure for .NET Developers | Microsoft Docs . Connections are closed when the LoRaDevice is disposed.","title":"Connections"},{"location":"user-guide/ci-setup/","text":"LoRaWAN Starter Kit uses GitHub Actions for executing CI workflows. This page describes the CI workflows which are currently used in the project. LoRa Build & Test CI The Build & Test CI pipeline runs the following tasks: Builds the LoRaEngine and DecoderSample Runs unit tests Runs integration tests Publishes test results Builds a docker image of the LoRaEngine LoRa E2E CI The E2E CI pipeline is used to run end-to-end tests (implemented in the LoRaWan.Tests.E2E project). The pipeline runs tests using real LoRaWan hardware, it therefore requires a VPN tunnel between the local hardware deployment and Azure. you can find more information on this blog post . The pipeline runs the following tasks: Prepares the required environment variables Builds and deploys Facade Azure Function Builds and pushes docker images for LoRaWanNetworkServer and LoRaWanBasicsStation modules Generates required server and client certificates using scripts located in Tools/BasicStation-Certificates-Generation/ ; the trust certificates are then copied to a pre-created $CERT_REMOTE_PATH location in the local CI and to a remote device Deploys IoT Edge solution to ARM gateway Deploys IoT Edge solution to EFLOW gateway Deploys IoT Edge solution to a standalone concentrator Runs E2E tests on a dedicated agent Pipeline authentication setup The pipeline uses the Github environment named CI and OIDC tokens to authenticate to Azure. OIDC auth is enabled ONLY for this environement. All pipeline secrets are taken from a Keyvault. The only environment secrets needed at the time of writing are : AZURE_CLIENT_ID : Required to set up the OIDC connection AZURE_TENANT_ID : Required to set up the OIDC connection AZURE_SUBSCRIPTION_ID : Required to set up the OIDC connection AZURE_FUNCTIONAPP_PUBLISH_PROFILE : Required as the Azure Function step doesn't support OIDC auth KEYVAULT_NAME : Required to indicate which keyvault the pipeline should point to The OIDC connection is made using a service principal which has the following permissions: Desktop Virtualization Power On Off Contributor on the Eflow vm Contributor on the subscription Key Vault Secrets User on the Keyvault Pipeline settings The E2E pipeline has a number of settings that can be configured in GitHub Actions: RunE2ETestsOnly - if set to true only the E2E tests will be run, all other steps of the workflow will be skipped E2ETestsToRun - allows selection of only specific E2E tests to be run using the E2E test class name pattern, e.g. if set to [MultiGatewayTest] only E2E tests implemented in Tests/E2E/MultiGatewayTests.cs will be run. The variable defaults to all E2E tests. TxPower - allows setting a custom transmission power on the leaf devices to be used during the E2E test run (with 14 being the maximum). The default is TX power is 6. Execution The E2E CI can be triggered manually via GitHub Actions and runs automatically on a daily schedule. The pipeline is also set up to run on pull requests under certain conditions. In order for this workflow to be run on an open pull request, the label fullci needs to be added to the PR. Upon successful execution of the tests, additional labels will be added to the PR automatically by GitHub Actions, e.g. if all multi-concentrator E2E tests pass, the MultiConcentrator label will automatically be added to the PR. The workflow will be re-executed on new changes being pushed, as long as the fullci label is present. By default all E2E tests will be run each time (including the ones which previously passed). In order to prevent this and only run previously failing tests, additional label must be added to the PR (e.g. label 1 ). In this case the test labels already added to the PR will prevent those tests from being re-executed. Connecting to the Environment CI operators can use an Azure VPN to connect to the local CI using P2S , certificates and secrets are in the Keyvault Manual steps to recreate the environment In addition to running the Bicep scripts, the following action needs to be manually executed: Create a service principal with permissions as described above Create a new Github Environment (or update the existing one) to reflect the new service principal (AZURE_CLIENT_ID, AZURE_TENANT_ID and AZURE_SUBSCRIPTION_ID) Follow the documentation to create trust between Azure and the Github Environment Create an Azure Keyvault and Migrate the secrets from the previous Keyvault Create an Azure VPN Gateway - Create a certificate chain to authenticate following this doc - Update the local CI Devices with the new certificate - Save the certificates and Key to the new Keyvault Create a Windows Server 2022 VM to Host the Eflow VM - Installation instructions can be found here Create a new Azure Container Registry and import the required docker image (Convenience script below ). Alternatively, rebuild it from the sample folder . Grant permissions to the newly created service principal to the new Azure resources as described previously Docker import convenience script $newRegistry =< your registry > $previousRegistry =< the previous azure registry > $previousRegistryLogin =< previous registry login > $previousRegistryPW =< previous registry password > $debianRelease = bullseye az acr import - -name $newRegistry - -source docker . io / amd64 / debian : $debianRelease - -image amd64 / debian : $debianRelease az acr import - -name $newRegistry - -source docker . io / amd64 / debian : $debianRelease -slim - -image amd64 / debian : $debianRelease -slim az acr import - -name $newRegistry - -source docker . io / arm32v7 / debian : $debianRelease - -image arm32v7 / debian : $debianRelease az acr import - -name $newRegistry - -source docker . io / arm32v7 / debian : $debianRelease -slim - -image arm32v7 / debian : $debianRelease -slim az acr import - -name $newRegistry - -source docker . io / arm64v8 / debian : $debianRelease - -image arm64v8 / debian : $debianRelease az acr import - -name $newRegistry - -source docker . io / arm64v8 / debian : $debianRelease -slim - -image arm64v8 / debian : $debianRelease -slim az acr import - -name $newRegistry - -source docker . io / amd64 / node : $debianRelease - -image amd64 / node : $debianRelease az acr import - -name $newRegistry - -source docker . io / amd64 / node : $debianRelease -slim - -image amd64 / node : $debianRelease -slim az acr import - -name $newRegistry - -source docker . io / arm32v7 / node : $debianRelease - -image arm32v7 / node : $debianRelease az acr import - -name $newRegistry - -source docker . io / arm32v7 / node : $debianRelease -slim - -image arm32v7 / node : $debianRelease -slim az acr import - -name $newRegistry - -source docker . io / arm64v8 / node : $debianRelease - -image arm64v8 / node : $debianRelease az acr import - -name $newRegistry - -source docker . io / arm64v8 / node : $debianRelease -slim - -image arm64v8 / node : $debianRelease -slim az acr import - -name $newRegistry - -source $previousRegistry . azurecr . io / decodersample : 2 . 0-arm32v7 - -image decodersample : 2 . 0-arm32v7 - -username $previousRegistryLogin - -password $previousRegistryPW az acr import - -name $newRegistry - -source $previousRegistry . azurecr . io / decodersample : 2 . 0-amd64 - -image decodersample : 2 . 0-amd64 - -username $previousRegistryLogin - -password $previousRegistryPW az acr import - -name $newRegistry - -source $previousRegistry . azurecr . io / decodersample : 2 . 0 - -image decodersample : 2 . 0 - -username $previousRegistryLogin - -password $previousRegistryPW Universal Decoder CI The Universal decoder CI pipeline runs the following tasks: Builds and tests the Universal Decoder sample project Builds and pushes a docker image for the decoder Other workflows The repository contains other workflows which are run automatically under certain confitions, typically when a pull request is created: CodeQL - runs CodeQL analysis on each PR created against dev branch and after merge Lint and Check Markdown - runs linter and checks links in markdown files; runs on PR created agains docs/main branch and only checks .md (or .markdown ) files Test Report - publishes test results after Build & Test CI or E2E CI have completed Publish docs (new version) - publishes project documentation using MkDocs. The workflow needs to be triggered manually against docs/main branch after documentation has been updated and requires a version to publish as input to run. Publish docs dev - runs on changes to docs/main branch and publishes dev version of the documentation","title":"Continuous Integration Setup"},{"location":"user-guide/ci-setup/#lora-build-test-ci","text":"The Build & Test CI pipeline runs the following tasks: Builds the LoRaEngine and DecoderSample Runs unit tests Runs integration tests Publishes test results Builds a docker image of the LoRaEngine","title":"LoRa Build &amp; Test CI"},{"location":"user-guide/ci-setup/#lora-e2e-ci","text":"The E2E CI pipeline is used to run end-to-end tests (implemented in the LoRaWan.Tests.E2E project). The pipeline runs tests using real LoRaWan hardware, it therefore requires a VPN tunnel between the local hardware deployment and Azure. you can find more information on this blog post . The pipeline runs the following tasks: Prepares the required environment variables Builds and deploys Facade Azure Function Builds and pushes docker images for LoRaWanNetworkServer and LoRaWanBasicsStation modules Generates required server and client certificates using scripts located in Tools/BasicStation-Certificates-Generation/ ; the trust certificates are then copied to a pre-created $CERT_REMOTE_PATH location in the local CI and to a remote device Deploys IoT Edge solution to ARM gateway Deploys IoT Edge solution to EFLOW gateway Deploys IoT Edge solution to a standalone concentrator Runs E2E tests on a dedicated agent","title":"LoRa E2E CI"},{"location":"user-guide/ci-setup/#pipeline-authentication-setup","text":"The pipeline uses the Github environment named CI and OIDC tokens to authenticate to Azure. OIDC auth is enabled ONLY for this environement. All pipeline secrets are taken from a Keyvault. The only environment secrets needed at the time of writing are : AZURE_CLIENT_ID : Required to set up the OIDC connection AZURE_TENANT_ID : Required to set up the OIDC connection AZURE_SUBSCRIPTION_ID : Required to set up the OIDC connection AZURE_FUNCTIONAPP_PUBLISH_PROFILE : Required as the Azure Function step doesn't support OIDC auth KEYVAULT_NAME : Required to indicate which keyvault the pipeline should point to The OIDC connection is made using a service principal which has the following permissions: Desktop Virtualization Power On Off Contributor on the Eflow vm Contributor on the subscription Key Vault Secrets User on the Keyvault","title":"Pipeline authentication setup"},{"location":"user-guide/ci-setup/#pipeline-settings","text":"The E2E pipeline has a number of settings that can be configured in GitHub Actions: RunE2ETestsOnly - if set to true only the E2E tests will be run, all other steps of the workflow will be skipped E2ETestsToRun - allows selection of only specific E2E tests to be run using the E2E test class name pattern, e.g. if set to [MultiGatewayTest] only E2E tests implemented in Tests/E2E/MultiGatewayTests.cs will be run. The variable defaults to all E2E tests. TxPower - allows setting a custom transmission power on the leaf devices to be used during the E2E test run (with 14 being the maximum). The default is TX power is 6.","title":"Pipeline settings"},{"location":"user-guide/ci-setup/#execution","text":"The E2E CI can be triggered manually via GitHub Actions and runs automatically on a daily schedule. The pipeline is also set up to run on pull requests under certain conditions. In order for this workflow to be run on an open pull request, the label fullci needs to be added to the PR. Upon successful execution of the tests, additional labels will be added to the PR automatically by GitHub Actions, e.g. if all multi-concentrator E2E tests pass, the MultiConcentrator label will automatically be added to the PR. The workflow will be re-executed on new changes being pushed, as long as the fullci label is present. By default all E2E tests will be run each time (including the ones which previously passed). In order to prevent this and only run previously failing tests, additional label must be added to the PR (e.g. label 1 ). In this case the test labels already added to the PR will prevent those tests from being re-executed.","title":"Execution"},{"location":"user-guide/ci-setup/#connecting-to-the-environment","text":"CI operators can use an Azure VPN to connect to the local CI using P2S , certificates and secrets are in the Keyvault","title":"Connecting to the Environment"},{"location":"user-guide/ci-setup/#manual-steps-to-recreate-the-environment","text":"In addition to running the Bicep scripts, the following action needs to be manually executed: Create a service principal with permissions as described above Create a new Github Environment (or update the existing one) to reflect the new service principal (AZURE_CLIENT_ID, AZURE_TENANT_ID and AZURE_SUBSCRIPTION_ID) Follow the documentation to create trust between Azure and the Github Environment Create an Azure Keyvault and Migrate the secrets from the previous Keyvault Create an Azure VPN Gateway - Create a certificate chain to authenticate following this doc - Update the local CI Devices with the new certificate - Save the certificates and Key to the new Keyvault Create a Windows Server 2022 VM to Host the Eflow VM - Installation instructions can be found here Create a new Azure Container Registry and import the required docker image (Convenience script below ). Alternatively, rebuild it from the sample folder . Grant permissions to the newly created service principal to the new Azure resources as described previously","title":"Manual steps to recreate the environment"},{"location":"user-guide/ci-setup/#docker-import-convenience-script","text":"$newRegistry =< your registry > $previousRegistry =< the previous azure registry > $previousRegistryLogin =< previous registry login > $previousRegistryPW =< previous registry password > $debianRelease = bullseye az acr import - -name $newRegistry - -source docker . io / amd64 / debian : $debianRelease - -image amd64 / debian : $debianRelease az acr import - -name $newRegistry - -source docker . io / amd64 / debian : $debianRelease -slim - -image amd64 / debian : $debianRelease -slim az acr import - -name $newRegistry - -source docker . io / arm32v7 / debian : $debianRelease - -image arm32v7 / debian : $debianRelease az acr import - -name $newRegistry - -source docker . io / arm32v7 / debian : $debianRelease -slim - -image arm32v7 / debian : $debianRelease -slim az acr import - -name $newRegistry - -source docker . io / arm64v8 / debian : $debianRelease - -image arm64v8 / debian : $debianRelease az acr import - -name $newRegistry - -source docker . io / arm64v8 / debian : $debianRelease -slim - -image arm64v8 / debian : $debianRelease -slim az acr import - -name $newRegistry - -source docker . io / amd64 / node : $debianRelease - -image amd64 / node : $debianRelease az acr import - -name $newRegistry - -source docker . io / amd64 / node : $debianRelease -slim - -image amd64 / node : $debianRelease -slim az acr import - -name $newRegistry - -source docker . io / arm32v7 / node : $debianRelease - -image arm32v7 / node : $debianRelease az acr import - -name $newRegistry - -source docker . io / arm32v7 / node : $debianRelease -slim - -image arm32v7 / node : $debianRelease -slim az acr import - -name $newRegistry - -source docker . io / arm64v8 / node : $debianRelease - -image arm64v8 / node : $debianRelease az acr import - -name $newRegistry - -source docker . io / arm64v8 / node : $debianRelease -slim - -image arm64v8 / node : $debianRelease -slim az acr import - -name $newRegistry - -source $previousRegistry . azurecr . io / decodersample : 2 . 0-arm32v7 - -image decodersample : 2 . 0-arm32v7 - -username $previousRegistryLogin - -password $previousRegistryPW az acr import - -name $newRegistry - -source $previousRegistry . azurecr . io / decodersample : 2 . 0-amd64 - -image decodersample : 2 . 0-amd64 - -username $previousRegistryLogin - -password $previousRegistryPW az acr import - -name $newRegistry - -source $previousRegistry . azurecr . io / decodersample : 2 . 0 - -image decodersample : 2 . 0 - -username $previousRegistryLogin - -password $previousRegistryPW","title":"Docker import convenience script"},{"location":"user-guide/ci-setup/#universal-decoder-ci","text":"The Universal decoder CI pipeline runs the following tasks: Builds and tests the Universal Decoder sample project Builds and pushes a docker image for the decoder","title":"Universal Decoder CI"},{"location":"user-guide/ci-setup/#other-workflows","text":"The repository contains other workflows which are run automatically under certain confitions, typically when a pull request is created: CodeQL - runs CodeQL analysis on each PR created against dev branch and after merge Lint and Check Markdown - runs linter and checks links in markdown files; runs on PR created agains docs/main branch and only checks .md (or .markdown ) files Test Report - publishes test results after Build & Test CI or E2E CI have completed Publish docs (new version) - publishes project documentation using MkDocs. The workflow needs to be triggered manually against docs/main branch after documentation has been updated and requires a version to publish as input to run. Publish docs dev - runs on changes to docs/main branch and publishes dev version of the documentation","title":"Other workflows"},{"location":"user-guide/class-b-beaconing/","text":"Class-B: Beacon locking This doc describes the process of locking a Class-B arduino device to a beaconing signal issued from the basic station and reading the GPS coordinates transmitted by that beacon. Network Server The LoRaWAN network server ( LoraWanNetworkSrvModule ) doesn't need any special configuration beyond the usual required launch settings. Basic Station / Concentrator For this setup, we use a concentrator with a GPS antenna attached. Note : The GPS data can be faked by the concentrator in the case when no GPS antenna is available. This has not yet been tested . See Class B Beaconing Settings , Creating a FIFO and GPS NMEA data for more information. Modify station.conf (see this GH issue for more context about the following settings): 1. Add \"pps\": true under SX1301_conf . 2. Add \"pps\": \"fuzzy\" under station_conf . 3. [Optional] Set \"log_level\": \"XDEBUG\" for extra detailed logs. When the basic station is run, we expect a few things to happen: Beaconing starts and is immediately suspended awaiting synchronization from the network server. [ S2E:INFO ] Beaconing every 2m8s on 869 .525MHz ( 1 ) @ DR3 ( frame layout 2 /8/17 ) [ S2E:INFO ] Beaconing suspend - missing GPS data: time A timesync message is sent from the basic station to the network server. [ AIO:XDEB ] [ 3 | WS ] > { \"msgtype\" : \"timesync\" , \"txtime\" :1023024197 } A timesync response message is received from the network server. [ AIO:XDEB ] [ 3 | WS ] < { \"txtime\" :1023024197, \"gpstime\" :1350820883268000, \"msgtype\" : \"timesync\" } Beaconing resumes: [ S2E:INFO ] Beaconing resumed - recovered GPS data: time Multiple things may go wrong during this process. Check this page for some common issues and troubleshooting tips. Arduino To test that the beacon can be locked by an arduino device, flash the following code onto your Seeeduino LoRaWAN . void setup () { Serial1 . begin ( 9600 ); SerialUSB . begin ( 115200 ); } void loop () { while ( Serial1 . available ()) { SerialUSB . write ( Serial1 . read ()); } while ( SerialUSB . available ()) { Serial1 . write ( SerialUSB . read ()); } } Open the serial monitor and check the version. AT+VER We recommend upgrading the firmware, some of the following might fail for older versions. Switch to Class mode (See section 4.25.5 here ) AT+CLASS = B Wait until the +BEACON: LOCKED message is receieved. Then retrieve the beacon info: AT+BEACON = INFO Which should return the longitude and latitude in the last 2 parameters +BEACON: INFO, 000000, 000000, 8.469193, 47.39558","title":"Class-B: Beacon locking"},{"location":"user-guide/class-b-beaconing/#class-b-beacon-locking","text":"This doc describes the process of locking a Class-B arduino device to a beaconing signal issued from the basic station and reading the GPS coordinates transmitted by that beacon.","title":"Class-B: Beacon locking"},{"location":"user-guide/class-b-beaconing/#network-server","text":"The LoRaWAN network server ( LoraWanNetworkSrvModule ) doesn't need any special configuration beyond the usual required launch settings.","title":"Network Server"},{"location":"user-guide/class-b-beaconing/#basic-station-concentrator","text":"For this setup, we use a concentrator with a GPS antenna attached. Note : The GPS data can be faked by the concentrator in the case when no GPS antenna is available. This has not yet been tested . See Class B Beaconing Settings , Creating a FIFO and GPS NMEA data for more information. Modify station.conf (see this GH issue for more context about the following settings): 1. Add \"pps\": true under SX1301_conf . 2. Add \"pps\": \"fuzzy\" under station_conf . 3. [Optional] Set \"log_level\": \"XDEBUG\" for extra detailed logs. When the basic station is run, we expect a few things to happen: Beaconing starts and is immediately suspended awaiting synchronization from the network server. [ S2E:INFO ] Beaconing every 2m8s on 869 .525MHz ( 1 ) @ DR3 ( frame layout 2 /8/17 ) [ S2E:INFO ] Beaconing suspend - missing GPS data: time A timesync message is sent from the basic station to the network server. [ AIO:XDEB ] [ 3 | WS ] > { \"msgtype\" : \"timesync\" , \"txtime\" :1023024197 } A timesync response message is received from the network server. [ AIO:XDEB ] [ 3 | WS ] < { \"txtime\" :1023024197, \"gpstime\" :1350820883268000, \"msgtype\" : \"timesync\" } Beaconing resumes: [ S2E:INFO ] Beaconing resumed - recovered GPS data: time Multiple things may go wrong during this process. Check this page for some common issues and troubleshooting tips.","title":"Basic Station / Concentrator"},{"location":"user-guide/class-b-beaconing/#arduino","text":"To test that the beacon can be locked by an arduino device, flash the following code onto your Seeeduino LoRaWAN . void setup () { Serial1 . begin ( 9600 ); SerialUSB . begin ( 115200 ); } void loop () { while ( Serial1 . available ()) { SerialUSB . write ( Serial1 . read ()); } while ( SerialUSB . available ()) { Serial1 . write ( SerialUSB . read ()); } } Open the serial monitor and check the version. AT+VER We recommend upgrading the firmware, some of the following might fail for older versions. Switch to Class mode (See section 4.25.5 here ) AT+CLASS = B Wait until the +BEACON: LOCKED message is receieved. Then retrieve the beacon info: AT+BEACON = INFO Which should return the longitude and latitude in the last 2 parameters +BEACON: INFO, 000000, 000000, 8.469193, 47.39558","title":"Arduino"},{"location":"user-guide/deployment-scenarios/","text":"Deployment Scenarios The Starter Kit support a wide variety of deployments, and this article will highlight some of them. Keep data on-premise Redundancy with multiple concentrators and gateways Deployment on Windows Server Deployment of IoT Edge in the cloud Other scenarios are supported, and combinations of the below scenarios are possible. Keep data on-premise It is possible to deploy Azure IoT Edge on your own hardware, and keep all data in your local network or infrastructure. For example, by using a custom local forwarding module, it is possible to route the data to a local queue or message bus. In this case, the sensor data will never leave the on-premise network, and the connection to Azure will be used for managing the devices, handling the deduplication or managing concentrator updates for example. Scalability & Availability There are multiple strategies that you can take to improve the availability of the starter kit listed below. For the scenarios that use multiple LNS, you can further increase the availability of a concentrator by using a highly available LNS discovery service . Note : This guide is only talking about the LBS/LNS deployment configuration. For the full solution, the function endpoint, IoT Hub and Redis need to be taken into consideration as well. There is documentation for all of these services explaining the different options for HA and scalability. With the version 2.1.0 we introduced a major improvement for multi gateway deployments that allows the LNS to scale much better when using DeduplicationMode.Drop . All the deployment scenarios are now scaling to similiar levels no matter if a multi gateway deployment is used or not. Single concentrator with single LNS This is the most basic deployment you can chose. It does only deploy 1 concentrator and one network server. Each sensor can at most reach a single concentrator. Advantages Simple: the deployment is simple to start with and maintain. Low cost: No redundant hardware is used, which helps keeping the operational cost down. Disadvantages Availability: this solution has 2 points of failure: the concentrator and the network server. Either of those can go down. The result in the worst case is loss of messages. Limited reach: Since there is only a single concentrator, you have to put all your sensor within reach of that concentrator. Reliability: message delivery might be impacted. Recommended settings Target Setting Value Device Twin KeepAliveTimeout undefined or 0 Device Twin Deduplication None Device Twin GatewayId The Id of the Network Server Edge Hub environment variable MaxConnectedClients Depends on number of devices Network server environment variable IOTHUB_CONNECTION_POOL_SIZE Depends on the number of devices Multi concentrator with single LNS Multiple concentrators are deployed that reach a single network server. Each sensor can reach one or multiple concentrators. Depending on the goal of the deployment (availability and/or reach). Advantages Relatively simple Low cost Partial redundancy: if the deployment is designed to ensure that each sensor can reach at least 2 concentrators, you get higher availability than with single/single. Reach: if you deploy for reach, you can get a larger support a larger geographical deployment. To combine reach with availability, the cost will raise. Disadvantages Availability: Depending on the deployment, this solution has at least one single point of failure: the network server. The result in the worst case is loss of messages. Reliability: message delivery might be impacted. Recommended settings Target Setting Value Device Twin KeepAliveTimeout undefined or 0 Device Twin Deduplication None Device Twin GatewayId The Id of the Network Server Edge Hub Environment variable MaxConnectedClients Depends on number of devices Network server environment variable IOTHUB_CONNECTION_POOL_SIZE Depends on the number of devices Multiple concentrator with Multiple LNS Multiple concentrators are deployed that reach multiple LNS ( note one concentrator can only be connected to a single LNS). Each sensor can reach one or multiple concentrators. Depending on the goal of the deployment (availability and/or reach). To get high availability concentrator deployment and assignment to LNS should be done so that a single sensor is in range of at least 2 concentrators, both connecting to a different LNS. Advantages Availability: If the deployment is done right, the single point of failure can be eliminated. Reliability: message delivery likelihood is increased. Reach: The deployment model can be expanded Disadvantages Cost: all components need to be deployed and managed multiple times. Complexity Recommended settings Target Setting Value Device Twin KeepAliveTimeout > 0 - depending on the sensor, this can be tuned to be the time you expect a new message to come in. Ideally not > 300 Device Twin Deduplication Drop Device Twin GatewayId empty Deployment on Windows Server Some organizations only support Windows Server operating systems on their infrastructure. In this case, it is still possible to use IoT Edge and the Starter Kit by using EFLOW , short for \"Azure IoT Edge for Linux on Windows\". This allows you to run containerized Linux workloads on Windows machines. Deployment in the cloud outside of IoT Edge It is also possible to run the LNS directly in the cloud. You can run the LNS for example on AKS in the cloud without using IoT Edge. For detailed information on how to deploy the LNS in the cloud without using IoT Edge, refer to Cloud-based Network Server configuration documentation . This configuration enables you to reuse the same Network Servers for globally distributed concentrators. In previous versions, we detailed options to perform deployment of IoT Edge in the cloud. Although this is technically still possible, we strongly discourage it as it has worse performance than the current alternative. Appendix More info on deduplication strategies","title":"Deployment Scenarios"},{"location":"user-guide/deployment-scenarios/#deployment-scenarios","text":"The Starter Kit support a wide variety of deployments, and this article will highlight some of them. Keep data on-premise Redundancy with multiple concentrators and gateways Deployment on Windows Server Deployment of IoT Edge in the cloud Other scenarios are supported, and combinations of the below scenarios are possible.","title":"Deployment Scenarios"},{"location":"user-guide/deployment-scenarios/#keep-data-on-premise","text":"It is possible to deploy Azure IoT Edge on your own hardware, and keep all data in your local network or infrastructure. For example, by using a custom local forwarding module, it is possible to route the data to a local queue or message bus. In this case, the sensor data will never leave the on-premise network, and the connection to Azure will be used for managing the devices, handling the deduplication or managing concentrator updates for example.","title":"Keep data on-premise"},{"location":"user-guide/deployment-scenarios/#scalability-availability","text":"There are multiple strategies that you can take to improve the availability of the starter kit listed below. For the scenarios that use multiple LNS, you can further increase the availability of a concentrator by using a highly available LNS discovery service . Note : This guide is only talking about the LBS/LNS deployment configuration. For the full solution, the function endpoint, IoT Hub and Redis need to be taken into consideration as well. There is documentation for all of these services explaining the different options for HA and scalability. With the version 2.1.0 we introduced a major improvement for multi gateway deployments that allows the LNS to scale much better when using DeduplicationMode.Drop . All the deployment scenarios are now scaling to similiar levels no matter if a multi gateway deployment is used or not.","title":"Scalability &amp; Availability"},{"location":"user-guide/deployment-scenarios/#single-concentrator-with-single-lns","text":"This is the most basic deployment you can chose. It does only deploy 1 concentrator and one network server. Each sensor can at most reach a single concentrator.","title":"Single concentrator with single LNS"},{"location":"user-guide/deployment-scenarios/#advantages","text":"Simple: the deployment is simple to start with and maintain. Low cost: No redundant hardware is used, which helps keeping the operational cost down.","title":"Advantages"},{"location":"user-guide/deployment-scenarios/#disadvantages","text":"Availability: this solution has 2 points of failure: the concentrator and the network server. Either of those can go down. The result in the worst case is loss of messages. Limited reach: Since there is only a single concentrator, you have to put all your sensor within reach of that concentrator. Reliability: message delivery might be impacted.","title":"Disadvantages"},{"location":"user-guide/deployment-scenarios/#recommended-settings","text":"Target Setting Value Device Twin KeepAliveTimeout undefined or 0 Device Twin Deduplication None Device Twin GatewayId The Id of the Network Server Edge Hub environment variable MaxConnectedClients Depends on number of devices Network server environment variable IOTHUB_CONNECTION_POOL_SIZE Depends on the number of devices","title":"Recommended settings"},{"location":"user-guide/deployment-scenarios/#multi-concentrator-with-single-lns","text":"Multiple concentrators are deployed that reach a single network server. Each sensor can reach one or multiple concentrators. Depending on the goal of the deployment (availability and/or reach).","title":"Multi concentrator with single LNS"},{"location":"user-guide/deployment-scenarios/#advantages_1","text":"Relatively simple Low cost Partial redundancy: if the deployment is designed to ensure that each sensor can reach at least 2 concentrators, you get higher availability than with single/single. Reach: if you deploy for reach, you can get a larger support a larger geographical deployment. To combine reach with availability, the cost will raise.","title":"Advantages"},{"location":"user-guide/deployment-scenarios/#disadvantages_1","text":"Availability: Depending on the deployment, this solution has at least one single point of failure: the network server. The result in the worst case is loss of messages. Reliability: message delivery might be impacted.","title":"Disadvantages"},{"location":"user-guide/deployment-scenarios/#recommended-settings_1","text":"Target Setting Value Device Twin KeepAliveTimeout undefined or 0 Device Twin Deduplication None Device Twin GatewayId The Id of the Network Server Edge Hub Environment variable MaxConnectedClients Depends on number of devices Network server environment variable IOTHUB_CONNECTION_POOL_SIZE Depends on the number of devices","title":"Recommended settings"},{"location":"user-guide/deployment-scenarios/#multiple-concentrator-with-multiple-lns","text":"Multiple concentrators are deployed that reach multiple LNS ( note one concentrator can only be connected to a single LNS). Each sensor can reach one or multiple concentrators. Depending on the goal of the deployment (availability and/or reach). To get high availability concentrator deployment and assignment to LNS should be done so that a single sensor is in range of at least 2 concentrators, both connecting to a different LNS.","title":"Multiple concentrator with Multiple LNS"},{"location":"user-guide/deployment-scenarios/#advantages_2","text":"Availability: If the deployment is done right, the single point of failure can be eliminated. Reliability: message delivery likelihood is increased. Reach: The deployment model can be expanded","title":"Advantages"},{"location":"user-guide/deployment-scenarios/#disadvantages_2","text":"Cost: all components need to be deployed and managed multiple times. Complexity","title":"Disadvantages"},{"location":"user-guide/deployment-scenarios/#recommended-settings_2","text":"Target Setting Value Device Twin KeepAliveTimeout > 0 - depending on the sensor, this can be tuned to be the time you expect a new message to come in. Ideally not > 300 Device Twin Deduplication Drop Device Twin GatewayId empty","title":"Recommended settings"},{"location":"user-guide/deployment-scenarios/#deployment-on-windows-server","text":"Some organizations only support Windows Server operating systems on their infrastructure. In this case, it is still possible to use IoT Edge and the Starter Kit by using EFLOW , short for \"Azure IoT Edge for Linux on Windows\". This allows you to run containerized Linux workloads on Windows machines.","title":"Deployment on Windows Server"},{"location":"user-guide/deployment-scenarios/#deployment-in-the-cloud-outside-of-iot-edge","text":"It is also possible to run the LNS directly in the cloud. You can run the LNS for example on AKS in the cloud without using IoT Edge. For detailed information on how to deploy the LNS in the cloud without using IoT Edge, refer to Cloud-based Network Server configuration documentation . This configuration enables you to reuse the same Network Servers for globally distributed concentrators. In previous versions, we detailed options to perform deployment of IoT Edge in the cloud. Although this is technically still possible, we strongly discourage it as it has worse performance than the current alternative.","title":"Deployment in the cloud outside of IoT Edge"},{"location":"user-guide/deployment-scenarios/#appendix","text":"More info on deduplication strategies","title":"Appendix"},{"location":"user-guide/devguide/","text":"Developer Guidance Directory Structure The code is organized into three sections: LoRaEngine - a .NET 6 solution with the following folders: modules - Azure IoT Edge modules. LoraKeysManagerFacade - An Azure function handling device provisioning (e.g. LoRa network join, OTAA) with Azure IoT Hub as persistence layer. Arduino - Examples and references for LoRa Arduino based devices. Template - Contain code useful for the \"deploy to Azure button\" Tools - Contains tools that support the LoRaWan Gateway project BasicStation-Certificates-Generation - Bash scripts for generating self-signed certificates for LoRa Basics Station to LoRaWan Network Server interactions. Read more in \"Basics Station configuration - Authentication Modes\" Cli-LoRa-Device-Provisioning - .NET 6 Command Line tool that allows to list, query, verify, insert, edit, update and delete LoRa leaf device configurations into IoT Hub Cups-Firmware-Upgrade - Bash scripts helping Starter Kit users to generate the files needed for executing a Basics Station firmware upgrade. Read more in \"Basics Station configuration - Firmware upgrade\" Eflow - Includes a PowerShell script to install Edge For Linux On Windows (EFLOW) on a new Windows Server VM. The script is not intended to be run as-is, but should be seen as a collection of manual steps to be run to get eflow up and running. In case of doubts, read more in \"Create and provision an IoT Edge for Linux on Windows device using symmetric keys\" official documentation Samples - Contains sample decoders Docs - Additional modules, pictures and documentations LoRaEngine A .NET 6 solution with the following projects: modules - Azure IoT Edge modules. LoRaBasicsStationModule packages the Basics Station into an IoT Edge compatible docker container (See https://github.com/lorabasics/basicstation ). If you are using a RAK833-USB, you need to build your own Basics Station docker image starting from the fork at this link . LoRaWanNetworkSrvModule - is the LoRaWAN network server implementation. LoraKeysManagerFacade - An Azure function handling device provisioning (e.g. LoRa network join, OTAA) with Azure IoT Hub as persistence layer. The overall architecture This schema represent the various components and how they interact to have a better understand of the various solution elements. Once the IoT Edge engine start on the Edge device, the code modules are downloaded from the Azure Container Registry. The module containing the LoRaWan network server is downloaded on the Edge device The LoRaWan Network Server request status for the LoRa devices. The Azure Function LoraKeysManagerFacade is used to aquire the device identity from IoT Hub. In the case you're using the demo device with the automatic deployment Azure Resource Manager (ARM) template: the Azure function LoraKeysManagerFacade will register the device 47AAC86800430028 into the Azure IoT Hub for you. Otherwise you need to provision a device yourself in IoT Hub: device provisioning The Azure function LoraKeysManagerFacade sends back the device identity to the module The LoRaWan Network Server module: - instantiate the device on the LoRa Gateway if needed - gather the LoRa sensor data from the LoRaWan gateway thru the LoRa Basics\u2122 Station - decode the LoRa data if requested Publish the LoRa sensor data to Azure IoT Hub Another view of the architecture and a more message driven view is the following: Getting started with: Build and deploy LoRaEngine The following guide describes the necessary steps to build and deploy the LoRaEngine to an Azure IoT Edge installation on a LoRaWAN antenna gateway. If you want to update a LoRa Gateway running a previous version fo our software to the current release, follow this guide Used Azure services Azure IoT Hub Azure Container registry Azure Functions Redis Cache Azure Monitor Prerequisites Have LoRaWAN concentrator and edge node hardware ready for testing. The LoRaEngine has been tested and build for various hardware setups. However, for this guide we used the Seeed LoRa/LoRaWAN Gateway Kit and concentrator and the Seeeduino LoRaWAN as edge node. Installed Azure IoT Edge on your LoRaWAN concentrator enabled edge device. SetUp an Azure IoT Hub instance and be familiar with Azure IoT Edge module deployment mechanism. Be familiar with Azure IoT Edge module development . Note: the following guide expects that your modules will be pushed to Azure Container registry . Create a new IoT Edge device in you IoT Hub with a name of your choice and the default settings. Create Redis Cache Create a Redis Cache in your resource group and the region you are using with a DNS Name of your choice and of the size Standard C0 . Leave all other settings unchanged. Navigate to your Redis Cache and from Settings -> Access Keys, note the Primary connection string (StackExchange.Redis) . Setup Azure function facade and Azure Container registry You have the option to either deploy the Azure Function code from your Visual Studio Code to Azure or create an empty Azure Function that points to a Zip file hosted by us, containing the function code. Follow one of the two sets of instructions that follow: Deploy manually using Visual Studio On your Visual Studio Solution, right click on the 'LoRaKeysManagerFacade' project, select 'deploy', then 'Azure' and then 'Azure function'. You should then arrive on a page where you just need to hit the deploy button to get the code deployed on Azure. Deploy manually using Visual Studio Code Open the Azure function folder with Visual Studio Code with the Azure Functions Plugin installed. Now run the command Azure Functions: Deploy to function app... and provide the name of the Azure function to deploy to. If prompted, select environment C# and version V3 . If you want to just deploy the function from Visual Studio Code with the root project folder iotedge-lorawan-starterkit open (of which the Function is a subfolder /LoRaEngine/LoraKeysManagerFacade ), you need to run the Visual Studio Command Azure Functions: Deploy to function app... and then manually choose the folder LoraKeysManagerFacade/bin/Release/net6.0/publish . (Unfortunately at time of this writing we saw the behavior that VSCode is proposing the wrong folder). Building the function does not work in this way unfortunately. If you choose to create an empty Azure Function pointing to our Zipped code Using the Azure Portal, create a new \"Function App\" in the resource group and location you chose for the deployment, using the default creation settings. Once the function is created, navigate to the Application settings from the Overview page. Add a new Application Setting with: App Settings Name Value WEBSITE_RUN_FROM_ZIP The url of the .zip file containing the Function code Follow these next steps in both cases Configure IoT Hub and Redis connection strings in the function: Copy your Redis Cache connection string in a connection string names RedisConnectionString Copy your IoT Hub Connection string with owner policy applied: Now paste it into Application settings -> Connection strings as IoTHubConnectionString of type Custom : Also, add the previously saved Primary connection string (StackExchange.Redis) from your Redis Cache to the Connection strings of your function. Use type Custom again. From the Facade Azure function, extract the Host key of type _master and save it somewhere. (We will need it in the next step) Create your .env file in the /LoRaEngine folder by copying the example.env file located here Configure your .env file with your own Azure Container registry as well as the Facade access URL and credentials. Set the region to \"EU\" or \"US\" based on your location. You do not need to change any of the other settings at this point. Those variables will be used by our Azure IoT Edge solution template . ... CONTAINER_REGISTRY_ADDRESS=yourregistry.azurecr.io CONTAINER_REGISTRY_USERNAME=yourlogin CONTAINER_REGISTRY_PASSWORD=registrypassword ... REGION=EU ... FACADE_SERVER_URL=https://yourfunction.azurewebsites.net/api/ FACADE_AUTH_CODE=yourfunctionpassword ... Use a Proxy server to connect your edge gateway to Azure This step is optional and should only be executed if your edge gateway needs to use a proxy server to communicate with Azure Follow the guide on configuring an IoT Edge device to communicate through a proxy server to: Configure the Docker daemon and the IoT Edge daemon on your device to use a proxy server. Configure the edgeAgent properties in the config.yaml file on your device. Set environment variables for the IoT Edge runtime in the deployment manifest. After that, add the environment variable https_proxy to the LoRaWanNetworkSrvModule in your IoT Hub \u2192 IoT Edge \u2192 Edge Device \u2192 Set Modules section. End of optional proxy configuration Setup concentrator with Azure IoT Edge Note: if your LoRa chip set is connected by SPI on raspberry PI bus don't forget to enable it , (You need to restart your pi). Build and deploy Azure IoT Edge solution We will use Azure IoT Edge for Visual Studio Code extension to build, push and deploy our solution. Make sure you are logged in to the Azure Container Registry you are using. Run docker login <mycontainerregistry>.azurecr.io on your development machine. Select the architecture of your gateway (Azure IoT Edge Solution Default Platform) by clicking on the button in the taskbar and selecting amd64 or arm32v7 in the command pallette. Now, build an push the solution by right clicking deployment.template.json and select Build and Push IoT Edge Solution . After that you can push the solution to your IoT Edge device by right clicking on the device and selecting Create Deployment for single device . In the file dialog, navigate to the LoRaEngine\\config folder and select the deployment.json file which was created during the previous step. Provision LoRa leaf device The sample code used in this example is based on Seeeduino LoRaWAN with a Grove - Temperature Sensor . It sends every 30 seconds its current temperature reading and prints out a Cloud-2-Device message if one is transmitted in its receive window. The sample has configured the following sample device identifiers and credentials : DevEUI: 47AAC86800430010 AppEUI: BE7A0000000014E3 AppKey: 8AFE71A145B253E49C3031AD068277A3 You will need your own identifiers when provisioning the device. Look out for these code lines: lora . setId ( NULL , \"47AAC86800430010\" , \"BE7A0000000014E3\" ); lora . setKey ( NULL , NULL , \"8AFE71A145B253E49C3031AD068277A3\" ); To provisioning a device in Azure IoT Hub with these identifiers and capable to decode simple value payload into Json you have to create a device with: Device Id: 47AAC86800430010 and Device Twin's deired properties: \"desired\" : { \"AppEUI\" : \"BE7A0000000014E3\" , \"AppKey\" : \"8AFE71A145B253E49C3031AD068277A3\" , \"SensorDecoder\" : \"DecoderValueSensor\" } You can provision the device manually in the Azure portal or use the provided Command Line Interface Provisioning Tool to list, query, verify add, update, and remove devices . The command to execute is: dotnet run -- add - -type OTAA - -deveui 47AAC86800430010 - -appeui BE7A0000000014E3 - -appkey 8AFE71A145B253E49C3031AD068277A3 - -decoder DecoderValueSensor To manually provision the device in IoT Hub, do the following: Device to Cloud and Cloud to Device messaging in action As soon as you start your device you should see the following: DevAddr, AppSKey and NwkSKey are generated and stored in the Device Twin, e.g.: \"desired\" : { \"AppEUI\" : \"BE7A0000000014E3\" , \"AppKey\" : \"8AFE71A145B253E49C3031AD068277A3\" , \"SensorDecoder\" : \"DecoderValueSensor\" , \"AppSKey\" : \"5E8513F64D99A63753A5F0DBB9FB9F91\" , \"NwkSKey\" : \"C0EF4B9495BD4A4C32B42438CD52D4B8\" , \"DevAddr\" : \"025DEAAE\" , \"DevNonce\" : \"D9B6\" } If you follow the logs of the network server module (e.g. sudo iotedge logs LoRaWanNetworkSrvModule -f ) you can follow the LoRa device join: {\"rxpk\":[{\"tmst\":3831950603,\"chan\":2,\"rfch\":1,\"freq\":868.500000,\"stat\":1,\"modu\":\"LORA\",\"datr\":\"SF7BW125\",\"codr\":\"4/5\",\"lsnr\":8.5,\"rssi\":-30,\"size\":23,\"data\":\"AOMUAAAAAHq+EABDAGjIqkfZtkroyCc=\"}]} Join Request Received {\"txpk\":{\"imme\":false,\"data\":\"IE633dznxvgA89ZTkH1jET0=\",\"tmst\":3836950603,\"size\":17,\"freq\":868.5,\"rfch\":0,\"modu\":\"LORA\",\"datr\":\"SF7BW125\",\"codr\":\"4/5\",\"powe\":14,\"ipol\":true}} Using edgeHub as local queue Updating twins... Join Accept sent TX ACK RECEIVED Every 30 seconds the temperature is transmitted by the device, e.g.: { \"time\" : null , \"tmms\" : 0 , \"tmst\" : 4226472308 , \"freq\" : 868.5 , \"chan\" : 2 , \"rfch\" : 1 , \"stat\" : 1 , \"modu\" : \"LORA\" , \"datr\" : \"SF12BW125\" , \"codr\" : \"4/5\" , \"rssi\" : -33 , \"lsnr\" : 7.5 , \"size\" : 18 , \"data\" : { \"temperature\" : 18.78 }, \"EUI\" : \"47AAC86800430010\" , \"gatewayId\" : \"berry2\" , \"edgets\" : 1534253192857 } Note: an easy way to follow messages send from the device is again with VSCode: right click on the device in the explorer -> Start Monitoring D2C Message . This is how a complete transmission looks like: You can even test sending Cloud-2-Device message (e.g. by VSCode right click on the device in the explorer -> Send C2D Message To Device ). The Arduino example provided above will print the message on the console. Keep in mind that a LoRaWAN Class A device will only receive after a transmit, in our case every 30 seconds. Observability Refer to the Observability guide if you want to learn about how to use the starter kit observability features. Debugging in Visual Studio, outside of IoT Edge and Docker It is possible to run the LoRaEngine locally from Visual Studio in order to enable a better debugging experience. Here are the steps you will need to follow in order to enable this feature: You need to point the cups.uri and/or the tc.uri Basics Station files to the endpoints exposed by your machine (i.e. https://IP_ADDRESS:5002 and wss://IP_ADDRESS:5001 when using a server PFX certificate or ws://IP_ADDRESS:5000 ) If you are using a Wireless network in Windows, make sure it is configured as a private network in your Windows settings. Otherwise, the Windows Firewall could bock the incoming packets. Open the properties of the project LoRaWanNetworkServerModule and set the following Environment Variables under the Debug tab: 'IOTEDGE_IOTHUBHOSTNAME': <your iot hub hostname>.azure-devices.net 'ENABLE_GATEWAY': false 'FACADE_SERVER_URL': <http://localhost:7071/api/> (when debugging locally or any other URL of the Azure function you want to use) 'IOTEDGE_DEVICEID': The name of your PC 'FACADE_AUTH_CODE': (only needed for deployed Azure Function) the code for authenticating and authorizing requests 'LOG_LEVEL': 1 or Debug (optional, to activate most verbose logging level) 'LOCAL_DEVELOPMENT': true Add a local.settings.json file to the project LoRaKeysManagerFacade containing: { \"IsEncrypted\" : false , \"values\" : { \"AzureWebJobsStorage\" : \"<Connection String of your deployed blob storage>\" , \"WEBSITE_CONTENTSHARE\" : \"<Name of your Azure function>\" }, \"ConnectionStrings\" : { \"IoTHubConnectionString\" : \"<Connection string of your IoT Hub Owner (go to keys -> IoT Hub owner and select the connection string)>\" , \"RedisConnectionString\" : \"<Connection string of your Redis Cache>\" } } Right click on your solution and select properties, select multiple startup projects. Start LoRaWanNetworkSrvModule and LoRaKeysManagerFacade . If you hit start in your VS solution, you will receive messages directly from your LoRa Basics\u2122 Station. You will be able to debug directly from your computer. Happy Debugging!","title":"Developer Guidance"},{"location":"user-guide/devguide/#developer-guidance","text":"","title":"Developer Guidance"},{"location":"user-guide/devguide/#directory-structure","text":"The code is organized into three sections: LoRaEngine - a .NET 6 solution with the following folders: modules - Azure IoT Edge modules. LoraKeysManagerFacade - An Azure function handling device provisioning (e.g. LoRa network join, OTAA) with Azure IoT Hub as persistence layer. Arduino - Examples and references for LoRa Arduino based devices. Template - Contain code useful for the \"deploy to Azure button\" Tools - Contains tools that support the LoRaWan Gateway project BasicStation-Certificates-Generation - Bash scripts for generating self-signed certificates for LoRa Basics Station to LoRaWan Network Server interactions. Read more in \"Basics Station configuration - Authentication Modes\" Cli-LoRa-Device-Provisioning - .NET 6 Command Line tool that allows to list, query, verify, insert, edit, update and delete LoRa leaf device configurations into IoT Hub Cups-Firmware-Upgrade - Bash scripts helping Starter Kit users to generate the files needed for executing a Basics Station firmware upgrade. Read more in \"Basics Station configuration - Firmware upgrade\" Eflow - Includes a PowerShell script to install Edge For Linux On Windows (EFLOW) on a new Windows Server VM. The script is not intended to be run as-is, but should be seen as a collection of manual steps to be run to get eflow up and running. In case of doubts, read more in \"Create and provision an IoT Edge for Linux on Windows device using symmetric keys\" official documentation Samples - Contains sample decoders Docs - Additional modules, pictures and documentations","title":"Directory Structure"},{"location":"user-guide/devguide/#loraengine","text":"A .NET 6 solution with the following projects: modules - Azure IoT Edge modules. LoRaBasicsStationModule packages the Basics Station into an IoT Edge compatible docker container (See https://github.com/lorabasics/basicstation ). If you are using a RAK833-USB, you need to build your own Basics Station docker image starting from the fork at this link . LoRaWanNetworkSrvModule - is the LoRaWAN network server implementation. LoraKeysManagerFacade - An Azure function handling device provisioning (e.g. LoRa network join, OTAA) with Azure IoT Hub as persistence layer.","title":"LoRaEngine"},{"location":"user-guide/devguide/#the-overall-architecture","text":"This schema represent the various components and how they interact to have a better understand of the various solution elements. Once the IoT Edge engine start on the Edge device, the code modules are downloaded from the Azure Container Registry. The module containing the LoRaWan network server is downloaded on the Edge device The LoRaWan Network Server request status for the LoRa devices. The Azure Function LoraKeysManagerFacade is used to aquire the device identity from IoT Hub. In the case you're using the demo device with the automatic deployment Azure Resource Manager (ARM) template: the Azure function LoraKeysManagerFacade will register the device 47AAC86800430028 into the Azure IoT Hub for you. Otherwise you need to provision a device yourself in IoT Hub: device provisioning The Azure function LoraKeysManagerFacade sends back the device identity to the module The LoRaWan Network Server module: - instantiate the device on the LoRa Gateway if needed - gather the LoRa sensor data from the LoRaWan gateway thru the LoRa Basics\u2122 Station - decode the LoRa data if requested Publish the LoRa sensor data to Azure IoT Hub Another view of the architecture and a more message driven view is the following:","title":"The overall architecture"},{"location":"user-guide/devguide/#getting-started-with-build-and-deploy-loraengine","text":"The following guide describes the necessary steps to build and deploy the LoRaEngine to an Azure IoT Edge installation on a LoRaWAN antenna gateway. If you want to update a LoRa Gateway running a previous version fo our software to the current release, follow this guide","title":"Getting started with: Build and deploy LoRaEngine"},{"location":"user-guide/devguide/#used-azure-services","text":"Azure IoT Hub Azure Container registry Azure Functions Redis Cache Azure Monitor","title":"Used Azure services"},{"location":"user-guide/devguide/#prerequisites","text":"Have LoRaWAN concentrator and edge node hardware ready for testing. The LoRaEngine has been tested and build for various hardware setups. However, for this guide we used the Seeed LoRa/LoRaWAN Gateway Kit and concentrator and the Seeeduino LoRaWAN as edge node. Installed Azure IoT Edge on your LoRaWAN concentrator enabled edge device. SetUp an Azure IoT Hub instance and be familiar with Azure IoT Edge module deployment mechanism. Be familiar with Azure IoT Edge module development . Note: the following guide expects that your modules will be pushed to Azure Container registry . Create a new IoT Edge device in you IoT Hub with a name of your choice and the default settings.","title":"Prerequisites"},{"location":"user-guide/devguide/#create-redis-cache","text":"Create a Redis Cache in your resource group and the region you are using with a DNS Name of your choice and of the size Standard C0 . Leave all other settings unchanged. Navigate to your Redis Cache and from Settings -> Access Keys, note the Primary connection string (StackExchange.Redis) .","title":"Create Redis Cache"},{"location":"user-guide/devguide/#setup-azure-function-facade-and-azure-container-registry","text":"You have the option to either deploy the Azure Function code from your Visual Studio Code to Azure or create an empty Azure Function that points to a Zip file hosted by us, containing the function code. Follow one of the two sets of instructions that follow:","title":"Setup Azure function facade and Azure Container registry"},{"location":"user-guide/devguide/#deploy-manually-using-visual-studio","text":"On your Visual Studio Solution, right click on the 'LoRaKeysManagerFacade' project, select 'deploy', then 'Azure' and then 'Azure function'. You should then arrive on a page where you just need to hit the deploy button to get the code deployed on Azure.","title":"Deploy manually using Visual Studio"},{"location":"user-guide/devguide/#deploy-manually-using-visual-studio-code","text":"Open the Azure function folder with Visual Studio Code with the Azure Functions Plugin installed. Now run the command Azure Functions: Deploy to function app... and provide the name of the Azure function to deploy to. If prompted, select environment C# and version V3 . If you want to just deploy the function from Visual Studio Code with the root project folder iotedge-lorawan-starterkit open (of which the Function is a subfolder /LoRaEngine/LoraKeysManagerFacade ), you need to run the Visual Studio Command Azure Functions: Deploy to function app... and then manually choose the folder LoraKeysManagerFacade/bin/Release/net6.0/publish . (Unfortunately at time of this writing we saw the behavior that VSCode is proposing the wrong folder). Building the function does not work in this way unfortunately.","title":"Deploy manually using Visual Studio Code"},{"location":"user-guide/devguide/#if-you-choose-to-create-an-empty-azure-function-pointing-to-our-zipped-code","text":"Using the Azure Portal, create a new \"Function App\" in the resource group and location you chose for the deployment, using the default creation settings. Once the function is created, navigate to the Application settings from the Overview page. Add a new Application Setting with: App Settings Name Value WEBSITE_RUN_FROM_ZIP The url of the .zip file containing the Function code","title":"If you choose to create an empty Azure Function pointing to our Zipped code"},{"location":"user-guide/devguide/#follow-these-next-steps-in-both-cases","text":"Configure IoT Hub and Redis connection strings in the function: Copy your Redis Cache connection string in a connection string names RedisConnectionString Copy your IoT Hub Connection string with owner policy applied: Now paste it into Application settings -> Connection strings as IoTHubConnectionString of type Custom : Also, add the previously saved Primary connection string (StackExchange.Redis) from your Redis Cache to the Connection strings of your function. Use type Custom again. From the Facade Azure function, extract the Host key of type _master and save it somewhere. (We will need it in the next step) Create your .env file in the /LoRaEngine folder by copying the example.env file located here Configure your .env file with your own Azure Container registry as well as the Facade access URL and credentials. Set the region to \"EU\" or \"US\" based on your location. You do not need to change any of the other settings at this point. Those variables will be used by our Azure IoT Edge solution template . ... CONTAINER_REGISTRY_ADDRESS=yourregistry.azurecr.io CONTAINER_REGISTRY_USERNAME=yourlogin CONTAINER_REGISTRY_PASSWORD=registrypassword ... REGION=EU ... FACADE_SERVER_URL=https://yourfunction.azurewebsites.net/api/ FACADE_AUTH_CODE=yourfunctionpassword ...","title":"Follow these next steps in both cases"},{"location":"user-guide/devguide/#use-a-proxy-server-to-connect-your-edge-gateway-to-azure","text":"This step is optional and should only be executed if your edge gateway needs to use a proxy server to communicate with Azure Follow the guide on configuring an IoT Edge device to communicate through a proxy server to: Configure the Docker daemon and the IoT Edge daemon on your device to use a proxy server. Configure the edgeAgent properties in the config.yaml file on your device. Set environment variables for the IoT Edge runtime in the deployment manifest. After that, add the environment variable https_proxy to the LoRaWanNetworkSrvModule in your IoT Hub \u2192 IoT Edge \u2192 Edge Device \u2192 Set Modules section. End of optional proxy configuration","title":"Use a Proxy server to connect your edge gateway to Azure"},{"location":"user-guide/devguide/#setup-concentrator-with-azure-iot-edge","text":"Note: if your LoRa chip set is connected by SPI on raspberry PI bus don't forget to enable it , (You need to restart your pi). Build and deploy Azure IoT Edge solution We will use Azure IoT Edge for Visual Studio Code extension to build, push and deploy our solution. Make sure you are logged in to the Azure Container Registry you are using. Run docker login <mycontainerregistry>.azurecr.io on your development machine. Select the architecture of your gateway (Azure IoT Edge Solution Default Platform) by clicking on the button in the taskbar and selecting amd64 or arm32v7 in the command pallette. Now, build an push the solution by right clicking deployment.template.json and select Build and Push IoT Edge Solution . After that you can push the solution to your IoT Edge device by right clicking on the device and selecting Create Deployment for single device . In the file dialog, navigate to the LoRaEngine\\config folder and select the deployment.json file which was created during the previous step.","title":"Setup concentrator with Azure IoT Edge"},{"location":"user-guide/devguide/#provision-lora-leaf-device","text":"The sample code used in this example is based on Seeeduino LoRaWAN with a Grove - Temperature Sensor . It sends every 30 seconds its current temperature reading and prints out a Cloud-2-Device message if one is transmitted in its receive window. The sample has configured the following sample device identifiers and credentials : DevEUI: 47AAC86800430010 AppEUI: BE7A0000000014E3 AppKey: 8AFE71A145B253E49C3031AD068277A3 You will need your own identifiers when provisioning the device. Look out for these code lines: lora . setId ( NULL , \"47AAC86800430010\" , \"BE7A0000000014E3\" ); lora . setKey ( NULL , NULL , \"8AFE71A145B253E49C3031AD068277A3\" ); To provisioning a device in Azure IoT Hub with these identifiers and capable to decode simple value payload into Json you have to create a device with: Device Id: 47AAC86800430010 and Device Twin's deired properties: \"desired\" : { \"AppEUI\" : \"BE7A0000000014E3\" , \"AppKey\" : \"8AFE71A145B253E49C3031AD068277A3\" , \"SensorDecoder\" : \"DecoderValueSensor\" } You can provision the device manually in the Azure portal or use the provided Command Line Interface Provisioning Tool to list, query, verify add, update, and remove devices . The command to execute is: dotnet run -- add - -type OTAA - -deveui 47AAC86800430010 - -appeui BE7A0000000014E3 - -appkey 8AFE71A145B253E49C3031AD068277A3 - -decoder DecoderValueSensor To manually provision the device in IoT Hub, do the following:","title":"Provision LoRa leaf device"},{"location":"user-guide/devguide/#device-to-cloud-and-cloud-to-device-messaging-in-action","text":"As soon as you start your device you should see the following: DevAddr, AppSKey and NwkSKey are generated and stored in the Device Twin, e.g.: \"desired\" : { \"AppEUI\" : \"BE7A0000000014E3\" , \"AppKey\" : \"8AFE71A145B253E49C3031AD068277A3\" , \"SensorDecoder\" : \"DecoderValueSensor\" , \"AppSKey\" : \"5E8513F64D99A63753A5F0DBB9FB9F91\" , \"NwkSKey\" : \"C0EF4B9495BD4A4C32B42438CD52D4B8\" , \"DevAddr\" : \"025DEAAE\" , \"DevNonce\" : \"D9B6\" } If you follow the logs of the network server module (e.g. sudo iotedge logs LoRaWanNetworkSrvModule -f ) you can follow the LoRa device join: {\"rxpk\":[{\"tmst\":3831950603,\"chan\":2,\"rfch\":1,\"freq\":868.500000,\"stat\":1,\"modu\":\"LORA\",\"datr\":\"SF7BW125\",\"codr\":\"4/5\",\"lsnr\":8.5,\"rssi\":-30,\"size\":23,\"data\":\"AOMUAAAAAHq+EABDAGjIqkfZtkroyCc=\"}]} Join Request Received {\"txpk\":{\"imme\":false,\"data\":\"IE633dznxvgA89ZTkH1jET0=\",\"tmst\":3836950603,\"size\":17,\"freq\":868.5,\"rfch\":0,\"modu\":\"LORA\",\"datr\":\"SF7BW125\",\"codr\":\"4/5\",\"powe\":14,\"ipol\":true}} Using edgeHub as local queue Updating twins... Join Accept sent TX ACK RECEIVED Every 30 seconds the temperature is transmitted by the device, e.g.: { \"time\" : null , \"tmms\" : 0 , \"tmst\" : 4226472308 , \"freq\" : 868.5 , \"chan\" : 2 , \"rfch\" : 1 , \"stat\" : 1 , \"modu\" : \"LORA\" , \"datr\" : \"SF12BW125\" , \"codr\" : \"4/5\" , \"rssi\" : -33 , \"lsnr\" : 7.5 , \"size\" : 18 , \"data\" : { \"temperature\" : 18.78 }, \"EUI\" : \"47AAC86800430010\" , \"gatewayId\" : \"berry2\" , \"edgets\" : 1534253192857 } Note: an easy way to follow messages send from the device is again with VSCode: right click on the device in the explorer -> Start Monitoring D2C Message . This is how a complete transmission looks like: You can even test sending Cloud-2-Device message (e.g. by VSCode right click on the device in the explorer -> Send C2D Message To Device ). The Arduino example provided above will print the message on the console. Keep in mind that a LoRaWAN Class A device will only receive after a transmit, in our case every 30 seconds.","title":"Device to Cloud and Cloud to Device messaging in action"},{"location":"user-guide/devguide/#observability","text":"Refer to the Observability guide if you want to learn about how to use the starter kit observability features.","title":"Observability"},{"location":"user-guide/devguide/#debugging-in-visual-studio-outside-of-iot-edge-and-docker","text":"It is possible to run the LoRaEngine locally from Visual Studio in order to enable a better debugging experience. Here are the steps you will need to follow in order to enable this feature: You need to point the cups.uri and/or the tc.uri Basics Station files to the endpoints exposed by your machine (i.e. https://IP_ADDRESS:5002 and wss://IP_ADDRESS:5001 when using a server PFX certificate or ws://IP_ADDRESS:5000 ) If you are using a Wireless network in Windows, make sure it is configured as a private network in your Windows settings. Otherwise, the Windows Firewall could bock the incoming packets. Open the properties of the project LoRaWanNetworkServerModule and set the following Environment Variables under the Debug tab: 'IOTEDGE_IOTHUBHOSTNAME': <your iot hub hostname>.azure-devices.net 'ENABLE_GATEWAY': false 'FACADE_SERVER_URL': <http://localhost:7071/api/> (when debugging locally or any other URL of the Azure function you want to use) 'IOTEDGE_DEVICEID': The name of your PC 'FACADE_AUTH_CODE': (only needed for deployed Azure Function) the code for authenticating and authorizing requests 'LOG_LEVEL': 1 or Debug (optional, to activate most verbose logging level) 'LOCAL_DEVELOPMENT': true Add a local.settings.json file to the project LoRaKeysManagerFacade containing: { \"IsEncrypted\" : false , \"values\" : { \"AzureWebJobsStorage\" : \"<Connection String of your deployed blob storage>\" , \"WEBSITE_CONTENTSHARE\" : \"<Name of your Azure function>\" }, \"ConnectionStrings\" : { \"IoTHubConnectionString\" : \"<Connection string of your IoT Hub Owner (go to keys -> IoT Hub owner and select the connection string)>\" , \"RedisConnectionString\" : \"<Connection string of your Redis Cache>\" } } Right click on your solution and select properties, select multiple startup projects. Start LoRaWanNetworkSrvModule and LoRaKeysManagerFacade . If you hit start in your VS solution, you will receive messages directly from your LoRa Basics\u2122 Station. You will be able to debug directly from your computer. Happy Debugging!","title":"Debugging in Visual Studio, outside of IoT Edge and Docker"},{"location":"user-guide/documentation/","text":"Working with the documentation This documentation site is built using MkDocs and mkdocs-material . These tools generate a static website based on a configuration file and a set of markdown files in the docs/main branch . docs/main is a detached branch that is locked and only accepts PRs. Two Actions are triggered by the PR: On PR creation: Markdown linting and link checking On PR merge : deployment of dev version of docs website Working locally Checkout the branch that contains the documentation: git worktree git checkout docs/main # If you want to have `dev` branch and `docs` branch side by side, # try out git worktree # from the working folder: git worktree add c:/path-to-sources/lorawan.docs docs/main The recommended approach is using docker to serve the static site locally: serve documentation locally docker pull squidfunk/mkdocs-material # in the folder where the `docs/main` branch lives locally: docker run --rm -it -p 8000 :8000 -v ${ PWD } :/docs squidfunk/mkdocs-material Now you can see the site running locally on http://localhost:8000 . You can change the port in the docker run command. Required extensions We are using extensions which are not supported by the mkdocs-material container out-of-the-box. There are two ways to deal with this: use the manual approach Create a custom docker image with the plugin installed: Dockerfile FROM squidfunk/mkdocs-material COPY requirements.txt . RUN pip install -r requirements.txt The Dockerfile is available in the repo as well. ```bash title=\"Build and run container\" # in the directory where your dockerfile is docker build . -t mkdocs-material-with-extensions docker run --rm -it -p 8000:8000 -v ${PWD}:/docs mkdocs-material-with-extensions ``` Alternate approach Install Python and pip, and then the required packages: install prerequisites pip install - r requirements . txt run mkdocs mkdocs serve Deployment For deployment, the additional toolset mike is used. This tool allows us to deploy multiple versions of the documentation. There is a manual GitHub Action to deploy a specific version. Configuration The file mkdocs.yml provides the main configuration for the website, such as color and themes, plugins and extension. The TOC is also defined in the config file, under the section nav . TOC is not auto-generated Currently, new pages are not automatically added to the TOC. You will need to manually add new pages to the nav section of the configuration file.","title":"Working with the documentation"},{"location":"user-guide/documentation/#working-with-the-documentation","text":"This documentation site is built using MkDocs and mkdocs-material . These tools generate a static website based on a configuration file and a set of markdown files in the docs/main branch . docs/main is a detached branch that is locked and only accepts PRs. Two Actions are triggered by the PR: On PR creation: Markdown linting and link checking On PR merge : deployment of dev version of docs website","title":"Working with the documentation"},{"location":"user-guide/documentation/#working-locally","text":"Checkout the branch that contains the documentation: git worktree git checkout docs/main # If you want to have `dev` branch and `docs` branch side by side, # try out git worktree # from the working folder: git worktree add c:/path-to-sources/lorawan.docs docs/main The recommended approach is using docker to serve the static site locally: serve documentation locally docker pull squidfunk/mkdocs-material # in the folder where the `docs/main` branch lives locally: docker run --rm -it -p 8000 :8000 -v ${ PWD } :/docs squidfunk/mkdocs-material Now you can see the site running locally on http://localhost:8000 . You can change the port in the docker run command. Required extensions We are using extensions which are not supported by the mkdocs-material container out-of-the-box. There are two ways to deal with this: use the manual approach Create a custom docker image with the plugin installed: Dockerfile FROM squidfunk/mkdocs-material COPY requirements.txt . RUN pip install -r requirements.txt The Dockerfile is available in the repo as well. ```bash title=\"Build and run container\" # in the directory where your dockerfile is docker build . -t mkdocs-material-with-extensions docker run --rm -it -p 8000:8000 -v ${PWD}:/docs mkdocs-material-with-extensions ```","title":"Working locally"},{"location":"user-guide/documentation/#alternate-approach","text":"Install Python and pip, and then the required packages: install prerequisites pip install - r requirements . txt run mkdocs mkdocs serve","title":"Alternate approach"},{"location":"user-guide/documentation/#deployment","text":"For deployment, the additional toolset mike is used. This tool allows us to deploy multiple versions of the documentation. There is a manual GitHub Action to deploy a specific version.","title":"Deployment"},{"location":"user-guide/documentation/#configuration","text":"The file mkdocs.yml provides the main configuration for the website, such as color and themes, plugins and extension. The TOC is also defined in the config file, under the section nav . TOC is not auto-generated Currently, new pages are not automatically added to the TOC. You will need to manually add new pages to the nav section of the configuration file.","title":"Configuration"},{"location":"user-guide/gateway-troubleshooting/","text":"Basics Station and Concentrator Troubleshooting We list some of the the issues we have encountered running the basics station; and tips on how to resolve them: The following errors were encountered when setting up the basics station for Class-B beaconing (see this page for more context). The concentrator fails to connect: ERROR: CONCENTRATOR UNCONNECTED It is possible this is a hardware issue. Make sure that the LoRa module is tightly connected to the raspberry pi and reboot it. The concentrator fails to start: [ RAL:ERRO ] Concentrator start failed: lgw_start This could be due to the SPI speed being too high. By default it is 8000000; 2000000 or 1000000 might be more suitable. This can be changed by setting the LORAGW_SPI_SPEED env var. LORAGW_SPI_SPEED = 2000000 ../path/to/bin/station Beaconing is suspended but doesn't resume/takes a long time to resume. This is typically characterized by many messages in the XDEBUG logs rejecting the PPS: [ SYN:XDEB ] SYNC: ustime = 0x00002D5B691E ( Q = 117 ) : xticks = 0x0029b132 xtime = 0x9A00000029B132 - PPS: pps_xticks = 0x0029aa38 ( 2730552 ) pps_xtime = 0x9A00000029AA38 ( pps_en = 1 ) [ SYN:XDEB ] SYNC: ustime = 0x00002D7B76E1 ( Q = 131 ) : xticks = 0x0049bee0 xtime = 0x9A00000049BEE0 - PPS: pps_xticks = 0x0029b207 ( 2732551 ) pps_xtime = 0x9A00000029B207 ( pps_en = 1 ) [ SYN:XDEB ] PPS: Rejecting PPS ( xtime/pps_xtime spread ) : curr->xtime = 0x9A00000049BEE0 curr->pps_xtime = 0x9A00000029B207 diff = 2100441 ( >1010000 ) This issue can sometimes be resolved by rebooting the gateway. If that does not work, the section of the code rejecting the PPS can be disabled in the code. Note : The following instructions on how to diable PPS rejection could have unintended side-effects. Proceed with caution. The code that needs to be diabled can be found in basicstation/src/timesync.c . It is enough to comment out the following 2 sections (lines 259-263 and 266-270 in release 2.0.6) and recompile. if ( curr -> xtime - curr -> pps_xtime > PPM + TX_MIN_GAP ) { LOG ( MOD_SYN | XDEBUG , \"PPS: Rejecting PPS (xtime/pps_xtime spread): curr->xtime=0x%lX curr->pps_xtime=0x%lX diff=%lu (>%u)\" , curr -> xtime , curr -> pps_xtime , curr -> xtime - curr -> pps_xtime , PPM + TX_MIN_GAP ); goto done ; // no PPS since last time sync } and if ( err > MAX_PPS_ERROR && err < PPM - MAX_PPS_ERROR ) { LOG ( MOD_SYN | XDEBUG , \"PPS: Rejecting PPS (consecutive pps_xtime error): curr->pps_xtime=0x%lX last->pps_xtime=0x%lX diff=%lu\" , curr -> pps_xtime , last -> pps_xtime , curr -> pps_xtime - last -> pps_xtime ); goto done ; // out of scope - probably no value latched }","title":"Basics Station and Concentrator Troubleshooting"},{"location":"user-guide/gateway-troubleshooting/#basics-station-and-concentrator-troubleshooting","text":"We list some of the the issues we have encountered running the basics station; and tips on how to resolve them: The following errors were encountered when setting up the basics station for Class-B beaconing (see this page for more context). The concentrator fails to connect: ERROR: CONCENTRATOR UNCONNECTED It is possible this is a hardware issue. Make sure that the LoRa module is tightly connected to the raspberry pi and reboot it. The concentrator fails to start: [ RAL:ERRO ] Concentrator start failed: lgw_start This could be due to the SPI speed being too high. By default it is 8000000; 2000000 or 1000000 might be more suitable. This can be changed by setting the LORAGW_SPI_SPEED env var. LORAGW_SPI_SPEED = 2000000 ../path/to/bin/station Beaconing is suspended but doesn't resume/takes a long time to resume. This is typically characterized by many messages in the XDEBUG logs rejecting the PPS: [ SYN:XDEB ] SYNC: ustime = 0x00002D5B691E ( Q = 117 ) : xticks = 0x0029b132 xtime = 0x9A00000029B132 - PPS: pps_xticks = 0x0029aa38 ( 2730552 ) pps_xtime = 0x9A00000029AA38 ( pps_en = 1 ) [ SYN:XDEB ] SYNC: ustime = 0x00002D7B76E1 ( Q = 131 ) : xticks = 0x0049bee0 xtime = 0x9A00000049BEE0 - PPS: pps_xticks = 0x0029b207 ( 2732551 ) pps_xtime = 0x9A00000029B207 ( pps_en = 1 ) [ SYN:XDEB ] PPS: Rejecting PPS ( xtime/pps_xtime spread ) : curr->xtime = 0x9A00000049BEE0 curr->pps_xtime = 0x9A00000029B207 diff = 2100441 ( >1010000 ) This issue can sometimes be resolved by rebooting the gateway. If that does not work, the section of the code rejecting the PPS can be disabled in the code. Note : The following instructions on how to diable PPS rejection could have unintended side-effects. Proceed with caution. The code that needs to be diabled can be found in basicstation/src/timesync.c . It is enough to comment out the following 2 sections (lines 259-263 and 266-270 in release 2.0.6) and recompile. if ( curr -> xtime - curr -> pps_xtime > PPM + TX_MIN_GAP ) { LOG ( MOD_SYN | XDEBUG , \"PPS: Rejecting PPS (xtime/pps_xtime spread): curr->xtime=0x%lX curr->pps_xtime=0x%lX diff=%lu (>%u)\" , curr -> xtime , curr -> pps_xtime , curr -> xtime - curr -> pps_xtime , PPM + TX_MIN_GAP ); goto done ; // no PPS since last time sync } and if ( err > MAX_PPS_ERROR && err < PPM - MAX_PPS_ERROR ) { LOG ( MOD_SYN | XDEBUG , \"PPS: Rejecting PPS (consecutive pps_xtime error): curr->pps_xtime=0x%lX last->pps_xtime=0x%lX diff=%lu\" , curr -> pps_xtime , last -> pps_xtime , curr -> pps_xtime - last -> pps_xtime ); goto done ; // out of scope - probably no value latched }","title":"Basics Station and Concentrator Troubleshooting"},{"location":"user-guide/lns-configuration/","text":"Network Server Configuration Network Server IoT Edge Module configuration The following table is providing a list of configuration options, to be provided as environment variables for manual configuration of the LoRaWanNetworkSrvModule : Environment variable name Description Mandatory ENABLE_GATEWAY Indicates whether the edgeHub gateway should be enabled or not No (defaults to true ) HTTPS_PROXY HTTPS proxy url No RX2_DATR RX2 data rate; useful to override the default regional RX2 Data Rate at a global level No (defaults to null, regional default value is used) RX2_FREQ RX2 frequency; useful to override the default regional RX2 Frequency at a global level No (defaults to null, regional default value is used) FACADE_SERVER_URL Azure Facade function url, e.g. https://deployedfunction.azurewebsites.net/api Yes FACADE_AUTH_CODE Azure Facade function auth code Yes LOG_LEVEL Logging level No (defaults to level 4 (Error) LOG_TO_CONSOLE Indicates whether logging to console is enabled or not No (default to true ) LOG_TO_TCP Indicates whether logging to TCP is enabled or not (used mainly for integration tests) No (defaults to false ) LOG_TO_HUB Indicates whether logging to IoT Hub is enabled or not No (defaults to false ) LOG_TO_TCP_ADDRESS IP address for TCP logs Yes, only if TCP logging is enabled LOG_TO_TCP_PORT TCP port to send logs to Yes, only if TCP logging is enabled NETID Gateway network ID No (defaults to network id 1) AllowedDevAddresses List of allowed dev addresses from which message processing is enabled. No (by default allows all messages coming from the defined NETID to be processed) LNS_SERVER_PFX_PATH Path of the .pfx certificate to be used for LNS Server endpoint No LNS_SERVER_PFX_PASSWORD Password of the .pfx certificate to be used for LNS Server endpoint No CLIENT_CERTIFICATE_MODE Specifies the client certificate mode with which the server should be run No (defaults to NoCertificate ) LNS_VERSION Version of the LNS No IOTHUB_CONNECTION_POOL_SIZE AMQP Connection Pool Size for communication to IoT Edge Hub / IoT Hub (depending on ENABLE_GATEWAY ). Increasing this value to higher number will improve scalability; for more information see Scalability No (defaults to 1) APPLICATIONINSIGHTS_CONNECTION_STRING Connection string for forwarding metrics to Application Insights No The following settings can be configured via desired properties of the Network Server module twin in IoT Hub: Property name Description Mandatory FacadeServerUrl Azure Facade function url Yes FacadeAuthCode Azure Facade function auth code Yes ProcessingDelayInMilliseconds Processing delay (in milliseconds) to be used for the LNS not owning the connection for a device in a multi-gateway scenario; for more information see Scalability No (defaults to 400 ms) Cloud-based Network Server configuration You can run the Network Server directly in the cloud without requiring IoT Edge, e.g. on an AKS cluster. In general, the same environment variables as for the module configuration apply (e.g. for the facade connection). In addition make sure to set the following environment variables: Environment variable name Description Mandatory CLOUD_DEPLOYMENT Switch to indicate that the LNS is deployed as a standalone cloud-based instance Yes (must be set to true) ENABLE_GATEWAY Gateway mode is only applicable to IoT Edge-based deployments. Must be set to false or unset. No IOTHUBHOSTNAME Host name of the IoT Hub to which the LNS should connect to. Yes HOSTNAME Identifier of the LNS. Yes REDIS_CONNECTION_STRING Connection string used to connect to the deployed Redis instance. Yes FACADE_SERVER_URL Azure Facade function url, e.g. https://deployedfunction.azurewebsites.net/api Yes FACADE_AUTH_CODE Azure Facade function auth code Yes","title":"Network Server Configuration"},{"location":"user-guide/lns-configuration/#network-server-configuration","text":"","title":"Network Server Configuration"},{"location":"user-guide/lns-configuration/#network-server-iot-edge-module-configuration","text":"The following table is providing a list of configuration options, to be provided as environment variables for manual configuration of the LoRaWanNetworkSrvModule : Environment variable name Description Mandatory ENABLE_GATEWAY Indicates whether the edgeHub gateway should be enabled or not No (defaults to true ) HTTPS_PROXY HTTPS proxy url No RX2_DATR RX2 data rate; useful to override the default regional RX2 Data Rate at a global level No (defaults to null, regional default value is used) RX2_FREQ RX2 frequency; useful to override the default regional RX2 Frequency at a global level No (defaults to null, regional default value is used) FACADE_SERVER_URL Azure Facade function url, e.g. https://deployedfunction.azurewebsites.net/api Yes FACADE_AUTH_CODE Azure Facade function auth code Yes LOG_LEVEL Logging level No (defaults to level 4 (Error) LOG_TO_CONSOLE Indicates whether logging to console is enabled or not No (default to true ) LOG_TO_TCP Indicates whether logging to TCP is enabled or not (used mainly for integration tests) No (defaults to false ) LOG_TO_HUB Indicates whether logging to IoT Hub is enabled or not No (defaults to false ) LOG_TO_TCP_ADDRESS IP address for TCP logs Yes, only if TCP logging is enabled LOG_TO_TCP_PORT TCP port to send logs to Yes, only if TCP logging is enabled NETID Gateway network ID No (defaults to network id 1) AllowedDevAddresses List of allowed dev addresses from which message processing is enabled. No (by default allows all messages coming from the defined NETID to be processed) LNS_SERVER_PFX_PATH Path of the .pfx certificate to be used for LNS Server endpoint No LNS_SERVER_PFX_PASSWORD Password of the .pfx certificate to be used for LNS Server endpoint No CLIENT_CERTIFICATE_MODE Specifies the client certificate mode with which the server should be run No (defaults to NoCertificate ) LNS_VERSION Version of the LNS No IOTHUB_CONNECTION_POOL_SIZE AMQP Connection Pool Size for communication to IoT Edge Hub / IoT Hub (depending on ENABLE_GATEWAY ). Increasing this value to higher number will improve scalability; for more information see Scalability No (defaults to 1) APPLICATIONINSIGHTS_CONNECTION_STRING Connection string for forwarding metrics to Application Insights No The following settings can be configured via desired properties of the Network Server module twin in IoT Hub: Property name Description Mandatory FacadeServerUrl Azure Facade function url Yes FacadeAuthCode Azure Facade function auth code Yes ProcessingDelayInMilliseconds Processing delay (in milliseconds) to be used for the LNS not owning the connection for a device in a multi-gateway scenario; for more information see Scalability No (defaults to 400 ms)","title":"Network Server IoT Edge Module configuration"},{"location":"user-guide/lns-configuration/#cloud-based-network-server-configuration","text":"You can run the Network Server directly in the cloud without requiring IoT Edge, e.g. on an AKS cluster. In general, the same environment variables as for the module configuration apply (e.g. for the facade connection). In addition make sure to set the following environment variables: Environment variable name Description Mandatory CLOUD_DEPLOYMENT Switch to indicate that the LNS is deployed as a standalone cloud-based instance Yes (must be set to true) ENABLE_GATEWAY Gateway mode is only applicable to IoT Edge-based deployments. Must be set to false or unset. No IOTHUBHOSTNAME Host name of the IoT Hub to which the LNS should connect to. Yes HOSTNAME Identifier of the LNS. Yes REDIS_CONNECTION_STRING Connection string used to connect to the deployed Redis instance. Yes FACADE_SERVER_URL Azure Facade function url, e.g. https://deployedfunction.azurewebsites.net/api Yes FACADE_AUTH_CODE Azure Facade function auth code Yes","title":"Cloud-based Network Server configuration"},{"location":"user-guide/lns-discovery/","text":"LNS discovery The LNS protocol specifies that the first request an LBS makes is to the /router-info discovery endpoint. The LNS from the starter kit implements the /router-info endpoint and redirects any requests to that endpoint to the /router-data endpoint on the same LNS. In addition to the discovery endpoint on the LNS itself, we also support a standalone discovery service, which you can use to dynamically distribute LBS connections to different LNS, ensuring failover of LBS to another LNS in case the current LNS is experiencing downtime. The discovery service is a .NET application, and its implementation is part of the LoRaWan.NetworkServerDiscovery project. The discovery service relies on configuration from IoT Hub module twins to associate each LBS with a set of LNS to which it may connect to. For this the configuration needs to take into account possible network boundaries - by defining these networks you can control which LBS should connect to which LNS. For this you need to configure your LBS twin in IoT Hub as follows: { ... , \"tags\" : { \"network\" : \"<network-id>\" }, ... } The network ID may only consist of alphanumeric characters. After you configured the LBS, you need to also configure your LNS with the same network. The LNS twin furthermore needs to contain the IP/DNS of the host, hence the twin of the LNS module should look like: Warning We will only query the LNS module twins for LNS within the same network. If you configure the network/host address on the Edge device twin, it will not be detected. { ... , \"tags\" : { \"network\" : \"<network-id>\" }, ... , \"properties\" : { \"desired\" : { \"hostAddress\" : \"wss://mylns:5001\" , ... } } } Keep in mind that the hostAddress value must include the scheme and the host name. In case you omit the port, the defaults of the protocol will be used. Note The discovery endpoint distributes LBS to LNS using a round-robin distribution mechanism. It will always try the same LNS per LBS first. Hence, it can be used for an active/passive scenario, but not to distribute load more evenly across different LNS. Note The configuration values of the network name of a station, respectively of the set of LNS in a given network, are cached by the discovery endpoint for 6 hours. If you updated the configuration and want it to take effect sooner, make sure to restart the discovery service to ensure that the cache is refreshed. You can choose to deploy the discovery service either on-prem or in the cloud. For both deployment strategies, you can configure the following behavior: Configuration You can configure the following behavior of the LNS discovery service. Environment variable Description Deployment type Logging__LogLevel__Default Configures the default log level. For more fine-grained configuration of the console log level, refer to Logging in .NET Core and ASP.NET Core All APPLICATIONINSIGHTS_CONNECTION_STRING Useful for sending telemetry data to Application Insights All Logging__ApplicationInsights__LogLevel__<Default|..> Configures the Application Insights log levels All ASPNETCORE_URLS Configures on which URLs the service is listening. Multiple URLs should be separated by a ; All IotHubHostName Host name of the Iot Hub. Only used if you connect to IoT Hub using managed identities. App Service ConnectionStrings__IotHub Connection string to the Iot Hub. In case of App Service deployment, use managed identities instead. On-prem Kestrel__Certificates__Default__<Path|KeyPath|...> Configures the certificates that should be used by the discovery endpoint as described in the Minimal APIs overview . Instead of using the appsettings.json , you can use environment variables of the same structure, where a double underscore replaces a level of hierarchy. On-prem Deployment in Azure We recommend that you use an Azure App Service to run the discovery service in the cloud. You can follow the App Service Quickstart for instructions how to deploy an ASP.NET Core app in an Azure App Service. When using an App Service, make sure that you: Enable the system assigned managed identity Assign a role to the system assigned identity which allows it to execute the Microsoft.Devices/IotHubs/twins/read data action for reading the IoT Hub twins. Built-in IoT Hub Twin Contributor role allows that. Specify the Iot Hub host name as described in the configuration section. On-premises deployment When deploying the discovery service on-premises, please read how to Host ASP.NET Core on Windows with IIS (or any other hosting strategy you may want to use). The discovery endpoint exposes metrics in Prometheus format. You must specify the IoT Hub connection string as described in the configuration section, since you cannot use managed identities with an on-premises deployment.","title":"LNS discovery"},{"location":"user-guide/lns-discovery/#lns-discovery","text":"The LNS protocol specifies that the first request an LBS makes is to the /router-info discovery endpoint. The LNS from the starter kit implements the /router-info endpoint and redirects any requests to that endpoint to the /router-data endpoint on the same LNS. In addition to the discovery endpoint on the LNS itself, we also support a standalone discovery service, which you can use to dynamically distribute LBS connections to different LNS, ensuring failover of LBS to another LNS in case the current LNS is experiencing downtime. The discovery service is a .NET application, and its implementation is part of the LoRaWan.NetworkServerDiscovery project. The discovery service relies on configuration from IoT Hub module twins to associate each LBS with a set of LNS to which it may connect to. For this the configuration needs to take into account possible network boundaries - by defining these networks you can control which LBS should connect to which LNS. For this you need to configure your LBS twin in IoT Hub as follows: { ... , \"tags\" : { \"network\" : \"<network-id>\" }, ... } The network ID may only consist of alphanumeric characters. After you configured the LBS, you need to also configure your LNS with the same network. The LNS twin furthermore needs to contain the IP/DNS of the host, hence the twin of the LNS module should look like: Warning We will only query the LNS module twins for LNS within the same network. If you configure the network/host address on the Edge device twin, it will not be detected. { ... , \"tags\" : { \"network\" : \"<network-id>\" }, ... , \"properties\" : { \"desired\" : { \"hostAddress\" : \"wss://mylns:5001\" , ... } } } Keep in mind that the hostAddress value must include the scheme and the host name. In case you omit the port, the defaults of the protocol will be used. Note The discovery endpoint distributes LBS to LNS using a round-robin distribution mechanism. It will always try the same LNS per LBS first. Hence, it can be used for an active/passive scenario, but not to distribute load more evenly across different LNS. Note The configuration values of the network name of a station, respectively of the set of LNS in a given network, are cached by the discovery endpoint for 6 hours. If you updated the configuration and want it to take effect sooner, make sure to restart the discovery service to ensure that the cache is refreshed. You can choose to deploy the discovery service either on-prem or in the cloud. For both deployment strategies, you can configure the following behavior:","title":"LNS discovery"},{"location":"user-guide/lns-discovery/#configuration","text":"You can configure the following behavior of the LNS discovery service. Environment variable Description Deployment type Logging__LogLevel__Default Configures the default log level. For more fine-grained configuration of the console log level, refer to Logging in .NET Core and ASP.NET Core All APPLICATIONINSIGHTS_CONNECTION_STRING Useful for sending telemetry data to Application Insights All Logging__ApplicationInsights__LogLevel__<Default|..> Configures the Application Insights log levels All ASPNETCORE_URLS Configures on which URLs the service is listening. Multiple URLs should be separated by a ; All IotHubHostName Host name of the Iot Hub. Only used if you connect to IoT Hub using managed identities. App Service ConnectionStrings__IotHub Connection string to the Iot Hub. In case of App Service deployment, use managed identities instead. On-prem Kestrel__Certificates__Default__<Path|KeyPath|...> Configures the certificates that should be used by the discovery endpoint as described in the Minimal APIs overview . Instead of using the appsettings.json , you can use environment variables of the same structure, where a double underscore replaces a level of hierarchy. On-prem","title":"Configuration"},{"location":"user-guide/lns-discovery/#deployment-in-azure","text":"We recommend that you use an Azure App Service to run the discovery service in the cloud. You can follow the App Service Quickstart for instructions how to deploy an ASP.NET Core app in an Azure App Service. When using an App Service, make sure that you: Enable the system assigned managed identity Assign a role to the system assigned identity which allows it to execute the Microsoft.Devices/IotHubs/twins/read data action for reading the IoT Hub twins. Built-in IoT Hub Twin Contributor role allows that. Specify the Iot Hub host name as described in the configuration section.","title":"Deployment in Azure"},{"location":"user-guide/lns-discovery/#on-premises-deployment","text":"When deploying the discovery service on-premises, please read how to Host ASP.NET Core on Windows with IIS (or any other hosting strategy you may want to use). The discovery endpoint exposes metrics in Prometheus format. You must specify the IoT Hub connection string as described in the configuration section, since you cannot use managed identities with an on-premises deployment.","title":"On-premises deployment"},{"location":"user-guide/message-flows/","text":"Message Flows DefaultLoRaDataRequestHandler:ProcessRequestAsync flowchart TB ProcessRequestAsync-->ReqVal{IsValidRequest?} ReqVal-->|Yes|PerformADR ReqVal-->|No|Done PerformADR-->DedupDrop{MultiGW & Drop?} DedupDrop-->|Yes|Done DedupDrop-->|No|ReqConf{Requires confirmation?} ReqConf-->|No|HasValidFctUp{Has valid fcnt down?} ReqConf-->|Yes|HasFctDown HasFctDown-->|No|Done HasFctDown-->|Yes|HasValidFctUp{Has valid fcnt up?} HasValidFctUp-->decryptPayload[decrypt payload] decryptPayload-->IsMacAnswer{Is Mac answer?} IsMacAnswer-->|Yes|ValidFctDwn{Has valid fct down?} ValidFctDwn-->|No|Done ValidFctDwn-->|Yes|CheckSendDeviceEvt IsMacAnswer-->|No|DecodePayload DecodePayload-->C2DMsg{Has C2D msg?} C2DMsg-->|Yes|CheckSameDevice{Is for same device?} CheckSameDevice-->|Yes|ValidFctDwn2{Has valid fcnt down?} ValidFctDwn2-->|Yes|CheckSendDeviceEvt ValidFctDwn2-->|No|C2DAbandonAsync C2DAbandonAsync-->CheckSendDeviceEvt CheckSameDevice-->|No|SendC2DClassC SendC2DClassC-->CheckSendDeviceEvt C2DMsg-->|No|CheckSendDeviceEvt{Should send event upstream?} CheckSendDeviceEvt-->|Yes|SendDeviceEventAsync SendDeviceEventAsync-->ValidateTime{Still time for Rx Wnd?} CheckSendDeviceEvt-->|No|ValidateTime ValidateTime-->|No|Done ValidateTime-->|Yes|ConfirmDirect{Confirmation and no downlink or not enough time?} ConfirmDirect-->|Yes|SendDownlinkMsg ConfirmDirect-->|No|ifC2DFromDecoder{C2D msg from decoder?} ifC2DFromDecoder-->|Yes|SendDownlinkMsg ifC2DFromDecoder-->|No|fetchC2D fetchC2D-->RequiresConfirmation{Requires confirmation?} RequiresConfirmation-->|Yes|check2ndC2DTime{Enough time for 2nd C2D msg?} RequiresConfirmation-->|No|ValidFctDwn3{Has valid fcnt down?} ValidFctDwn3-->|Yes|check2ndC2DTime ValidFctDwn3-->|No|Done check2ndC2DTime-->|Yes|CheckAdditionalMessages CheckAdditionalMessages-->additionalC2DMsg{Has more messages?} additionalC2DMsg-->|Yes|setFpending[set fpending] additionalC2DMsg-->|No|SendDownlinkMsg setFpending-->SendDownlinkMsg check2ndC2DTime-->|No|SendDownlinkMsg SendDownlinkMsg-->Done(Done) Incoming message - device not cached sequenceDiagram autonumber MessageDispatcher->>LoRaDeviceRegistry: GetLoRaRequestQueue LoRaDeviceRegistry->>DeviceLoaderSynchronizer: ctor DeviceLoaderSynchronizer->>DeviceLoaderSynchronizer: Load LoRaDeviceRegistry->>MessageDispatcher: DeviceLoaderSynchronizer MessageDispatcher->>DeviceLoaderSynchronizer: Queue DeviceLoaderSynchronizer->>API: SearchByDevAddrAsync DeviceLoaderSynchronizer->>DeviceLoaderSynchronizer: CreateDevicesAsync loop For each Device DeviceLoaderSynchronizer->>LoRaDeviceFactory: Create LoRaDeviceFactory->>LoRaDeviceFactory: CreateDeviceClient DeviceLoaderSynchronizer->>LoRaDevice: InitializeAsync LoRaDevice->>LoRaDeviceClient: GetTwinAsync end DeviceLoaderSynchronizer->>DeviceLoaderSynchronizer: DispatchQueuedItems DeviceLoaderSynchronizer->>LoRaDevice: Queue LoRaDevice->>DefaultLoRaDataRequestHandler: ProcessRequestAsync The message dispatcher requests the ILoRaDeviceRequestQueue from the LoRaDeviceRegistry where the LoRaRequest can be sent to. The LoRaDeviceRegistry maintains an in memory cache per DevAddr and checks, if it has a cache and if it contains a valid device matching the NwkSKey . If it does not, the LoRaDeviceRegistry initializes a DeviceLoaderSynchronizer as ILoRaDeviceRequestQueue , and adds it to its cache under the prefix devloader . The DeviceLoaderSynchronizer ctor does trigger an async initialization Load of the devices matching the DevAddr is triggered The MessageDispatcher receives the DeviceLoaderSynchronizer The original LoRaRequest is put onto the queue where it will wait for the device to be loaded. The SearchByDevAddrAsync is calling the function and tries to get a list for that particular DevAddr . The result is a list of IoTHubDeviceInfo which contains everything required to connect the device to IoT Hub as well as the NwkSKey . The DeviceLoaderSynchronizer iterates over the result and asks for each of the result item to be materialized into a LoRaDevice . The LoRaDeviceFactory creates a LoRaDevice from the IoTHubDeviceInfo The LoRaDeviceFactory also maintains the connections per device to IoT Hub. It does that through the LoRaDeviceClientConnectionManager where LoRaDeviceClient are registered per DevEUI . Each device is initialized to get ready for processing messages The initialization is triggering the load of the twins through the LoRaDeviceClient Once the device is initialized, the messages for the device are dispatched The dispatch is putting them on the LoRaDevice Queue The LoRaDevice will process the messages in sequence to avoid contention on the device connection and delegate the processing to the ILoRaDataRequestHandler . Observations If the DevAddr does not match any of our registered devices, we keep the DeviceLoaderSynchronizer in cache for 30s (which is designed to ensure that pending requests that were already on the queue, can be processed), then it's evicted. Subsequent messages after those 30s with the same DevAddr will keep going back to the functions API. Given the fact that a device could be registered between messages, I don't see a way to avoid that except if we are willing to accept a longer period until we recognize a device. In that case we could register a 'drop' queue for the DevAddr that will be evicted after a longer time. Incoming message - device cached sequenceDiagram autonumber MessageDispatcher->>LoRaDeviceRegistry: GetLoRaRequestQueue alt in cache but not our device LoRaDeviceRegistry->>MessageDispatcher:ExternalGatewayLoRaRequestQueue:ctor else LoRaDeviceRegistry->>MessageDispatcher:cached LoRaDevice end MessageDispatcher->>LoRaDevice: Queue LoRaDevice->>DefaultLoRaDataRequestHandler: ProcessRequestAsync The message dispatcher requests the ILoRaDeviceRequestQueue from the LoRaDeviceRegistry If the device was in cache, but does not belong to our gateway, we return a ExternalGatewayLoRaRequestQueue . That queue is basically dropping any messages that are sent to it. If the device was found in the cache we return that to the MessageDispatcher . The request is put onto the LoRaDevice 's queue. The LoRaDevice will process the messages in sequence to avoid contention on the device connection and delegate the processing to the ILoRaDataRequestHandler . Join Request - OTAA sequenceDiagram autonumber MessageDispatcher->>JoinRequestMessageHandler: DispatchRequest JoinRequestMessageHandler->>JoinRequestMessageHandler: ProcessJoinRequestAsync JoinRequestMessageHandler->>LoRaOperationTimeWatcher: ctor JoinRequestMessageHandler->>LoRaDeviceRegistry: GetDeviceForJoinRequestAsync LoRaDeviceRegistry->>API: SearchAndLockForJoinAsync LoRaDeviceRegistry->>JoinDeviceLoader: ctor activate LoRaDevice par JoinDeviceLoader->>JoinDeviceLoader:LoadAsync JoinDeviceLoader->>ILoRaDeviceFactory: Create ILoRaDeviceFactory-->>JoinDeviceLoader: LoRaDevice JoinDeviceLoader->>LoRaDevice: InitializeAsync LoRaDevice->>ILoRaDeviceClient: GetTwinAsync and LoRaDeviceRegistry->>JoinDeviceLoader: WaitCompleteAsync end JoinDeviceLoader-->>LoRaDeviceRegistry: LoRaDevice LoRaDeviceRegistry-->>JoinRequestMessageHandler: LoRaDevice JoinRequestMessageHandler-->>JoinRequestMessageHandler: Validation JoinRequestMessageHandler->>OTAAKeysGenerator: CalculateKey JoinRequestMessageHandler->>LoRaOperationTimeWatcher: InTimeForJoinAccept JoinRequestMessageHandler->>LoRaDevice: UpdateAfterJoinAsync deactivate LoRaDevice The MessageDispatcher delegates the handling of the join request to the JoinRequestMessageHandler The JoinRequestMessageHandler is executing ProcessJoinRequestAsync and extracts: DevEUI, AppEUI and DevNonce from the join request. A LoRaOperationTimeWatcher is created to monitor the elapsed time for the join request. The LoRaDeviceRegistry is queried for the device matching the join request. The LoRaDeviceRegistry is asking the functions API to lookup the device using the DevEUI, AppEUI and the DevNonce. Also the Gateway Id is sent to allow locking the join request. see the GetDevice flow Q: why do we send the AppEUI ? It looks like that's not used for the OTAA join? LoRaDeviceRegistry creates a new JoinDeviceLoader (unless the loader is still in the cache - valid for 30min) passing in the IoTHubDeviceInfo . The ctor of the JoinDeviceLoader starts a thread executing LoadAsync A new LoRaDevice is created through the factory from the IoTHubDeviceInfo LoRaDevice is returned. The LoRaDevice is initialized. Twins are loaded through the ILoRaDeviceClient (keys were fetched from the API). JoinDeviceLoader is waiting for completion of the device load process The LoRaDevice is returned to the LoRaDeviceRegistry The LoRaDevice is returned to the JoinRequestMessageHandler Validation of the join request is performed (CheckMic, DevNonce, GatewayID) Keys are generated Validate that we can confirm the join to the device and are within Join_accept_delay2 for the current region. Writing DevAddr , NwkSKey , AppSKey , AppNonce , DevNonce , NetID , Region , PreferredGatewayID If we are still in time for a valid receive window, a JoinAccept will be sent to the device after calculating the DR and Frequency. Function GetDevice - OTAA sequenceDiagram autonumber LNS->>DeviceGetter:GetDevice DeviceGetter->>DeviceGetter:TryGetJoinInfoAndValidateAsync DeviceGetter->>Redis:GetObject - JoinInfo alt JoinInfo not in cache DeviceGetter->>RegistryManager: GetDeviceAsync DeviceGetter->>RegistryManager: GetTwinAsync DeviceGetter->>Redis: ObjectSet end alt if not our device DeviceGetter-->>LNS: JoinRefused end DeviceGetter->>Redis:StringSet Note over DeviceGetter,Redis: Only if it does not exist, valid: 5min alt if it did exist DeviceGetter-->>LNS: JoinRefused else DeviceGetter->>DeviceCache: TryToAcquireLock Note over DeviceGetter,DeviceCache: This tries to aquire a lock on the DevEUI alt if lock acquired DeviceGetter->>DeviceCache: KeyDelete Note over DeviceGetter,DeviceCache: Delete DevEUI key from Redis else DeviceGetter->>DeviceGetter: log warning end DeviceGetter->>LNS: IoTHubDeviceInfo end The LNS requests the device for a join request The DeviceGetter calls TryGetJoinInfoAndValidateAsync Try to get the JoinInfo (containing the primary key and the desired gateway id for the device) from Redis. If the device was not in the cache, we use the IoT Hub RegistryManager to fetch the Device If the device exists, we fetch the twins and get the Desired GatewayId. The JoinInfo is stored in Redis for 60min We validate that if there is a desired gateway, the gateway processing the join request, is the desired gateway. If not, a BadRequest is returned to the LNS indicating the join failure. We try to set the DevEUI:Nonce value in Redis cache to ensure, only 1 Gateway is processing the join request If we did not win the race, the Gateway receives a BadRequest response If we were successful we create a IoTHubDeviceInfo and try to acquire a lock on the DevEUI If we did get the lock, we delete the DevEUI key. If not, we print out a warning We return the IoTHubDeviceInfo","title":"Message Flows"},{"location":"user-guide/message-flows/#message-flows","text":"","title":"Message Flows"},{"location":"user-guide/message-flows/#defaultloradatarequesthandlerprocessrequestasync","text":"flowchart TB ProcessRequestAsync-->ReqVal{IsValidRequest?} ReqVal-->|Yes|PerformADR ReqVal-->|No|Done PerformADR-->DedupDrop{MultiGW & Drop?} DedupDrop-->|Yes|Done DedupDrop-->|No|ReqConf{Requires confirmation?} ReqConf-->|No|HasValidFctUp{Has valid fcnt down?} ReqConf-->|Yes|HasFctDown HasFctDown-->|No|Done HasFctDown-->|Yes|HasValidFctUp{Has valid fcnt up?} HasValidFctUp-->decryptPayload[decrypt payload] decryptPayload-->IsMacAnswer{Is Mac answer?} IsMacAnswer-->|Yes|ValidFctDwn{Has valid fct down?} ValidFctDwn-->|No|Done ValidFctDwn-->|Yes|CheckSendDeviceEvt IsMacAnswer-->|No|DecodePayload DecodePayload-->C2DMsg{Has C2D msg?} C2DMsg-->|Yes|CheckSameDevice{Is for same device?} CheckSameDevice-->|Yes|ValidFctDwn2{Has valid fcnt down?} ValidFctDwn2-->|Yes|CheckSendDeviceEvt ValidFctDwn2-->|No|C2DAbandonAsync C2DAbandonAsync-->CheckSendDeviceEvt CheckSameDevice-->|No|SendC2DClassC SendC2DClassC-->CheckSendDeviceEvt C2DMsg-->|No|CheckSendDeviceEvt{Should send event upstream?} CheckSendDeviceEvt-->|Yes|SendDeviceEventAsync SendDeviceEventAsync-->ValidateTime{Still time for Rx Wnd?} CheckSendDeviceEvt-->|No|ValidateTime ValidateTime-->|No|Done ValidateTime-->|Yes|ConfirmDirect{Confirmation and no downlink or not enough time?} ConfirmDirect-->|Yes|SendDownlinkMsg ConfirmDirect-->|No|ifC2DFromDecoder{C2D msg from decoder?} ifC2DFromDecoder-->|Yes|SendDownlinkMsg ifC2DFromDecoder-->|No|fetchC2D fetchC2D-->RequiresConfirmation{Requires confirmation?} RequiresConfirmation-->|Yes|check2ndC2DTime{Enough time for 2nd C2D msg?} RequiresConfirmation-->|No|ValidFctDwn3{Has valid fcnt down?} ValidFctDwn3-->|Yes|check2ndC2DTime ValidFctDwn3-->|No|Done check2ndC2DTime-->|Yes|CheckAdditionalMessages CheckAdditionalMessages-->additionalC2DMsg{Has more messages?} additionalC2DMsg-->|Yes|setFpending[set fpending] additionalC2DMsg-->|No|SendDownlinkMsg setFpending-->SendDownlinkMsg check2ndC2DTime-->|No|SendDownlinkMsg SendDownlinkMsg-->Done(Done)","title":"DefaultLoRaDataRequestHandler:ProcessRequestAsync"},{"location":"user-guide/message-flows/#incoming-message-device-not-cached","text":"sequenceDiagram autonumber MessageDispatcher->>LoRaDeviceRegistry: GetLoRaRequestQueue LoRaDeviceRegistry->>DeviceLoaderSynchronizer: ctor DeviceLoaderSynchronizer->>DeviceLoaderSynchronizer: Load LoRaDeviceRegistry->>MessageDispatcher: DeviceLoaderSynchronizer MessageDispatcher->>DeviceLoaderSynchronizer: Queue DeviceLoaderSynchronizer->>API: SearchByDevAddrAsync DeviceLoaderSynchronizer->>DeviceLoaderSynchronizer: CreateDevicesAsync loop For each Device DeviceLoaderSynchronizer->>LoRaDeviceFactory: Create LoRaDeviceFactory->>LoRaDeviceFactory: CreateDeviceClient DeviceLoaderSynchronizer->>LoRaDevice: InitializeAsync LoRaDevice->>LoRaDeviceClient: GetTwinAsync end DeviceLoaderSynchronizer->>DeviceLoaderSynchronizer: DispatchQueuedItems DeviceLoaderSynchronizer->>LoRaDevice: Queue LoRaDevice->>DefaultLoRaDataRequestHandler: ProcessRequestAsync The message dispatcher requests the ILoRaDeviceRequestQueue from the LoRaDeviceRegistry where the LoRaRequest can be sent to. The LoRaDeviceRegistry maintains an in memory cache per DevAddr and checks, if it has a cache and if it contains a valid device matching the NwkSKey . If it does not, the LoRaDeviceRegistry initializes a DeviceLoaderSynchronizer as ILoRaDeviceRequestQueue , and adds it to its cache under the prefix devloader . The DeviceLoaderSynchronizer ctor does trigger an async initialization Load of the devices matching the DevAddr is triggered The MessageDispatcher receives the DeviceLoaderSynchronizer The original LoRaRequest is put onto the queue where it will wait for the device to be loaded. The SearchByDevAddrAsync is calling the function and tries to get a list for that particular DevAddr . The result is a list of IoTHubDeviceInfo which contains everything required to connect the device to IoT Hub as well as the NwkSKey . The DeviceLoaderSynchronizer iterates over the result and asks for each of the result item to be materialized into a LoRaDevice . The LoRaDeviceFactory creates a LoRaDevice from the IoTHubDeviceInfo The LoRaDeviceFactory also maintains the connections per device to IoT Hub. It does that through the LoRaDeviceClientConnectionManager where LoRaDeviceClient are registered per DevEUI . Each device is initialized to get ready for processing messages The initialization is triggering the load of the twins through the LoRaDeviceClient Once the device is initialized, the messages for the device are dispatched The dispatch is putting them on the LoRaDevice Queue The LoRaDevice will process the messages in sequence to avoid contention on the device connection and delegate the processing to the ILoRaDataRequestHandler .","title":"Incoming message - device not cached"},{"location":"user-guide/message-flows/#observations","text":"If the DevAddr does not match any of our registered devices, we keep the DeviceLoaderSynchronizer in cache for 30s (which is designed to ensure that pending requests that were already on the queue, can be processed), then it's evicted. Subsequent messages after those 30s with the same DevAddr will keep going back to the functions API. Given the fact that a device could be registered between messages, I don't see a way to avoid that except if we are willing to accept a longer period until we recognize a device. In that case we could register a 'drop' queue for the DevAddr that will be evicted after a longer time.","title":"Observations"},{"location":"user-guide/message-flows/#incoming-message-device-cached","text":"sequenceDiagram autonumber MessageDispatcher->>LoRaDeviceRegistry: GetLoRaRequestQueue alt in cache but not our device LoRaDeviceRegistry->>MessageDispatcher:ExternalGatewayLoRaRequestQueue:ctor else LoRaDeviceRegistry->>MessageDispatcher:cached LoRaDevice end MessageDispatcher->>LoRaDevice: Queue LoRaDevice->>DefaultLoRaDataRequestHandler: ProcessRequestAsync The message dispatcher requests the ILoRaDeviceRequestQueue from the LoRaDeviceRegistry If the device was in cache, but does not belong to our gateway, we return a ExternalGatewayLoRaRequestQueue . That queue is basically dropping any messages that are sent to it. If the device was found in the cache we return that to the MessageDispatcher . The request is put onto the LoRaDevice 's queue. The LoRaDevice will process the messages in sequence to avoid contention on the device connection and delegate the processing to the ILoRaDataRequestHandler .","title":"Incoming message - device cached"},{"location":"user-guide/message-flows/#join-request-otaa","text":"sequenceDiagram autonumber MessageDispatcher->>JoinRequestMessageHandler: DispatchRequest JoinRequestMessageHandler->>JoinRequestMessageHandler: ProcessJoinRequestAsync JoinRequestMessageHandler->>LoRaOperationTimeWatcher: ctor JoinRequestMessageHandler->>LoRaDeviceRegistry: GetDeviceForJoinRequestAsync LoRaDeviceRegistry->>API: SearchAndLockForJoinAsync LoRaDeviceRegistry->>JoinDeviceLoader: ctor activate LoRaDevice par JoinDeviceLoader->>JoinDeviceLoader:LoadAsync JoinDeviceLoader->>ILoRaDeviceFactory: Create ILoRaDeviceFactory-->>JoinDeviceLoader: LoRaDevice JoinDeviceLoader->>LoRaDevice: InitializeAsync LoRaDevice->>ILoRaDeviceClient: GetTwinAsync and LoRaDeviceRegistry->>JoinDeviceLoader: WaitCompleteAsync end JoinDeviceLoader-->>LoRaDeviceRegistry: LoRaDevice LoRaDeviceRegistry-->>JoinRequestMessageHandler: LoRaDevice JoinRequestMessageHandler-->>JoinRequestMessageHandler: Validation JoinRequestMessageHandler->>OTAAKeysGenerator: CalculateKey JoinRequestMessageHandler->>LoRaOperationTimeWatcher: InTimeForJoinAccept JoinRequestMessageHandler->>LoRaDevice: UpdateAfterJoinAsync deactivate LoRaDevice The MessageDispatcher delegates the handling of the join request to the JoinRequestMessageHandler The JoinRequestMessageHandler is executing ProcessJoinRequestAsync and extracts: DevEUI, AppEUI and DevNonce from the join request. A LoRaOperationTimeWatcher is created to monitor the elapsed time for the join request. The LoRaDeviceRegistry is queried for the device matching the join request. The LoRaDeviceRegistry is asking the functions API to lookup the device using the DevEUI, AppEUI and the DevNonce. Also the Gateway Id is sent to allow locking the join request. see the GetDevice flow Q: why do we send the AppEUI ? It looks like that's not used for the OTAA join? LoRaDeviceRegistry creates a new JoinDeviceLoader (unless the loader is still in the cache - valid for 30min) passing in the IoTHubDeviceInfo . The ctor of the JoinDeviceLoader starts a thread executing LoadAsync A new LoRaDevice is created through the factory from the IoTHubDeviceInfo LoRaDevice is returned. The LoRaDevice is initialized. Twins are loaded through the ILoRaDeviceClient (keys were fetched from the API). JoinDeviceLoader is waiting for completion of the device load process The LoRaDevice is returned to the LoRaDeviceRegistry The LoRaDevice is returned to the JoinRequestMessageHandler Validation of the join request is performed (CheckMic, DevNonce, GatewayID) Keys are generated Validate that we can confirm the join to the device and are within Join_accept_delay2 for the current region. Writing DevAddr , NwkSKey , AppSKey , AppNonce , DevNonce , NetID , Region , PreferredGatewayID If we are still in time for a valid receive window, a JoinAccept will be sent to the device after calculating the DR and Frequency.","title":"Join Request - OTAA"},{"location":"user-guide/message-flows/#function-getdevice-otaa","text":"sequenceDiagram autonumber LNS->>DeviceGetter:GetDevice DeviceGetter->>DeviceGetter:TryGetJoinInfoAndValidateAsync DeviceGetter->>Redis:GetObject - JoinInfo alt JoinInfo not in cache DeviceGetter->>RegistryManager: GetDeviceAsync DeviceGetter->>RegistryManager: GetTwinAsync DeviceGetter->>Redis: ObjectSet end alt if not our device DeviceGetter-->>LNS: JoinRefused end DeviceGetter->>Redis:StringSet Note over DeviceGetter,Redis: Only if it does not exist, valid: 5min alt if it did exist DeviceGetter-->>LNS: JoinRefused else DeviceGetter->>DeviceCache: TryToAcquireLock Note over DeviceGetter,DeviceCache: This tries to aquire a lock on the DevEUI alt if lock acquired DeviceGetter->>DeviceCache: KeyDelete Note over DeviceGetter,DeviceCache: Delete DevEUI key from Redis else DeviceGetter->>DeviceGetter: log warning end DeviceGetter->>LNS: IoTHubDeviceInfo end The LNS requests the device for a join request The DeviceGetter calls TryGetJoinInfoAndValidateAsync Try to get the JoinInfo (containing the primary key and the desired gateway id for the device) from Redis. If the device was not in the cache, we use the IoT Hub RegistryManager to fetch the Device If the device exists, we fetch the twins and get the Desired GatewayId. The JoinInfo is stored in Redis for 60min We validate that if there is a desired gateway, the gateway processing the join request, is the desired gateway. If not, a BadRequest is returned to the LNS indicating the join failure. We try to set the DevEUI:Nonce value in Redis cache to ensure, only 1 Gateway is processing the join request If we did not win the race, the Gateway receives a BadRequest response If we were successful we create a IoTHubDeviceInfo and try to acquire a lock on the DevEUI If we did get the lock, we delete the DevEUI key. If not, we print out a warning We return the IoTHubDeviceInfo","title":"Function GetDevice - OTAA"},{"location":"user-guide/observability/","text":"Observability We recommend that you use Azure Monitor for observability when working with the starter kit. To observe the system, we make use of metrics and logs, but we do not support distributed tracing for the starter kit. However, you will get some limited tracing functionality between the Network Server and its dependencies, but only if you decide to use Azure Monitor. Even if you decide to not use Azure Monitor, you can always access metrics in Prometheus format on the Network Server at the path /metrics , similarly to how you can access built-in metrics on IoT Edge. The Network Server will always expose logs via the standard output and standard error. Integrating with Azure Monitor If you decide to use Azure Monitor, you will need to create an Application Insights instance and a Log Analytics workspace in your Azure subscription. Follow the steps in the Dev Guide to learn how to deploy the engine components. To enable observability using Azure Monitor, ensure that the following settings in your .env file (also described in the Dev Guide) are used for the IoT Edge deployment: APPLICATIONINSIGHTS_CONNECTION_STRING={application_insights_connection_string} IOT_HUB_RESOURCE_ID=/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.Devices/IotHubs/{iot_hub_name} LOG_ANALYTICS_WORKSPACE_ID={log_analytics_workspace_id} LOG_ANALYTICS_SHARED_KEY={log_analytics_shared_key} Generate a deployment manifest from deployment_observability.layered.template.json and deploy it to the edge devices for which you want to apply the observability. The template will set up the metrics collector module on the edge and connect it with your Log Analytics instance. The gateway will connect directly to your Application Insights instance, if you make sure to set the APPLICATIONINSIGHTS_CONNECTION_STRING before deploying the deployment.template.lbs.json solution. The Application Insights log level will always be the same as the console log level. Integrating with the Elastic stack In this section we describe an example setup that may help you to get started if you decide to use the Elastic stack for the engine observability. We will assume that you have set up the Elastic stack already, and that you now want to integrate the engine components with ELK. If you do not have the Elastic stack set up yet, refer to Elastic's documentation and set it up before you continue with this example. To integrate the starter kit into your ELK stack, we rely on Metricbeat to scrape metrics from the Prometheus endpoints of the IoT Edge modules (Network Server, Edge Hub and Edge Agent). Since Metricbeat requires access to the metric endpoints on IoT Edge, we will deploy it as an IoT Edge module, too. Warning To run Metricbeat on Docker you will need to make sure that you run IoT Edge on a supported OS/Architecture. At the time of writing, the Metricbeat Docker image does not work on ARM. To ensure that the Metricbeat is aware of all metrics endpoints that it needs to scrape and the ELK backend for the export, we need to first configure it correctly. Typically, to configure Metricbeat on Docker , we rely on a configuration file, which we will call metricbeat.yml in the following. Before we discuss how to make this file available inside the Docker container, we discuss how we need to change metricbeat.yml to support IoT Edge metrics collection. We rely on the Prometheus module to ship metrics from the Prometheus endpoints on the IoT Edge to the ELK stack. Make sure that you add the Prometheus module configuration to your metricbeat.yml . A basic configuration snippet might look like this: ... metricbeat.modules : - module : prometheus period : 10s metricsets : [ \"collector\" ] hosts : [ \"LoRaWanNetworkSrvModule:5000\" , \"edgeHub:9600\" , \"edgeAgent:9600\" ] metrics_path : /metrics ... Note If you configure the Network Server to use HTTPS, it will listen on port 5001 instead of 5000. If you use self-signed certificates for this, make sure that you configure the Prometheus module with your chain of trust. Next, we need to make sure that the metricbeat.yml is available to the Metricbeat Docker container. You can either link module storage to device storage in IoT Edge to achieve this, in which case you have to take care of making metricbeat.yml available on the IoT Edge host system. Alternatively, you can deploy a custom image, containing a metricbeat.yml template , and then use environment variables in the configuration to set values that need to be configurable between deployments. Independent of which approach you choose, you should amend your IoT Edge deployment template with something similar to: { \"modulesContent\" : { \"$edgeAgent\" : { \"properties.desired\" : { \"schemaVersion\" : \"1.0\" , ... , \"modules\" : { ... , \"metricbeat\" : { \"settings\" : { \"image\" : \"{IMAGE_PATH}\" , \"createOptions\" : \"{\\\"User\\\":\\\"root\\\",\\\"HostConfig\\\":{\\\"Privileged\\\":true},\\\"Binds\\\":[\\\"/var/run/docker.sock:/var/run/docker.sock:ro\\\",\\\"sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\\\",...]}\" }, \"env\" : { \"foo\" : { \"value\" : \"bar\" } }, \"type\" : \"docker\" , \"version\" : \"1.0\" , \"imagePullPolicy\" : \"on-create\" , \"status\" : \"running\" , \"restartPolicy\" : \"always\" } } } }, ... } } You can use environment variables, such as the foo=bar environment variable example, to replace environment variable references in your metricbeat.yml . To ship logs to ELK, you can follow the same strategy using Filebeat instead of Metricbeat.","title":"Observability"},{"location":"user-guide/observability/#observability","text":"We recommend that you use Azure Monitor for observability when working with the starter kit. To observe the system, we make use of metrics and logs, but we do not support distributed tracing for the starter kit. However, you will get some limited tracing functionality between the Network Server and its dependencies, but only if you decide to use Azure Monitor. Even if you decide to not use Azure Monitor, you can always access metrics in Prometheus format on the Network Server at the path /metrics , similarly to how you can access built-in metrics on IoT Edge. The Network Server will always expose logs via the standard output and standard error.","title":"Observability"},{"location":"user-guide/observability/#integrating-with-azure-monitor","text":"If you decide to use Azure Monitor, you will need to create an Application Insights instance and a Log Analytics workspace in your Azure subscription. Follow the steps in the Dev Guide to learn how to deploy the engine components. To enable observability using Azure Monitor, ensure that the following settings in your .env file (also described in the Dev Guide) are used for the IoT Edge deployment: APPLICATIONINSIGHTS_CONNECTION_STRING={application_insights_connection_string} IOT_HUB_RESOURCE_ID=/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.Devices/IotHubs/{iot_hub_name} LOG_ANALYTICS_WORKSPACE_ID={log_analytics_workspace_id} LOG_ANALYTICS_SHARED_KEY={log_analytics_shared_key} Generate a deployment manifest from deployment_observability.layered.template.json and deploy it to the edge devices for which you want to apply the observability. The template will set up the metrics collector module on the edge and connect it with your Log Analytics instance. The gateway will connect directly to your Application Insights instance, if you make sure to set the APPLICATIONINSIGHTS_CONNECTION_STRING before deploying the deployment.template.lbs.json solution. The Application Insights log level will always be the same as the console log level.","title":"Integrating with Azure Monitor"},{"location":"user-guide/observability/#integrating-with-the-elastic-stack","text":"In this section we describe an example setup that may help you to get started if you decide to use the Elastic stack for the engine observability. We will assume that you have set up the Elastic stack already, and that you now want to integrate the engine components with ELK. If you do not have the Elastic stack set up yet, refer to Elastic's documentation and set it up before you continue with this example. To integrate the starter kit into your ELK stack, we rely on Metricbeat to scrape metrics from the Prometheus endpoints of the IoT Edge modules (Network Server, Edge Hub and Edge Agent). Since Metricbeat requires access to the metric endpoints on IoT Edge, we will deploy it as an IoT Edge module, too. Warning To run Metricbeat on Docker you will need to make sure that you run IoT Edge on a supported OS/Architecture. At the time of writing, the Metricbeat Docker image does not work on ARM. To ensure that the Metricbeat is aware of all metrics endpoints that it needs to scrape and the ELK backend for the export, we need to first configure it correctly. Typically, to configure Metricbeat on Docker , we rely on a configuration file, which we will call metricbeat.yml in the following. Before we discuss how to make this file available inside the Docker container, we discuss how we need to change metricbeat.yml to support IoT Edge metrics collection. We rely on the Prometheus module to ship metrics from the Prometheus endpoints on the IoT Edge to the ELK stack. Make sure that you add the Prometheus module configuration to your metricbeat.yml . A basic configuration snippet might look like this: ... metricbeat.modules : - module : prometheus period : 10s metricsets : [ \"collector\" ] hosts : [ \"LoRaWanNetworkSrvModule:5000\" , \"edgeHub:9600\" , \"edgeAgent:9600\" ] metrics_path : /metrics ... Note If you configure the Network Server to use HTTPS, it will listen on port 5001 instead of 5000. If you use self-signed certificates for this, make sure that you configure the Prometheus module with your chain of trust. Next, we need to make sure that the metricbeat.yml is available to the Metricbeat Docker container. You can either link module storage to device storage in IoT Edge to achieve this, in which case you have to take care of making metricbeat.yml available on the IoT Edge host system. Alternatively, you can deploy a custom image, containing a metricbeat.yml template , and then use environment variables in the configuration to set values that need to be configurable between deployments. Independent of which approach you choose, you should amend your IoT Edge deployment template with something similar to: { \"modulesContent\" : { \"$edgeAgent\" : { \"properties.desired\" : { \"schemaVersion\" : \"1.0\" , ... , \"modules\" : { ... , \"metricbeat\" : { \"settings\" : { \"image\" : \"{IMAGE_PATH}\" , \"createOptions\" : \"{\\\"User\\\":\\\"root\\\",\\\"HostConfig\\\":{\\\"Privileged\\\":true},\\\"Binds\\\":[\\\"/var/run/docker.sock:/var/run/docker.sock:ro\\\",\\\"sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\\\",...]}\" }, \"env\" : { \"foo\" : { \"value\" : \"bar\" } }, \"type\" : \"docker\" , \"version\" : \"1.0\" , \"imagePullPolicy\" : \"on-create\" , \"status\" : \"running\" , \"restartPolicy\" : \"always\" } } } }, ... } } You can use environment variables, such as the foo=bar environment variable example, to replace environment variable references in your metricbeat.yml . To ship logs to ELK, you can follow the same strategy using Filebeat instead of Metricbeat.","title":"Integrating with the Elastic stack"},{"location":"user-guide/partner/","text":"Device Manufacturer Guidance We have developed the LoRaWAN starter kit agnostic of any device manufacturer implementation and focused on the specifics of underlying architectures (arm, x86). However, we understand that device manufacturers can have specific requirements to ensure the LoRa packets are processed and decoded correctly. In this section, we provide guidance for the following: Gateway Manufacturers : Allow a gateway to be compatible with our kit. Gateway manufacturers will test / make our Edge Hub modules work on their gateway. LoRa Sensor Manufacturers : These manufacturers will develop a custom decoder using our decoding framework for their sensors. Please choose from a section that relates to your requirements. Device Gateway Manufacturer Guidance The LoRaWAN starter kit currently is tested on many popular gateways, we run some of those as part of daily CI/CD pipeline to test integrity and performance of our codebase. Ideally any Basics Station compatible gateway should be compatible, however, we cannot test each and every gateway out there and hence we have created a process for device manufacturer to support their gateways and get them highlighted in this repo. Instructions If you would like to test gateway compatibility with out starter kit and also get it highlighted on our GitHub page. To test gateway compatibility, please follow these steps: Go through the Developer Guidance to clone the repo and make sure everything works in your local dev environment. Make sure everything works with an Azure subscription with Standard Pricing SKU's, for example we do not support the Free Azure IoT Hub SKU. Ensure that the gateway specification meet the minimal hardware configuration required for Azure IoT Edge and a container framework like Docker, Moby to run. We recommend at the minimum of 1 GB RAM, rPi based boards and similar configuration devices will be a good candidate for our starter kit. If the gateway requires a specific LoRa Basics\u2122 Station not provided by our kit (we leverage an implementation of the LoRa Basics\u2122 Station), create the appropriate code for building the LoRa Basics\u2122 Station binary. Run the tests on the Gateway (must be a real device) to connect to a LoRa end node and receive and send packets. Once you have tested the framework and have all things running, open an issue on the repo and we will invite you to add a page for your gateway on our repo. The page can include details about your gateway and any specific instructions to make your gateway running with LoRaWAN starter kit. This approach provides us with validation that things work on the gateway and also allows others using the same Gateway to leverage the learnings. Device Node (sensor) Manufacturer Guidance If you are a LoRa Node/Sensor manufacturer that leverages specific decoding scheme for the LoRa packets, we have provision for you to run those devices using our decoding framework. Instructions Follow these steps to onboard your device with a custom decoder: Go through the Developer Guidance to clone the repo and make sure everything works in your local dev environment. Make sure everything works with an Azure subscription with Standard Pricing SKU's, for example we do not support the Free Azure IoT Hub SKU. We have provided a sample reference implementation of a decoder, please refer to this as a template and leverage the instructions to create implementation of your customer decoder. The Sample code can also contain device model specific tests that when run allows for testing of the gateway. Since we are .NET and C# based, the sample is based on the .NET technology stack, however you can create your decoders in your preferred languages by implementing similar interfaces. If you have a specific language or platform to be supported, submit an issue to let us know.","title":"Device Manufacturer Guidance"},{"location":"user-guide/partner/#device-manufacturer-guidance","text":"We have developed the LoRaWAN starter kit agnostic of any device manufacturer implementation and focused on the specifics of underlying architectures (arm, x86). However, we understand that device manufacturers can have specific requirements to ensure the LoRa packets are processed and decoded correctly. In this section, we provide guidance for the following: Gateway Manufacturers : Allow a gateway to be compatible with our kit. Gateway manufacturers will test / make our Edge Hub modules work on their gateway. LoRa Sensor Manufacturers : These manufacturers will develop a custom decoder using our decoding framework for their sensors. Please choose from a section that relates to your requirements.","title":"Device Manufacturer Guidance"},{"location":"user-guide/partner/#device-gateway-manufacturer-guidance","text":"The LoRaWAN starter kit currently is tested on many popular gateways, we run some of those as part of daily CI/CD pipeline to test integrity and performance of our codebase. Ideally any Basics Station compatible gateway should be compatible, however, we cannot test each and every gateway out there and hence we have created a process for device manufacturer to support their gateways and get them highlighted in this repo.","title":"Device Gateway Manufacturer Guidance"},{"location":"user-guide/partner/#instructions","text":"If you would like to test gateway compatibility with out starter kit and also get it highlighted on our GitHub page. To test gateway compatibility, please follow these steps: Go through the Developer Guidance to clone the repo and make sure everything works in your local dev environment. Make sure everything works with an Azure subscription with Standard Pricing SKU's, for example we do not support the Free Azure IoT Hub SKU. Ensure that the gateway specification meet the minimal hardware configuration required for Azure IoT Edge and a container framework like Docker, Moby to run. We recommend at the minimum of 1 GB RAM, rPi based boards and similar configuration devices will be a good candidate for our starter kit. If the gateway requires a specific LoRa Basics\u2122 Station not provided by our kit (we leverage an implementation of the LoRa Basics\u2122 Station), create the appropriate code for building the LoRa Basics\u2122 Station binary. Run the tests on the Gateway (must be a real device) to connect to a LoRa end node and receive and send packets. Once you have tested the framework and have all things running, open an issue on the repo and we will invite you to add a page for your gateway on our repo. The page can include details about your gateway and any specific instructions to make your gateway running with LoRaWAN starter kit. This approach provides us with validation that things work on the gateway and also allows others using the same Gateway to leverage the learnings.","title":"Instructions"},{"location":"user-guide/partner/#device-node-sensor-manufacturer-guidance","text":"If you are a LoRa Node/Sensor manufacturer that leverages specific decoding scheme for the LoRa packets, we have provision for you to run those devices using our decoding framework.","title":"Device Node (sensor) Manufacturer Guidance"},{"location":"user-guide/partner/#instructions_1","text":"Follow these steps to onboard your device with a custom decoder: Go through the Developer Guidance to clone the repo and make sure everything works in your local dev environment. Make sure everything works with an Azure subscription with Standard Pricing SKU's, for example we do not support the Free Azure IoT Hub SKU. We have provided a sample reference implementation of a decoder, please refer to this as a template and leverage the instructions to create implementation of your customer decoder. The Sample code can also contain device model specific tests that when run allows for testing of the gateway. Since we are .NET and C# based, the sample is based on the .NET technology stack, however you can create your decoders in your preferred languages by implementing similar interfaces. If you have a specific language or platform to be supported, submit an issue to let us know.","title":"Instructions"},{"location":"user-guide/pkt-fwd-to-station/","text":"Migrate from Packet Forwarder to LoRa Basics Station Before upgrading to v2.0.0, please take some time to review this document on how to migrate from Packet Forwarder to LoRa Basics Station. 1. Creation of a concentrator device Azure IoT Edge LoRaWAN Starter Kit v2.0.0 support the ability to de-couple the \"concentrator\" devices from the LoRaWan Network Server, ideally allowing the same LNS to handle concentrators with different antenna configuration or from completely different regions. Because of this, any specific configuration of the concentrator is now pushed from a new IoT Hub Device representing the \"concentrator\" device. Due to the decoupling, more secure authentication modes are also supported for the connection between the concentrator and the LNS. The concept of provisioning a IoT Hub Device representing the concentrator is explained in the concentrator provisioning documentation page. The supported authentication modes are explained in the authentication modes documentation page. 2. Connection of the concentrator to the LoRaWan Network Server After the creation of the concentrator device twin in IoT Hub, it will be possible to connect it to the LoRaWan Network Server. Pre-built docker module migration In case you were using the pre-built Packet Forwarder module , have a look at the following table for migrating the environment variables to the new Basic Station module configuration ones: Packet Forwarder variable name Basics Station variable name Comment REGION N/A No region variable is needed in Basics Station as the antenna configuration is pushed from IoT Hub Device Twin via LNS Protocol Implementation NETWORK_SERVER CUPS_URI and TC_URI The Network Server address is now mapped to the CUPS_URI and/or TC_URI fields. More info in Basic Station module configuration RESET_PIN RESET_PIN Name and functionality are not changing SPI_DEV SPI_DEV Name is not changing. In Basics Station module, it is a number identifying the SPI location where the board should be accessed (i.e.: when X, board accessed at /dev/spidevX.0) Field defaults to 0 SPI_SPEED SPI_SPEED Name and functionality are not changing. In Basics Station module, default to 8, unique alternative provided is 2 Previously, the Packet Forwarder module was built only for SX1301 based devices using SPI communication. Current LoRaBasicsStationModule is built for both SX1301 and SX1302 based devices (starting from v2.1.0). A more comprehensive list of allowed variables can be found in the Basic Station module configuration page. Custom built docker module In case you are not using the pre-built Packet Forwarder module, because of hardware incompatibilities, you can try build your own docker module by starting from the official Basics Station source code . If you own a USB-FTDI mPCIe RAK833 board, an unofficial and not supported fork of the Basics Station can be found here Industrial device In case you are using an industrial device, please make sure that it supports the Basics Station protocols. The vast majority of recent industrial devices should support the connection to the CUPS/LNS Protocols. Depending on the desired authentication mode, setting up an industrial device might be as easy as just pointing to the proper websocket endpoint exposed by the LoRaWan Network Server. If you think there is an issue with our codebase, feel free to open an issue in the GitHub repository","title":"Migrate from Packet Forwarder to LoRa Basics Station"},{"location":"user-guide/pkt-fwd-to-station/#migrate-from-packet-forwarder-to-lora-basics-station","text":"Before upgrading to v2.0.0, please take some time to review this document on how to migrate from Packet Forwarder to LoRa Basics Station.","title":"Migrate from Packet Forwarder to LoRa Basics Station"},{"location":"user-guide/pkt-fwd-to-station/#1-creation-of-a-concentrator-device","text":"Azure IoT Edge LoRaWAN Starter Kit v2.0.0 support the ability to de-couple the \"concentrator\" devices from the LoRaWan Network Server, ideally allowing the same LNS to handle concentrators with different antenna configuration or from completely different regions. Because of this, any specific configuration of the concentrator is now pushed from a new IoT Hub Device representing the \"concentrator\" device. Due to the decoupling, more secure authentication modes are also supported for the connection between the concentrator and the LNS. The concept of provisioning a IoT Hub Device representing the concentrator is explained in the concentrator provisioning documentation page. The supported authentication modes are explained in the authentication modes documentation page.","title":"1. Creation of a concentrator device"},{"location":"user-guide/pkt-fwd-to-station/#2-connection-of-the-concentrator-to-the-lorawan-network-server","text":"After the creation of the concentrator device twin in IoT Hub, it will be possible to connect it to the LoRaWan Network Server.","title":"2. Connection of the concentrator to the LoRaWan Network Server"},{"location":"user-guide/pkt-fwd-to-station/#pre-built-docker-module-migration","text":"In case you were using the pre-built Packet Forwarder module , have a look at the following table for migrating the environment variables to the new Basic Station module configuration ones: Packet Forwarder variable name Basics Station variable name Comment REGION N/A No region variable is needed in Basics Station as the antenna configuration is pushed from IoT Hub Device Twin via LNS Protocol Implementation NETWORK_SERVER CUPS_URI and TC_URI The Network Server address is now mapped to the CUPS_URI and/or TC_URI fields. More info in Basic Station module configuration RESET_PIN RESET_PIN Name and functionality are not changing SPI_DEV SPI_DEV Name is not changing. In Basics Station module, it is a number identifying the SPI location where the board should be accessed (i.e.: when X, board accessed at /dev/spidevX.0) Field defaults to 0 SPI_SPEED SPI_SPEED Name and functionality are not changing. In Basics Station module, default to 8, unique alternative provided is 2 Previously, the Packet Forwarder module was built only for SX1301 based devices using SPI communication. Current LoRaBasicsStationModule is built for both SX1301 and SX1302 based devices (starting from v2.1.0). A more comprehensive list of allowed variables can be found in the Basic Station module configuration page.","title":"Pre-built docker module migration"},{"location":"user-guide/pkt-fwd-to-station/#custom-built-docker-module","text":"In case you are not using the pre-built Packet Forwarder module, because of hardware incompatibilities, you can try build your own docker module by starting from the official Basics Station source code . If you own a USB-FTDI mPCIe RAK833 board, an unofficial and not supported fork of the Basics Station can be found here","title":"Custom built docker module"},{"location":"user-guide/pkt-fwd-to-station/#industrial-device","text":"In case you are using an industrial device, please make sure that it supports the Basics Station protocols. The vast majority of recent industrial devices should support the connection to the CUPS/LNS Protocols. Depending on the desired authentication mode, setting up an industrial device might be as easy as just pointing to the proper websocket endpoint exposed by the LoRaWan Network Server. If you think there is an issue with our codebase, feel free to open an issue in the GitHub repository","title":"Industrial device"},{"location":"user-guide/scalability/","text":"Scalability Different deployment scenarios have impact on the scalability of your LNS (LoRaWAN Network Server). Connection ownership The LNS is running as a module on IoT edge and processes messages from potentially multiple LBS (LoRa Basics Stations). Due to the broadcasting of messages, the same message from the same device can reach multiple LNS. One of the limiting factor is the connection awareness of IoT edge for its connected device clients. Edge keeps an active connection for all devices connected to it. If we have multiple open connections on multiple LNS servers for the same device identity, we experience an aggressive connection open/close pattern seriously affecting scalability of the LNS. Starting with version 2.1 we introduce a concept for connection ownership ensuring we only keep one active connection / LNS most of the time. To facilitate this, we track the last LNS that won the race to process a particular message. This LNS is then given an edge for future message processing for that device by a configurable amount. This allows the owning gateway to keep the connection open and keep processing messages without having to fight for the connection from other LNSes. LNSes that do not own the connection, never open it (unless for occasional cache refreshes). This allows us to have a high percentage of single connection management towards IoT hub. Should an owning LNS go down and a message for that device is sent, another LNS will eventually win the race and take the ownership. This guarantees seemless failover and message processing. Ownership is tracked both locally on the LNS to determine the connection state as well as on the function. The function side is used to send a notification, in case of an ownership change, to the previously owning LNS. This is covering the case of roaming devices, where a device could move outside of the reach of the owning gateway. That means it won't get any new messages and won't notice the ownership change, unless it is being informed by the function. Deduplication There is a feature built into the LNS to deduplicate messages , to deal with duplicate messages on multiple LNS. This does have an effect on scalability. Higher scalability as described above can only be achieved with Drop . Any other settings will require the connection to be opened during message processing on multiple gateways and does not allow the ownership of a connection on a single LNS.","title":"Scalability"},{"location":"user-guide/scalability/#scalability","text":"Different deployment scenarios have impact on the scalability of your LNS (LoRaWAN Network Server).","title":"Scalability"},{"location":"user-guide/scalability/#connection-ownership","text":"The LNS is running as a module on IoT edge and processes messages from potentially multiple LBS (LoRa Basics Stations). Due to the broadcasting of messages, the same message from the same device can reach multiple LNS. One of the limiting factor is the connection awareness of IoT edge for its connected device clients. Edge keeps an active connection for all devices connected to it. If we have multiple open connections on multiple LNS servers for the same device identity, we experience an aggressive connection open/close pattern seriously affecting scalability of the LNS. Starting with version 2.1 we introduce a concept for connection ownership ensuring we only keep one active connection / LNS most of the time. To facilitate this, we track the last LNS that won the race to process a particular message. This LNS is then given an edge for future message processing for that device by a configurable amount. This allows the owning gateway to keep the connection open and keep processing messages without having to fight for the connection from other LNSes. LNSes that do not own the connection, never open it (unless for occasional cache refreshes). This allows us to have a high percentage of single connection management towards IoT hub. Should an owning LNS go down and a message for that device is sent, another LNS will eventually win the race and take the ownership. This guarantees seemless failover and message processing. Ownership is tracked both locally on the LNS to determine the connection state as well as on the function. The function side is used to send a notification, in case of an ownership change, to the previously owning LNS. This is covering the case of roaming devices, where a device could move outside of the reach of the owning gateway. That means it won't get any new messages and won't notice the ownership change, unless it is being informed by the function.","title":"Connection ownership"},{"location":"user-guide/scalability/#deduplication","text":"There is a feature built into the LNS to deduplicate messages , to deal with duplicate messages on multiple LNS. This does have an effect on scalability. Higher scalability as described above can only be achieved with Drop . Any other settings will require the connection to be opened during message processing on multiple gateways and does not allow the ownership of a connection on a single LNS.","title":"Deduplication"},{"location":"user-guide/station-authentication-modes/","text":"Authentication modes Starting with 'Azure IoT Edge LoRaWAN Starter Kit' v2.0.0, the LoRaWan Network Server runs a WebSocket endpoint compatible with The LNS Protocol and the CUPS Protocol from LoRa Basics\u2122 Station. As described in the official LoRa Basics\u2122 Station documentation - Credentials , a Basics\u2122 Station client needs some credentials to establish a secure connection to LNS/CUPS compatible endpoints. Supported authentication modes The following table describes the supported authentication modes with the LoRaWan Network Server provided in Azure IoT Edge LoRaWAN Starter Kit LNS Endpoint CUPS Endpoint No Authentication \u2714\ufe0f \u274c Server Authentication only \u2714\ufe0f \u274c Mutual (server + client) authentication \u2714\ufe0f \u2714\ufe0f Server Authentication Importing certificate for server authentication in LoRaWan Network Server module LoRaWan Network Server IoT Edge module allows to import a certificate in 'pkcs12' format (.pfx) to be used for server authentication for both LNS and CUPS endpoints. Two environment variables need to be set in the deployment manifest for making this happen: LNS_SERVER_PFX_PATH : It's the absolute path to the .pfx certificate in the IoT Edge module filesystem (i.e.: /var/lorastarterkit/certs/lns.pfx ) LNS_SERVER_PFX_PASSWORD (optional) : needs to be set if the .pfx was exported with password Instructions on how to modify deployment manifest can be found in documentation ( Learn how to deploy modules and establish routes in IoT Edge ) Assuming the .pfx file is located in a folder on the host OS at /mnt/lora/certs , you will need to 'bind' this path to one in the IoT Edge module itself. In order to do so: Log into your Azure Portal Identify the IoT Edge Device in IoT Hub Set the 'LoRaWanNetworkSrvModule' HostConfiguration to include a binding for the folder under \"Container Create Options\" \"Binds\" : [ \"/mnt/lora/certs/:/var/lorastarterkit/certs/\" ] Additional information on this process can be found in the documentation - Use IoT Edge device local storage from a module . Importing 'tc.trust/cups.trust' in bundled 'LoRaBasicsStationModule' If you are making use of the bundled 'LoRaBasicsStationModule', it's possible to import a tc.trust/cups.trust certificate in the module itself. The default path where the trust file(s) will be searched is /var/lorastarterkit/certs/ . As described in the previous section, it is possible to bind a folder on the host OS to the one mentioned above. The default path of the tc.trust file can be overridden by using the 'TC_TRUST_PATH' environment variable (i.e.: setting it to /var/otherfolder/my.ca will make the module copy the my.ca file to a tc.trust in the LoRa Basics\u2122 Station working directory). Same can be done for a cups.trust file by overriding the 'CUPS_TRUST_PATH' environment variable Client authentication The LoRaWan Network Server implementation provided by this starter kit is allowing client authentication from a Basics Station client. Changing 'Client Certificate Mode' in 'LoRaWan Network Server module' and trusting certificate chain By default, the 'LoRaWanNetworkSrvModule' is not accepting/requiring any client certificate for its exposed endpoints. It is possible to modify the behavior of the module to actually either allow or require a client certificate for accessing to its endpoints. For example, to always require a client certificate for reaching LNS/CUPS endpoints, you should set the 'CLIENT_CERTIFICATE_MODE' environment variable in 'LoRaWanNetworkSrvModule' to a value of '2' or 'RequireCertificate'. Supported values for 'CLIENT_CERTIFICATE_MODE' environment variables are: 0 or NoCertificate : client certificate is not required and will not be requested from clients 1 or AllowCertificate : client certificate will be requested; however, authentication will not fail if a certificate is not provided by the client 2 or RequireCertificate : client certificate will be requested, and the client must provide a valid certificate for authentication to succeed When a client certificate is used, two verifications are done on the 'LoRaWanNetworkSrvModule' side: The certificate chain is validated. This implies that LoRaWanNetworkSrvModule will need to trust the root/intermediate certificates that generated the client one. If your certificate was not signed by a well-known CA, you will need to import one (or more) .crt PEM-encoded files for trusting the chain. The instructions for mounting volumes can be found in previous paragraphs. The client certificate will be searched by default at /var/lorastarterkit/certs/client.ca.crt . You can override this path to pass multiple files by specifying a ; separated list of paths in the CLIENT_CA_PATH environment variable. Exempli gratia, if you need to trust one root certificate located at module path /var/lorastarterkit/certs/root.crt plus one intermediate certificate at /var/lorastarterkit/certs/intermediate.crt you will need to set the CLIENT_CA_PATH environment variable to /var/lorastarterkit/certs/root.crt;/var/lorastarterkit/certs/intermediate.crt The certificate thumbprint gets compared with what is stored in the Concentrator Twin in IoT Hub. Importing 'tc.crt/tc.key/cups.crt/cups.key' in bundled 'LoRaBasicsStationModule' If you are making use of the bundled 'LoRaBasicsStationModule', it's possible to import a client certificate (.crt + .key files) in the module itself. The default path where the files will be searched is var/lorastarterkit/certs/ . As described in the previous section, it is possible to bind a folder on the host OS to the one mentioned above. The default path of the tc.crt/tc.key/cups.crt/cups.key file can be overridden by using the related environment variable (i.e.: setting any of 'TC_CRT_PATH' , 'TC_KEY_PATH' , 'CUPS_CRT_PATH' , 'CUPS_KEY_PATH' to /var/otherfolder/my.crt will make the module copy the my.crt file to a *.crt in the LoRa Basics\u2122 Station working directory). Providing a list of allowed client thumbprints for connection At the server side, the validation of the certificate is happening by comparing the thumbprint of the certificate provided for authentication with a list of allowed thumbprints stored in the Concentrator Twin (more information on 'clientThumbprint' property of Twin in related ADR ) When using the provided Cli-LoRa-Device-Provisioning tool to provision a concentrator device to IoT Hub, you can pass the '--client-certificate-thumbprint' option to specify the thumbprint of an allowed certificate. If you can't use the tool, when creating the Concentrator device in IoT Hub, all you need to do is to add a desired property named ' clientThumbprint ' (being an array of allowed certificate thumbprints) and specify the thumbprint in this array. Self-signed certificates generator (for tests only) This starter kit is providing a BasicStation Certificates Generation tool for helping its users to generate LoRaWAN Network Server certificates and Basics Station certificates for testing secure communication between a Basics Station client and the CUPS/LNS Protocol Endpoint in Network Server. Please refer to tool documentation for instructions on how to use it.","title":"Authentication modes"},{"location":"user-guide/station-authentication-modes/#authentication-modes","text":"Starting with 'Azure IoT Edge LoRaWAN Starter Kit' v2.0.0, the LoRaWan Network Server runs a WebSocket endpoint compatible with The LNS Protocol and the CUPS Protocol from LoRa Basics\u2122 Station. As described in the official LoRa Basics\u2122 Station documentation - Credentials , a Basics\u2122 Station client needs some credentials to establish a secure connection to LNS/CUPS compatible endpoints.","title":"Authentication modes"},{"location":"user-guide/station-authentication-modes/#supported-authentication-modes","text":"The following table describes the supported authentication modes with the LoRaWan Network Server provided in Azure IoT Edge LoRaWAN Starter Kit LNS Endpoint CUPS Endpoint No Authentication \u2714\ufe0f \u274c Server Authentication only \u2714\ufe0f \u274c Mutual (server + client) authentication \u2714\ufe0f \u2714\ufe0f","title":"Supported authentication modes"},{"location":"user-guide/station-authentication-modes/#server-authentication","text":"","title":"Server Authentication"},{"location":"user-guide/station-authentication-modes/#importing-certificate-for-server-authentication-in-lorawan-network-server-module","text":"LoRaWan Network Server IoT Edge module allows to import a certificate in 'pkcs12' format (.pfx) to be used for server authentication for both LNS and CUPS endpoints. Two environment variables need to be set in the deployment manifest for making this happen: LNS_SERVER_PFX_PATH : It's the absolute path to the .pfx certificate in the IoT Edge module filesystem (i.e.: /var/lorastarterkit/certs/lns.pfx ) LNS_SERVER_PFX_PASSWORD (optional) : needs to be set if the .pfx was exported with password Instructions on how to modify deployment manifest can be found in documentation ( Learn how to deploy modules and establish routes in IoT Edge ) Assuming the .pfx file is located in a folder on the host OS at /mnt/lora/certs , you will need to 'bind' this path to one in the IoT Edge module itself. In order to do so: Log into your Azure Portal Identify the IoT Edge Device in IoT Hub Set the 'LoRaWanNetworkSrvModule' HostConfiguration to include a binding for the folder under \"Container Create Options\" \"Binds\" : [ \"/mnt/lora/certs/:/var/lorastarterkit/certs/\" ] Additional information on this process can be found in the documentation - Use IoT Edge device local storage from a module .","title":"Importing certificate for server authentication in LoRaWan Network Server module"},{"location":"user-guide/station-authentication-modes/#importing-tctrustcupstrust-in-bundled-lorabasicsstationmodule","text":"If you are making use of the bundled 'LoRaBasicsStationModule', it's possible to import a tc.trust/cups.trust certificate in the module itself. The default path where the trust file(s) will be searched is /var/lorastarterkit/certs/ . As described in the previous section, it is possible to bind a folder on the host OS to the one mentioned above. The default path of the tc.trust file can be overridden by using the 'TC_TRUST_PATH' environment variable (i.e.: setting it to /var/otherfolder/my.ca will make the module copy the my.ca file to a tc.trust in the LoRa Basics\u2122 Station working directory). Same can be done for a cups.trust file by overriding the 'CUPS_TRUST_PATH' environment variable","title":"Importing 'tc.trust/cups.trust' in bundled 'LoRaBasicsStationModule'"},{"location":"user-guide/station-authentication-modes/#client-authentication","text":"The LoRaWan Network Server implementation provided by this starter kit is allowing client authentication from a Basics Station client.","title":"Client authentication"},{"location":"user-guide/station-authentication-modes/#changing-client-certificate-mode-in-lorawan-network-server-module-and-trusting-certificate-chain","text":"By default, the 'LoRaWanNetworkSrvModule' is not accepting/requiring any client certificate for its exposed endpoints. It is possible to modify the behavior of the module to actually either allow or require a client certificate for accessing to its endpoints. For example, to always require a client certificate for reaching LNS/CUPS endpoints, you should set the 'CLIENT_CERTIFICATE_MODE' environment variable in 'LoRaWanNetworkSrvModule' to a value of '2' or 'RequireCertificate'. Supported values for 'CLIENT_CERTIFICATE_MODE' environment variables are: 0 or NoCertificate : client certificate is not required and will not be requested from clients 1 or AllowCertificate : client certificate will be requested; however, authentication will not fail if a certificate is not provided by the client 2 or RequireCertificate : client certificate will be requested, and the client must provide a valid certificate for authentication to succeed When a client certificate is used, two verifications are done on the 'LoRaWanNetworkSrvModule' side: The certificate chain is validated. This implies that LoRaWanNetworkSrvModule will need to trust the root/intermediate certificates that generated the client one. If your certificate was not signed by a well-known CA, you will need to import one (or more) .crt PEM-encoded files for trusting the chain. The instructions for mounting volumes can be found in previous paragraphs. The client certificate will be searched by default at /var/lorastarterkit/certs/client.ca.crt . You can override this path to pass multiple files by specifying a ; separated list of paths in the CLIENT_CA_PATH environment variable. Exempli gratia, if you need to trust one root certificate located at module path /var/lorastarterkit/certs/root.crt plus one intermediate certificate at /var/lorastarterkit/certs/intermediate.crt you will need to set the CLIENT_CA_PATH environment variable to /var/lorastarterkit/certs/root.crt;/var/lorastarterkit/certs/intermediate.crt The certificate thumbprint gets compared with what is stored in the Concentrator Twin in IoT Hub.","title":"Changing 'Client Certificate Mode' in 'LoRaWan Network Server module' and trusting certificate chain"},{"location":"user-guide/station-authentication-modes/#importing-tccrttckeycupscrtcupskey-in-bundled-lorabasicsstationmodule","text":"If you are making use of the bundled 'LoRaBasicsStationModule', it's possible to import a client certificate (.crt + .key files) in the module itself. The default path where the files will be searched is var/lorastarterkit/certs/ . As described in the previous section, it is possible to bind a folder on the host OS to the one mentioned above. The default path of the tc.crt/tc.key/cups.crt/cups.key file can be overridden by using the related environment variable (i.e.: setting any of 'TC_CRT_PATH' , 'TC_KEY_PATH' , 'CUPS_CRT_PATH' , 'CUPS_KEY_PATH' to /var/otherfolder/my.crt will make the module copy the my.crt file to a *.crt in the LoRa Basics\u2122 Station working directory).","title":"Importing 'tc.crt/tc.key/cups.crt/cups.key' in bundled 'LoRaBasicsStationModule'"},{"location":"user-guide/station-authentication-modes/#providing-a-list-of-allowed-client-thumbprints-for-connection","text":"At the server side, the validation of the certificate is happening by comparing the thumbprint of the certificate provided for authentication with a list of allowed thumbprints stored in the Concentrator Twin (more information on 'clientThumbprint' property of Twin in related ADR ) When using the provided Cli-LoRa-Device-Provisioning tool to provision a concentrator device to IoT Hub, you can pass the '--client-certificate-thumbprint' option to specify the thumbprint of an allowed certificate. If you can't use the tool, when creating the Concentrator device in IoT Hub, all you need to do is to add a desired property named ' clientThumbprint ' (being an array of allowed certificate thumbprints) and specify the thumbprint in this array.","title":"Providing a list of allowed client thumbprints for connection"},{"location":"user-guide/station-authentication-modes/#self-signed-certificates-generator-for-tests-only","text":"This starter kit is providing a BasicStation Certificates Generation tool for helping its users to generate LoRaWAN Network Server certificates and Basics Station certificates for testing secure communication between a Basics Station client and the CUPS/LNS Protocol Endpoint in Network Server. Please refer to tool documentation for instructions on how to use it.","title":"Self-signed certificates generator (for tests only)"},{"location":"user-guide/station-device-provisioning/","text":"Concentrator provisioning Following the LoRaWAN Network Server specification, each Basics Station will at some point invoke the discovery endpoint on a LNS . Subsequently, it will establish a data connection on the data endpoint to receive its setup information. To ensure that the LBS is able to receive the setup information, you will need to add the LBS configuration to IoT Hub. An LBS that does not have its configuration stored in IoT Hub will not be able to connect to the LNS . Use LoRa Device Provisioning CLI In the following we describe how to register an LBS in IoT Hub by using the LoRa Device Provisioning CLI . Retrieve the LBS EUI in its hex-representation (e.g. AABBCCFFFE001122 ). If you are running a dev kit on a Linux machine, the EUI can be retrieved from the MAC address of the eth0 interface as follows: Info Assuming aa:bb:cc:00:11:22 is the returned MAC Address your EUI will be AABBCCFFFE001122. Please note the insertion of the literals 'FFFE' in the middle, as per Basic Station Glossary cat /sys/class/net/eth0/address # prints the MAC Address of eth0 Download the LoRa Device Provisioning CLI and populate the appsettings.json with the required connection strings of the services deployed by the starter kit. Execute the CLI and pass the parameters for the desired configuration. e.g.: if you want to register a EU863 concentrator, not using CUPS , you should issue .\\ loradeviceprovisioning . exe add - -type concentrator - -stationeui AABBCCFFFE001122 - -region EU863 - -no-cups e.g.: if you want to register a US902 concentrator, not using CUPS , which is expected to connect to LNS endpoint with client certificate, you should issue .\\ loradeviceprovisioning . exe add - -type concentrator - -stationeui AABBCCFFFE001122 - -region US902 - -no-cups - -client-certificate-thumbprint < AABBCCFFFE001122 . crt Thumbprint Here > e.g.: if you want to register a EU863 concentrator, using CUPS , you should issue .\\ loradeviceprovisioning . exe add - -type concentrator - -stationeui AABBCCFFFE001122 - -region EU863 - -client-certificate-thumbprint < AABBCCFFFE001122 . crt Thumbprint Here > - -certificate-bundle-location < path to AABBCCFFFE001122 . bundle > - -tc-uri wss :// IP_OR_DNS : 5001 - -cups-uri https :// IP_OR_DNS : 5002 Please note that currently supported regions for the LoRa Device Provisioning CLI are EU863, US902, CN470RP1 and CN470RP2. Nevertheless, the tool is extensible and you can bring your own 'region.json' in the Cli-LoRa-Device-Provisioning\\DefaultRouterConfig folder. Manual configuration If you don't want to use the LoRa Device Provisioning CLI , in the following section we describe how to register an LBS in IoT Hub and how to store its configuration. Create an IoT Hub device that has a name equal to the LBS EUI in hex-representation, e.g. AABBCCFFFE001122 . If you are running a dev kit on a Linux machine, the EUI will be retrieved from the MAC address of the eth0 interface as follows: cat /sys/class/net/eth0/address # prints the MAC Address of eth0 # Assuming aa:bb:cc:00:11:22 is the returned MAC Address # your EUI will be AABBCCFFFE001122 # Please note the insertion of the literals 'FFFE' in the middle, as per https://doc.sm.tc/station/glossary.html?highlight=mac The radio configuration needs to be stored as a desired twin property of the newly created LBS device. Make sure to store the configuration under properties.desired.routerConfig The configuration follows the router_config format from the LNS protocol as closely as possible. However, since device twins encode numbers as 32-bit values and given some configuration properties (such as EUIs) are 64-bit numbers, there are some minor differences. The JoinEui nested array must consist of hexadecimal-encoded strings. The property should look similar to: \"JoinEui\": [[\"DCA632FFFEB32FC5\",\"DCA632FFFEB32FC7\"]] which will restrict the range of devices that the concentrator will listen to. In the example below we set this limit to all devices to offer an easy quickstart, it is advised to restrict the value in production. A full configuration example might look like this, relative to the desired twin property path properties.desired : The default settings here below are compatible from the Region Example we provide in the Arduino folder. EU863 Example Configuration US902 Example Configuration CN470RP1 Example Configuration CN470RP2 Example Configuration AS923-1 Example Configuration AS923-2 Example Configuration AS923-3 Example Configuration \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"EU863\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 863000000 , 870000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 250 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 867500000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 868500000 }, \"chan_FSK\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -400000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 0 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -400000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -200000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 0 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 200000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 400000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } US902 defines several uplink channels and sub-bands. Router configuration below is suited for sub-band 1. Please adjust radio_0 and radio_1 freq fields accordingly for your sub-band needs. Uplink sub-bands Frequency range (MHz) Channels Radio 0 Frequency Radio 1 Frequency Sub-Band 1 902.3 - 903.7 0-7 902700000 903400000 Sub-Band 2 903.9 - 905.3 8-15 904300000 905000000 Sub-Band 3 905.5 - 906.9 16-23 905900000 906600000 Sub-Band 4 907.1 - 908.5 24-31 907500000 908200000 Sub-Band 5 908.7 - 910.1 32-39 909100000 909800000 Sub-Band 6 910.3 - 911.7 40-47 910700000 911400000 Sub-Band 7 911.9 - 913.3 48-55 912300000 913000000 Sub-Band 8 913.5 - 914.9 56-63 913900000 914600000 \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"US902\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 902000000 , 928000000 ], \"DRs\" : [ [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 8 , 500 , 0 ], [ -1 , 0 , 0 ], [ -1 , 0 , 0 ], [ -1 , 0 , 0 ], [ 12 , 500 , 1 ], [ 11 , 500 , 1 ], [ 10 , 500 , 1 ], [ 9 , 500 , 1 ], [ 8 , 500 , 1 ], [ 7 , 500 , 1 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 902700000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 903400000 }, \"chan_FSK\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 300000 , \"bandwidth\" : 500000 , \"spread_factor\" : 8 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -400000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -200000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 0 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 200000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } This Configuration is using channels 1-4 (470.3, 470.5, 470.7, 470.9) and 40-43 (478.1, 478.3, 478.5, 478.7) to avoid colliding with reserved China Electric frequencies \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"CN470RP1\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 470000000 , 510000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 500 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 470600000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 478400000 }, \"chan_FSK\" : { \"enable\" : false , \"radio\" : 0 , \"if\" : 1 }, \"chan_Lora_std\" : { \"enable\" : false , \"radio\" : 0 , \"if\" : 1 , \"bandwidth\" : 125000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -300000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -100000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 100000 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 300000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } Frequencies used are 498.3, 498.7, 498.9, 499.1, 499.3, 499.5, 499.7, 499.9 to avoid colliding with reserved China Electric frequencies { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"CN470RP2\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 470000000 , 510000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 500 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 498700000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 499600000 }, \"chan_FSK\" : { \"enable\" : false , \"radio\" : 0 , \"if\" : 1 }, \"chan_Lora_std\" : { \"enable\" : false , \"radio\" : 0 , \"if\" : 1 , \"bandwidth\" : 125000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -400000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 0 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 200000 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 400000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } For more details on the 'desiredTxParams' field, refer to the AS923 specificities section . For information where you should use AS923-1, AS923-2,... please refer to the LoRaWan Regional parameters to see which one your country supports. { \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"AS923\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 915000000 , 928000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 250 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 923500000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 924300000 }, \"chan_FSK\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 500000 }, \"chan_Lora_std\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true , \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } }, \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } } For more details on the 'desiredTxParams' field, refer to the AS923 specificities section . For information where you should use AS923-1, AS923-2,... please refer to the LoRaWan Regional parameters to see which one your country supports. { \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"AS923\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 915000000 , 928000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 250 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 921700000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 922500000 }, \"chan_FSK\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true , \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } }, \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } } For more details on the 'desiredTxParams' field, refer to the AS923 specificities section . For information where you should use AS923-1, AS923-2,... please refer to the LoRaWan Regional parameters to see which one your country supports. { \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"AS923\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 915000000 , 928000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 250 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 916900000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 917700000 }, \"chan_FSK\" : { \"enable\" : false , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true , \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } }, \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } } \"AU915RP1 Example Configuration\" { \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [ [ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ] ], \"region\" : \"AU915\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 915000000 , 928000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 8 , 500 , 0 ], [ -1 , 0 , 0 ], [ 12 , 500 , 0 ], [ 11 , 500 , 0 ], [ 10 , 500 , 0 ], [ 9 , 500 , 0 ], [ 8 , 500 , 0 ], [ 7 , 500 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 915600000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 916600000 }, \"chan_FSK\" : { \"enable\" : false , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" : { \"enable\" : false , \"radio\" : 1 , \"if\" : -200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -400000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 0 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -400000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -200000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 0 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 200000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 400000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } } A more thorough description of sx1301_conf can be found at The LNS Protocol specification. If you want to enable client certificate validation for this device, make sure to define the properties.desired.clientThumbprint desired property as an array of strings (each of them being one of the allowed thumbprints for client certificates of this device) If you want to enable CUPS for this device, after generating the certificates, you will need to: 1. upload the .bundle credential file to the 'stationcredentials' container in the Azure Function Storage Account created by the Starter Kit template ( Quickstart: Upload, download, and list blobs - Azure portal - Azure Storage | Microsoft Docs ) The .bundle file is the concatenation of the .trust, .crt and .key files in DER format as described in official Basics Station documentation 2. make sure to define the properties.desired.cups desired property as follows: \"cups\" : { \"cupsUri\" : \"https://IP_or_DNS:5002\" , \"tcUri\" : \"wss://IP_or_DNS:5001\" , \"cupsCredCrc\" : INT , \"tcCredCrc\" : INT , \"cupsCredentialUrl\" : \"https://...\" , \"tcCredentialUrl\" : \"https://...\" } with 'cupsCredCrc' : computed as CRC32 checksum calculated over the concatenated credentials files cups.{trust,cert,key} (or the .bundle file if certificates were generated with the tool provided in this kit) 'tcCredCrc' : computed as CRC32 checksum calculated over the concatenated credentials files tc.{trust,cert,key} (or the .bundle file if certificates were generated with the tool provided in this kit) 'cupsCredentialUrl' : should point to the blob in the Azure Function storage account containing the concatenated credentials (i.e.: .bundle file generated with the tool provided in this kit) 'tcCredentialUrl' : should point to the blob in the Azure Function storage account containing the concatenated credentials (i.e.: .bundle file generated with the tool provided in this kit) By saving the configuration per LBS in its device twin, the LBS will be able to successfully connect to the LNS and it can start sending frames. Class B beaconing A Basic station device can be instructed to send class B beaconing signals (disabled by default). In order to enable the feature, add the following JSON to the routerConfig object (described above) following the specs described for the bcning field in the basics station documentation . example for EU863: \"bcning\" : { \"DR\" : 3 , \"layout\" : [ 2 , 8 , 17 ], \"freqs\" : [ 869525000 ] } for more information refer to the class B docs .","title":"Concentrator provisioning"},{"location":"user-guide/station-device-provisioning/#concentrator-provisioning","text":"Following the LoRaWAN Network Server specification, each Basics Station will at some point invoke the discovery endpoint on a LNS . Subsequently, it will establish a data connection on the data endpoint to receive its setup information. To ensure that the LBS is able to receive the setup information, you will need to add the LBS configuration to IoT Hub. An LBS that does not have its configuration stored in IoT Hub will not be able to connect to the LNS .","title":"Concentrator provisioning"},{"location":"user-guide/station-device-provisioning/#use-lora-device-provisioning-cli","text":"In the following we describe how to register an LBS in IoT Hub by using the LoRa Device Provisioning CLI . Retrieve the LBS EUI in its hex-representation (e.g. AABBCCFFFE001122 ). If you are running a dev kit on a Linux machine, the EUI can be retrieved from the MAC address of the eth0 interface as follows: Info Assuming aa:bb:cc:00:11:22 is the returned MAC Address your EUI will be AABBCCFFFE001122. Please note the insertion of the literals 'FFFE' in the middle, as per Basic Station Glossary cat /sys/class/net/eth0/address # prints the MAC Address of eth0 Download the LoRa Device Provisioning CLI and populate the appsettings.json with the required connection strings of the services deployed by the starter kit. Execute the CLI and pass the parameters for the desired configuration. e.g.: if you want to register a EU863 concentrator, not using CUPS , you should issue .\\ loradeviceprovisioning . exe add - -type concentrator - -stationeui AABBCCFFFE001122 - -region EU863 - -no-cups e.g.: if you want to register a US902 concentrator, not using CUPS , which is expected to connect to LNS endpoint with client certificate, you should issue .\\ loradeviceprovisioning . exe add - -type concentrator - -stationeui AABBCCFFFE001122 - -region US902 - -no-cups - -client-certificate-thumbprint < AABBCCFFFE001122 . crt Thumbprint Here > e.g.: if you want to register a EU863 concentrator, using CUPS , you should issue .\\ loradeviceprovisioning . exe add - -type concentrator - -stationeui AABBCCFFFE001122 - -region EU863 - -client-certificate-thumbprint < AABBCCFFFE001122 . crt Thumbprint Here > - -certificate-bundle-location < path to AABBCCFFFE001122 . bundle > - -tc-uri wss :// IP_OR_DNS : 5001 - -cups-uri https :// IP_OR_DNS : 5002 Please note that currently supported regions for the LoRa Device Provisioning CLI are EU863, US902, CN470RP1 and CN470RP2. Nevertheless, the tool is extensible and you can bring your own 'region.json' in the Cli-LoRa-Device-Provisioning\\DefaultRouterConfig folder.","title":"Use LoRa Device Provisioning CLI"},{"location":"user-guide/station-device-provisioning/#manual-configuration","text":"If you don't want to use the LoRa Device Provisioning CLI , in the following section we describe how to register an LBS in IoT Hub and how to store its configuration. Create an IoT Hub device that has a name equal to the LBS EUI in hex-representation, e.g. AABBCCFFFE001122 . If you are running a dev kit on a Linux machine, the EUI will be retrieved from the MAC address of the eth0 interface as follows: cat /sys/class/net/eth0/address # prints the MAC Address of eth0 # Assuming aa:bb:cc:00:11:22 is the returned MAC Address # your EUI will be AABBCCFFFE001122 # Please note the insertion of the literals 'FFFE' in the middle, as per https://doc.sm.tc/station/glossary.html?highlight=mac The radio configuration needs to be stored as a desired twin property of the newly created LBS device. Make sure to store the configuration under properties.desired.routerConfig The configuration follows the router_config format from the LNS protocol as closely as possible. However, since device twins encode numbers as 32-bit values and given some configuration properties (such as EUIs) are 64-bit numbers, there are some minor differences. The JoinEui nested array must consist of hexadecimal-encoded strings. The property should look similar to: \"JoinEui\": [[\"DCA632FFFEB32FC5\",\"DCA632FFFEB32FC7\"]] which will restrict the range of devices that the concentrator will listen to. In the example below we set this limit to all devices to offer an easy quickstart, it is advised to restrict the value in production. A full configuration example might look like this, relative to the desired twin property path properties.desired : The default settings here below are compatible from the Region Example we provide in the Arduino folder. EU863 Example Configuration US902 Example Configuration CN470RP1 Example Configuration CN470RP2 Example Configuration AS923-1 Example Configuration AS923-2 Example Configuration AS923-3 Example Configuration \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"EU863\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 863000000 , 870000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 250 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 867500000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 868500000 }, \"chan_FSK\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -400000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 0 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -400000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -200000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 0 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 200000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 400000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } US902 defines several uplink channels and sub-bands. Router configuration below is suited for sub-band 1. Please adjust radio_0 and radio_1 freq fields accordingly for your sub-band needs. Uplink sub-bands Frequency range (MHz) Channels Radio 0 Frequency Radio 1 Frequency Sub-Band 1 902.3 - 903.7 0-7 902700000 903400000 Sub-Band 2 903.9 - 905.3 8-15 904300000 905000000 Sub-Band 3 905.5 - 906.9 16-23 905900000 906600000 Sub-Band 4 907.1 - 908.5 24-31 907500000 908200000 Sub-Band 5 908.7 - 910.1 32-39 909100000 909800000 Sub-Band 6 910.3 - 911.7 40-47 910700000 911400000 Sub-Band 7 911.9 - 913.3 48-55 912300000 913000000 Sub-Band 8 913.5 - 914.9 56-63 913900000 914600000 \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"US902\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 902000000 , 928000000 ], \"DRs\" : [ [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 8 , 500 , 0 ], [ -1 , 0 , 0 ], [ -1 , 0 , 0 ], [ -1 , 0 , 0 ], [ 12 , 500 , 1 ], [ 11 , 500 , 1 ], [ 10 , 500 , 1 ], [ 9 , 500 , 1 ], [ 8 , 500 , 1 ], [ 7 , 500 , 1 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 902700000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 903400000 }, \"chan_FSK\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 300000 , \"bandwidth\" : 500000 , \"spread_factor\" : 8 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -400000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -200000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 0 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 200000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } This Configuration is using channels 1-4 (470.3, 470.5, 470.7, 470.9) and 40-43 (478.1, 478.3, 478.5, 478.7) to avoid colliding with reserved China Electric frequencies \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"CN470RP1\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 470000000 , 510000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 500 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 470600000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 478400000 }, \"chan_FSK\" : { \"enable\" : false , \"radio\" : 0 , \"if\" : 1 }, \"chan_Lora_std\" : { \"enable\" : false , \"radio\" : 0 , \"if\" : 1 , \"bandwidth\" : 125000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -300000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -100000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 100000 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 300000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } Frequencies used are 498.3, 498.7, 498.9, 499.1, 499.3, 499.5, 499.7, 499.9 to avoid colliding with reserved China Electric frequencies { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"CN470RP2\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 470000000 , 510000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 500 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 498700000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 499600000 }, \"chan_FSK\" : { \"enable\" : false , \"radio\" : 0 , \"if\" : 1 }, \"chan_Lora_std\" : { \"enable\" : false , \"radio\" : 0 , \"if\" : 1 , \"bandwidth\" : 125000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -400000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 0 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 200000 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 400000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } For more details on the 'desiredTxParams' field, refer to the AS923 specificities section . For information where you should use AS923-1, AS923-2,... please refer to the LoRaWan Regional parameters to see which one your country supports. { \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"AS923\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 915000000 , 928000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 250 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 923500000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 924300000 }, \"chan_FSK\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 500000 }, \"chan_Lora_std\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true , \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } }, \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } } For more details on the 'desiredTxParams' field, refer to the AS923 specificities section . For information where you should use AS923-1, AS923-2,... please refer to the LoRaWan Regional parameters to see which one your country supports. { \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"AS923\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 915000000 , 928000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 250 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 921700000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 922500000 }, \"chan_FSK\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true , \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } }, \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } } For more details on the 'desiredTxParams' field, refer to the AS923 specificities section . For information where you should use AS923-1, AS923-2,... please refer to the LoRaWan Regional parameters to see which one your country supports. { \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [[ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ]], \"region\" : \"AS923\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 915000000 , 928000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 7 , 250 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 916900000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 917700000 }, \"chan_FSK\" : { \"enable\" : false , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -300000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -100000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 100000 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 300000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -300000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -100000 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 100000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 300000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true , \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } }, \"desiredTxParams\" : { \"downlinkDwellLimit\" : true , \"uplinkDwellLimit\" : true , \"eirp\" : 5 } } \"AU915RP1 Example Configuration\" { \"routerConfig\" : { \"NetID\" : [ 1 ], \"JoinEui\" : [ [ \"0000000000000000\" , \"FFFFFFFFFFFFFFFF\" ] ], \"region\" : \"AU915\" , \"hwspec\" : \"sx1301/1\" , \"freq_range\" : [ 915000000 , 928000000 ], \"DRs\" : [ [ 12 , 125 , 0 ], [ 11 , 125 , 0 ], [ 10 , 125 , 0 ], [ 9 , 125 , 0 ], [ 8 , 125 , 0 ], [ 7 , 125 , 0 ], [ 8 , 500 , 0 ], [ -1 , 0 , 0 ], [ 12 , 500 , 0 ], [ 11 , 500 , 0 ], [ 10 , 500 , 0 ], [ 9 , 500 , 0 ], [ 8 , 500 , 0 ], [ 7 , 500 , 0 ] ], \"sx1301_conf\" : [ { \"radio_0\" : { \"enable\" : true , \"freq\" : 915600000 }, \"radio_1\" : { \"enable\" : true , \"freq\" : 916600000 }, \"chan_FSK\" : { \"enable\" : false , \"radio\" : 1 , \"if\" : 300000 }, \"chan_Lora_std\" : { \"enable\" : false , \"radio\" : 1 , \"if\" : -200000 , \"bandwidth\" : 250000 , \"spread_factor\" : 7 }, \"chan_multiSF_0\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -400000 }, \"chan_multiSF_1\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : -200000 }, \"chan_multiSF_2\" : { \"enable\" : true , \"radio\" : 1 , \"if\" : 0 }, \"chan_multiSF_3\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -400000 }, \"chan_multiSF_4\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : -200000 }, \"chan_multiSF_5\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 0 }, \"chan_multiSF_6\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 200000 }, \"chan_multiSF_7\" : { \"enable\" : true , \"radio\" : 0 , \"if\" : 400000 } } ], \"nocca\" : true , \"nodc\" : true , \"nodwell\" : true } } A more thorough description of sx1301_conf can be found at The LNS Protocol specification. If you want to enable client certificate validation for this device, make sure to define the properties.desired.clientThumbprint desired property as an array of strings (each of them being one of the allowed thumbprints for client certificates of this device) If you want to enable CUPS for this device, after generating the certificates, you will need to: 1. upload the .bundle credential file to the 'stationcredentials' container in the Azure Function Storage Account created by the Starter Kit template ( Quickstart: Upload, download, and list blobs - Azure portal - Azure Storage | Microsoft Docs ) The .bundle file is the concatenation of the .trust, .crt and .key files in DER format as described in official Basics Station documentation 2. make sure to define the properties.desired.cups desired property as follows: \"cups\" : { \"cupsUri\" : \"https://IP_or_DNS:5002\" , \"tcUri\" : \"wss://IP_or_DNS:5001\" , \"cupsCredCrc\" : INT , \"tcCredCrc\" : INT , \"cupsCredentialUrl\" : \"https://...\" , \"tcCredentialUrl\" : \"https://...\" } with 'cupsCredCrc' : computed as CRC32 checksum calculated over the concatenated credentials files cups.{trust,cert,key} (or the .bundle file if certificates were generated with the tool provided in this kit) 'tcCredCrc' : computed as CRC32 checksum calculated over the concatenated credentials files tc.{trust,cert,key} (or the .bundle file if certificates were generated with the tool provided in this kit) 'cupsCredentialUrl' : should point to the blob in the Azure Function storage account containing the concatenated credentials (i.e.: .bundle file generated with the tool provided in this kit) 'tcCredentialUrl' : should point to the blob in the Azure Function storage account containing the concatenated credentials (i.e.: .bundle file generated with the tool provided in this kit) By saving the configuration per LBS in its device twin, the LBS will be able to successfully connect to the LNS and it can start sending frames.","title":"Manual configuration"},{"location":"user-guide/station-device-provisioning/#class-b-beaconing","text":"A Basic station device can be instructed to send class B beaconing signals (disabled by default). In order to enable the feature, add the following JSON to the routerConfig object (described above) following the specs described for the bcning field in the basics station documentation . example for EU863: \"bcning\" : { \"DR\" : 3 , \"layout\" : [ 2 , 8 , 17 ], \"freqs\" : [ 869525000 ] } for more information refer to the class B docs .","title":"Class B beaconing"},{"location":"user-guide/station-firmware-upgrade/","text":"Firmware upgrade with CUPS The Azure IoT Edge LoRaWAN Starter Kit offers the functionality of performing a firmware upgrade of the Basics Station. This document explains which steps are required to execute such upgrade. When provisioning a concentrator device that will require future firmware upgrades, you will need to generate a signature key and store it on the device and in a centralized repository of your choice. During the update process, CUPS Protocol is using the CRC32 checksum of the signature key on the device to compare the digest of the firmware upgrade executable generated with such key. You can use the CUPS Protocol - Firmware Upgrade Preparation tool to generate all needed files. Use LoRa Device Provisioning CLI tool to upload the upgrade files in the cloud. dotnet .\\ Tools \\ Cli-LoRa-Device-Provisioning \\ bin \\ Release \\ net6 . 0 \\ loradeviceprovisioning . dll upgrade-firmware - -stationeui < station_eui > - -package < package_version > - -firmware-location < firmware_file_path > - -digest-location < digest_file_path > - -checksum-location < checksum_file_path > - -iothub-connection-string < iothub_connection_string > - -storage-connection-string < storage_connection_string > Parameters: stationeui - StationEui of the target device package - new version of the Station, e.g. 1.0.1 firmware-location - local path of the firmware upgrade executable file digest-location - local path of the file containing the generated digest of the executable file of the upgrade checksum-location - local path of the file containing the CRC32 checksum of the key used to generate the digest The LoRa Device Provisioning CLI tool will save the upgrade data by uploading the firmware to a storage account and updating the device twin of the concentrator with required data. For more information about using the LoRa Device Provisioning CLI tool please refer to the LoRa Device Provisioning tool documentation. During the next reconnection of the Basics Station to the CUPS endpoint, it will execute the upgrade after receiving the updated information from the Network Server. A system downtime is to be expected in order for the upgrade to complete. After the upgrade is finished, and the Basics Station is reconnecting to the LNS Data endpoint, the updated version of the Basics Station will be reported in the properties of the concentrator twin in IoT Hub.","title":"Firmware upgrade with CUPS"},{"location":"user-guide/station-firmware-upgrade/#firmware-upgrade-with-cups","text":"The Azure IoT Edge LoRaWAN Starter Kit offers the functionality of performing a firmware upgrade of the Basics Station. This document explains which steps are required to execute such upgrade. When provisioning a concentrator device that will require future firmware upgrades, you will need to generate a signature key and store it on the device and in a centralized repository of your choice. During the update process, CUPS Protocol is using the CRC32 checksum of the signature key on the device to compare the digest of the firmware upgrade executable generated with such key. You can use the CUPS Protocol - Firmware Upgrade Preparation tool to generate all needed files. Use LoRa Device Provisioning CLI tool to upload the upgrade files in the cloud. dotnet .\\ Tools \\ Cli-LoRa-Device-Provisioning \\ bin \\ Release \\ net6 . 0 \\ loradeviceprovisioning . dll upgrade-firmware - -stationeui < station_eui > - -package < package_version > - -firmware-location < firmware_file_path > - -digest-location < digest_file_path > - -checksum-location < checksum_file_path > - -iothub-connection-string < iothub_connection_string > - -storage-connection-string < storage_connection_string > Parameters: stationeui - StationEui of the target device package - new version of the Station, e.g. 1.0.1 firmware-location - local path of the firmware upgrade executable file digest-location - local path of the file containing the generated digest of the executable file of the upgrade checksum-location - local path of the file containing the CRC32 checksum of the key used to generate the digest The LoRa Device Provisioning CLI tool will save the upgrade data by uploading the firmware to a storage account and updating the device twin of the concentrator with required data. For more information about using the LoRa Device Provisioning CLI tool please refer to the LoRa Device Provisioning tool documentation. During the next reconnection of the Basics Station to the CUPS endpoint, it will execute the upgrade after receiving the updated information from the Network Server. A system downtime is to be expected in order for the upgrade to complete. After the upgrade is finished, and the Basics Station is reconnecting to the LNS Data endpoint, the updated version of the Basics Station will be reported in the properties of the concentrator twin in IoT Hub.","title":"Firmware upgrade with CUPS"},{"location":"user-guide/station-module-configuration/","text":"LBS IoT Edge Module configuration The following table is providing a list of configuration options, to be provided as environment variables for manual configuration of the LoRaBasicsStationModule : Environment variable name Description Mandatory TC_URI The URI to the LNS Server implementation Yes (i.e.: ws://IP_or_DNS:5000 or wss:// IP_OR_DNS :5001 ) CUPS_URI The URI to the CUPS Server implementation Yes, if CUPS endpoint is required (i.e.: https:// IP_or_DNS :5002 ) TC_TRUST_PATH The path to the tc.trust file. Refer to this file for more information No (if not set, defaulting to /var/lorastarterkit/certs/tc.trust ) TC_CRT_PATH The path to the tc.crt file. Refer to this file for more information No (if not set, defaulting to /var/lorastarterkit/certs/tc.crt ) TC_KEY_PATH The path to the tc.key file. Refer to this file for more information No (if not set, defaulting to /var/lorastarterkit/certs/tc.key ) CUPS_TRUST_PATH The path to the cups.trust file. Refer to this file for more information Only when CUPS is enabled (if not set, defaulting to /var/lorastarterkit/certs/cups.trust ) CUPS_CRT_PATH The path to the cups.crt file. Refer to this file for more information Only when CUPS is enabled (if not set, defaulting to /var/lorastarterkit/certs/cups.crt ) CUPS_KEY_PATH The path to the cups.key file. Refer to this file for more information Only when CUPS is enabled (if not set, defaulting to /var/lorastarterkit/certs/cups.key ) RESET_PIN Pin number for resetting the concentrator. It is board specific. No (if not set, module will skip the reset of the board) CORECELL A boolean identifying whether to use the Corecell (SX1302) binary No (if not set, defaults to false) RADIODEV A string identifying the location where the board should be accessed (i.e.: /dev/ttyACM0 for SPI devices or usb:/dev/ttyUSB0 in case of USB-based SX1302 devices). No (if not set, board will be accessed at /dev/spidevX.0, see following item) SPI_DEV A number identifying the SPI location where the board should be accessed (i.e.: when X, board accessed at /dev/spidevX.0) No (defaults to 0) SPI_SPEED Useful for setting SPI max clock No (default to 8, unique alternative provided is 2) FIXED_STATION_EUI Provides the ability to start the Basics Station with a fixed EUI No (if not set, the Basics Station built-in logic will be used for generating a EUI) STATION_PATH A string identifying the path of the folder where the compiled station.std binary for Basics Station is located No (if not set, defaults to /basicstation folder) LOG_LEVEL A string setting the desired log level for the Basics Station binary. Allowed values: XDEBUG,DEBUG,VERBOSE,INFO,NOTICE,WARNING,ERROR,CRITICAL No (if not set, defaults to INFO) LOCAL_DEVELOPMENT A boolean indicating whether the Network Server is running locally in Visual Studio for debugging purposes No (if not set, defaults to False)","title":"LBS IoT Edge Module configuration"},{"location":"user-guide/station-module-configuration/#lbs-iot-edge-module-configuration","text":"The following table is providing a list of configuration options, to be provided as environment variables for manual configuration of the LoRaBasicsStationModule : Environment variable name Description Mandatory TC_URI The URI to the LNS Server implementation Yes (i.e.: ws://IP_or_DNS:5000 or wss:// IP_OR_DNS :5001 ) CUPS_URI The URI to the CUPS Server implementation Yes, if CUPS endpoint is required (i.e.: https:// IP_or_DNS :5002 ) TC_TRUST_PATH The path to the tc.trust file. Refer to this file for more information No (if not set, defaulting to /var/lorastarterkit/certs/tc.trust ) TC_CRT_PATH The path to the tc.crt file. Refer to this file for more information No (if not set, defaulting to /var/lorastarterkit/certs/tc.crt ) TC_KEY_PATH The path to the tc.key file. Refer to this file for more information No (if not set, defaulting to /var/lorastarterkit/certs/tc.key ) CUPS_TRUST_PATH The path to the cups.trust file. Refer to this file for more information Only when CUPS is enabled (if not set, defaulting to /var/lorastarterkit/certs/cups.trust ) CUPS_CRT_PATH The path to the cups.crt file. Refer to this file for more information Only when CUPS is enabled (if not set, defaulting to /var/lorastarterkit/certs/cups.crt ) CUPS_KEY_PATH The path to the cups.key file. Refer to this file for more information Only when CUPS is enabled (if not set, defaulting to /var/lorastarterkit/certs/cups.key ) RESET_PIN Pin number for resetting the concentrator. It is board specific. No (if not set, module will skip the reset of the board) CORECELL A boolean identifying whether to use the Corecell (SX1302) binary No (if not set, defaults to false) RADIODEV A string identifying the location where the board should be accessed (i.e.: /dev/ttyACM0 for SPI devices or usb:/dev/ttyUSB0 in case of USB-based SX1302 devices). No (if not set, board will be accessed at /dev/spidevX.0, see following item) SPI_DEV A number identifying the SPI location where the board should be accessed (i.e.: when X, board accessed at /dev/spidevX.0) No (defaults to 0) SPI_SPEED Useful for setting SPI max clock No (default to 8, unique alternative provided is 2) FIXED_STATION_EUI Provides the ability to start the Basics Station with a fixed EUI No (if not set, the Basics Station built-in logic will be used for generating a EUI) STATION_PATH A string identifying the path of the folder where the compiled station.std binary for Basics Station is located No (if not set, defaults to /basicstation folder) LOG_LEVEL A string setting the desired log level for the Basics Station binary. Allowed values: XDEBUG,DEBUG,VERBOSE,INFO,NOTICE,WARNING,ERROR,CRITICAL No (if not set, defaults to INFO) LOCAL_DEVELOPMENT A boolean indicating whether the Network Server is running locally in Visual Studio for debugging purposes No (if not set, defaults to False)","title":"LBS IoT Edge Module configuration"},{"location":"user-guide/troubleshooting/","text":"Troubleshooting Failed to load fw If you see the following logs in your basic station: [load_firmware:219] Failed to load fw 1 [lgw_start:841] Version of calibration firmware not expected, actual:0 expected:2 Concentrator start failed: lgw_start ral_config failed with status 0x08 Closing connection to muxs - error in s2e_onMsg It could be that your reset pin is already used. To fix the problem, you can give the functionality of your reset pin to another pin. For that, you need to add a dtoverlay entry to your /boot/config.txt file. Example: Let's say your reset pin is 7. We can see in this documentation that by default, GPIO 7 is the Chip select 1 pin for SPI0. With dtoverlay , you can change the chip select 1 pin to be GPIO 25 by adding this line to the /boot/config.txt file: dtoverlay=spi0-cs,cs1_pin=25 We choose 25 here but you should choose a free pin.","title":"Troubleshooting"},{"location":"user-guide/troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"user-guide/troubleshooting/#failed-to-load-fw","text":"If you see the following logs in your basic station: [load_firmware:219] Failed to load fw 1 [lgw_start:841] Version of calibration firmware not expected, actual:0 expected:2 Concentrator start failed: lgw_start ral_config failed with status 0x08 Closing connection to muxs - error in s2e_onMsg It could be that your reset pin is already used. To fix the problem, you can give the functionality of your reset pin to another pin. For that, you need to add a dtoverlay entry to your /boot/config.txt file. Example: Let's say your reset pin is 7. We can see in this documentation that by default, GPIO 7 is the Chip select 1 pin for SPI0. With dtoverlay , you can change the chip select 1 pin to be GPIO 25 by adding this line to the /boot/config.txt file: dtoverlay=spi0-cs,cs1_pin=25 We choose 25 here but you should choose a free pin.","title":"Failed to load fw"},{"location":"user-guide/upgrade/","text":"Upgrade to a new version Release 2.0.0-alpha (not released yet) With release 2.0.0 we will use .NET 6 for the starter kit. Our docker images will be based on Debian 11 (Bullseye). Please make sure that if you plan to use our Docker images, you use a Debian 11-based OS instead of Debian 10. If you plan to use a Debian 10-based OS on an ARM device, you might need to build a custom Docker image. Upgrading to Raspberry Pi OS (bullseye) If you are running IoT Edge on a Raspberry Pi that is based on Debian 10 (Buster), we recommend that you download a new version of the image and perform a clean install. After you installed the latest version of Raspberry Pi OS, execute the following commands to install IoT Edge: curl https://packages.microsoft.com/config/debian/11/packages-microsoft-prod.deb > ./packages-microsoft-prod.deb sudo apt-get install ./packages-microsoft-prod.deb sudo apt-get update sudo apt-get install moby-engine curl -L https://github.com/Azure/azure-iotedge/releases/download/1.2.5/aziot-identity-service_1.2.4-1_debian11_armhf.deb -o aziot-identity-service.deb && sudo apt-get install ./aziot-identity-service.deb curl -L https://github.com/Azure/azure-iotedge/releases/download/1.2.5/aziot-edge_1.2.5-1_debian11_armhf.deb -o aziot-edge.deb && sudo apt-get install ./aziot-edge.deb If you want to install specific versions of IoT Edge that differ from the abovementioned versions, refer to offline or specific version installation . If you do not want to perform a clean install of Raspberry OS but instead want to upgrade an existing image, you can consider using the following commands to perform a full upgrade. Please note that this is not recommended, it might leave you with a broken installation. Update the /etc/apt/sources.list file and replace all occurrences of buster with bullseye . Do the same for any list file in /etc/apt/sources.list.d . Then run: sudo apt-get update sudo apt install libgcc-8-dev gcc-8-base sudo apt-get full-upgrade sudo apt autoremove sudo reboot After your Pi was upgraded to the latest Raspberry Pi OS, run the following steps to uninstall the old versions of IoT Edge and then continue with the install of IoT Edge as described above. After you finish the abovementioned install steps, please make sure to run another sudo apt-get upgrade to install the latest versions of the moby dependencies. sudo apt-get remove aziot-edge aziot-identity-service moby-engine Azure Functions To support .NET 6 you will need to upgrade the Azure Functions runtime to v4. To update, you can set FUNCTIONS_EXTENSION_VERSION to ~4 in your Function configuration. Release 1.0.7 To update from version 1.0.6, 1.0.5, 1.0.4 or 1.0.3 you can follow the below instructions. If you want to update manually from a version prior to 1.0.3, please refer to the instructions in the Release 1.0.3 section below. Update the IoT Edge security daemon when upgrading from IoT Edge 1.1 (release prior to 1.0.6) Since release 1.0.6, the starter kit uses Azure IoT Edge version 1.2 which includes major changes the the IoT Edge Security daemon. Please follow this documentation to Update IoT Edge to upgrade Azure IoT Edge to 1.2. Updating from release post 1.0.3 Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.7 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.7 On the same Set Modules page, also update your current edge version to 1.2.2 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.2.2 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.2.2 and mcr.microsoft.com/azureiotedge-agent:1.2.2. Updating the Azure Function Facade If you are upgrading from release 1.0.5, There are no changes on the Azure function therefore you can use the same bin. If you are upgrading from a previous release please follow function deployment guidance under release Release 1.0.5 . Release 1.0.6 To update from version 1.0.5, 1.0.4 or 1.0.3 you can follow the below instructions. If you want to update manually from a version prior to 1.0.3, please refer to the instructions in the Release 1.0.3 section below. Update the IoT Edge security daemon when upgrading from IoT Edge 1.1 Since release 1.0.6, the starter kit uses Azure IoT Edge version 1.2 which includes major changes the the IoT Edge Security daemon. Please follow this documentation to Update IoT Edge to upgrade Azure IoT Edge to 1.2. Updating from 1.0.5, 1.0.4 or 1.0.3 Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.6 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.6 On the same Set Modules page, also update your current edge version to 1.2.2 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.2.2 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.2.2 and mcr.microsoft.com/azureiotedge-agent:1.2.2. Updating the Azure Function Facade There are no changes on the Azure function therefore you can use the same versioning as Release 1.0.5 just below. Release 1.0.5 To update from version 1.0.4 or 1.0.3 you can follow the below instructions. If you want to update manually from a version prior to 1.0.3, please refer to the instructions in the Release 1.0.3 section below. Updating from 1.0.4 or 1.0.3 Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.5 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.5 On the same Set Modules page, also update your current edge version to 1.0.9.5 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.0.9.5 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.0.9.5 and mcr.microsoft.com/azureiotedge-agent:1.0.9.5. Updating the Azure Function Facade If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.5/function-1.0.5.zip Release 1.0.4 To update from version 1.0.3 you can follow the below instructions. If you want to update manually from a version prior to 1.0.3, please refer to the instructions in the Release 1.0.3 section below. Updating from 1.0.3 Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.4 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.4 On the same Set Modules page, also update your current edge version to 1.0.9.4 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.0.9.4 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.0.9.4 and mcr.microsoft.com/azureiotedge-agent:1.0.9.4. Updating the Azure Function Facade If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.4/function-1.0.4.zip Release 1.0.3 To update from 1.0.1 or 1.0.2 you can follow the below instructions. If you want to update manually from a version prior to 1.0.1, please refer to Updating existing installations from 1.0.0 to release 1.0.1 section below. Updating existing installations from 1.0.1 or 1.0.2 to release 1.0.3 Go to your solution's Azure IoT Hub and under IoT Edge, select each of your gateways. Select Set Modules and configure the two deployment modules LoRaWanNetworkSrvModule and LoRaWanPktFwdModule . Make sure, the following image URIs are configured: Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.3 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.3 On the same Set Modules page, also update your current edge version to 1.0.9 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.0.9 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.0.9 and mcr.microsoft.com/azureiotedge-agent:1.0.9. Updating the Azure Function Facade If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.3/function-1.0.3.zip Release 1.0.2 We recommend re-deploying your solution based on the 1.0.2 release if you have been working with a solution before version 1.0.2. To update from 1.0.1 you can follow the below instructions. If you want to update manually from a version prior to 1.0.1, please refer to Updating existing installations from 1.0.0 to release 1.0.1 section below. Updating existing installations from 1.0.1 to release 1.0.2 Go to your solution's Azure IoT Hub and under IoT Edge, select each of your gateways. Select Set Modules and configure the two deployment modules LoRaWanNetworkSrvModule and LoRaWanPktFwdModule . Make sure, the following image URIs are configured: Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.2 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.2 On the same Set Modules page, also update your current edge version to 1.0.7 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.0.7 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.0.7 and mcr.microsoft.com/azureiotedge-agent:1.0.7. Updating the Azure Function Facade If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.2/function-1.0.2.zip Release 1.0.1 We recommend re-deploying your solution based on the 1.0.1 release if you have been working with a pre-release version. If you prefer to update your existing installation, the following lists describes the required steps. Updating existing installations from 1.0.0 to release 1.0.1 Updating your gateways' IoT Edge module versions Go to your solution's Azure IoT Hub and under IoT Edge, select each of your gateways. Select Set Modules and configure the two deployment modules LoRaWanNetworkSrvModule and LoRaWanPktFwdModule . Make sure, the following image URIs are configured: Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.1 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.1 Updating the Azure Function Facade If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.1/function-1.0.1.zip Edit the Function's Application settings and make sure the FUNCTIONS_EXTENSION_VERSION App setting is set to ~2 . If during a previous upgrade you manually set it to 2.0.12342.0 , please change it back to ~2 . App Settings Name Value FUNCTIONS_EXTENSION_VERSION ~2 Make sure the IoT Hub and Redis connection strings are properly configured in the function. Updating existing installations from 0.4.0-preview to release 1.0.0 Updating the Azure Function Facade If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.0/function-1.0.0.zip Edit the Function's Application settings and change the FUNCTIONS_EXTENSION_VERSION App setting from ~2 to 2.0.12342.0 App Settings Name Value FUNCTIONS_EXTENSION_VERSION 2.0.12342.0 Make sure the IoT Hub and Redis connection strings are properly configured in the function. Updating existing installations from 0.3.0-preview to 0.4.0-preview Updating IoT Edge Runtime Containers to Version 1.0.6 We highly recommend running the latest version of the IoT Edge runtime containers on your gateway to Version 1.0.6. The way that you update the IoT Edge agent and IoT Edge hub containers depends on whether you use rolling tags (like 1.0) or specific tags (like 1.0.2) in your deployment. The process is outlined in detail here . Furthermore, make sure, the following environment variables are set for your Edge hub container: mqttSettings__enabled: false httpSettings__enabled: false TwinManagerVersion: v2 You do this by clicking \"Set Modules\" \u2192 \"Configure advanced edge runtime settings\" on your IoT Edge device in Azure IoT Hub. Make sure the DevAddr of your ABP LoRa devices starts with \"02\" : Due to addition of NetId support in this pre-relese, ABP devices created by the template prior to 0.4.0-preview (and all devices with an incompatible NetId in general) will be incompatible with the 0.4.0-preview. In this case, make sure the DevAddr of your ABP LoRa devices starts with \"02\". Updating the Azure Function Facade Re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. Make sure the IoT Hub and Redis connection strings are properly configured in the function. Updating existing installations from 0.2.0-preview to 0.3.0-preview Updating IoT Edge Runtime Containers to Version 1.0.5 We highly recommend running the latest version of the IoT Edge runtime containers on your gateway (Version 1.0.5 at the time of writing). The way that you update the IoT Edge agent and IoT Edge hub containers depends on whether you use rolling tags (like 1.0) or specific tags (like 1.0.2) in your deployment. The process is outlined in detail here . Updating the Azure Function Facade Re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. Make sure the IoT Hub and Redis connection strings are properly configured in the function.","title":"Upgrade to a new version"},{"location":"user-guide/upgrade/#upgrade-to-a-new-version","text":"","title":"Upgrade to a new version"},{"location":"user-guide/upgrade/#release-200-alpha-not-released-yet","text":"With release 2.0.0 we will use .NET 6 for the starter kit. Our docker images will be based on Debian 11 (Bullseye). Please make sure that if you plan to use our Docker images, you use a Debian 11-based OS instead of Debian 10. If you plan to use a Debian 10-based OS on an ARM device, you might need to build a custom Docker image.","title":"Release 2.0.0-alpha (not released yet)"},{"location":"user-guide/upgrade/#upgrading-to-raspberry-pi-os-bullseye","text":"If you are running IoT Edge on a Raspberry Pi that is based on Debian 10 (Buster), we recommend that you download a new version of the image and perform a clean install. After you installed the latest version of Raspberry Pi OS, execute the following commands to install IoT Edge: curl https://packages.microsoft.com/config/debian/11/packages-microsoft-prod.deb > ./packages-microsoft-prod.deb sudo apt-get install ./packages-microsoft-prod.deb sudo apt-get update sudo apt-get install moby-engine curl -L https://github.com/Azure/azure-iotedge/releases/download/1.2.5/aziot-identity-service_1.2.4-1_debian11_armhf.deb -o aziot-identity-service.deb && sudo apt-get install ./aziot-identity-service.deb curl -L https://github.com/Azure/azure-iotedge/releases/download/1.2.5/aziot-edge_1.2.5-1_debian11_armhf.deb -o aziot-edge.deb && sudo apt-get install ./aziot-edge.deb If you want to install specific versions of IoT Edge that differ from the abovementioned versions, refer to offline or specific version installation . If you do not want to perform a clean install of Raspberry OS but instead want to upgrade an existing image, you can consider using the following commands to perform a full upgrade. Please note that this is not recommended, it might leave you with a broken installation. Update the /etc/apt/sources.list file and replace all occurrences of buster with bullseye . Do the same for any list file in /etc/apt/sources.list.d . Then run: sudo apt-get update sudo apt install libgcc-8-dev gcc-8-base sudo apt-get full-upgrade sudo apt autoremove sudo reboot After your Pi was upgraded to the latest Raspberry Pi OS, run the following steps to uninstall the old versions of IoT Edge and then continue with the install of IoT Edge as described above. After you finish the abovementioned install steps, please make sure to run another sudo apt-get upgrade to install the latest versions of the moby dependencies. sudo apt-get remove aziot-edge aziot-identity-service moby-engine","title":"Upgrading to Raspberry Pi OS (bullseye)"},{"location":"user-guide/upgrade/#azure-functions","text":"To support .NET 6 you will need to upgrade the Azure Functions runtime to v4. To update, you can set FUNCTIONS_EXTENSION_VERSION to ~4 in your Function configuration.","title":"Azure Functions"},{"location":"user-guide/upgrade/#release-107","text":"To update from version 1.0.6, 1.0.5, 1.0.4 or 1.0.3 you can follow the below instructions. If you want to update manually from a version prior to 1.0.3, please refer to the instructions in the Release 1.0.3 section below.","title":"Release 1.0.7"},{"location":"user-guide/upgrade/#update-the-iot-edge-security-daemon-when-upgrading-from-iot-edge-11-release-prior-to-106","text":"Since release 1.0.6, the starter kit uses Azure IoT Edge version 1.2 which includes major changes the the IoT Edge Security daemon. Please follow this documentation to Update IoT Edge to upgrade Azure IoT Edge to 1.2.","title":"Update the IoT Edge security daemon when upgrading from IoT Edge 1.1 (release prior to 1.0.6)"},{"location":"user-guide/upgrade/#updating-from-release-post-103","text":"Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.7 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.7 On the same Set Modules page, also update your current edge version to 1.2.2 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.2.2 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.2.2 and mcr.microsoft.com/azureiotedge-agent:1.2.2.","title":"Updating from release post 1.0.3"},{"location":"user-guide/upgrade/#updating-the-azure-function-facade","text":"If you are upgrading from release 1.0.5, There are no changes on the Azure function therefore you can use the same bin. If you are upgrading from a previous release please follow function deployment guidance under release Release 1.0.5 .","title":"Updating the Azure Function Facade"},{"location":"user-guide/upgrade/#release-106","text":"To update from version 1.0.5, 1.0.4 or 1.0.3 you can follow the below instructions. If you want to update manually from a version prior to 1.0.3, please refer to the instructions in the Release 1.0.3 section below.","title":"Release 1.0.6"},{"location":"user-guide/upgrade/#update-the-iot-edge-security-daemon-when-upgrading-from-iot-edge-11","text":"Since release 1.0.6, the starter kit uses Azure IoT Edge version 1.2 which includes major changes the the IoT Edge Security daemon. Please follow this documentation to Update IoT Edge to upgrade Azure IoT Edge to 1.2.","title":"Update the IoT Edge security daemon when upgrading from IoT Edge 1.1"},{"location":"user-guide/upgrade/#updating-from-105-104-or-103","text":"Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.6 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.6 On the same Set Modules page, also update your current edge version to 1.2.2 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.2.2 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.2.2 and mcr.microsoft.com/azureiotedge-agent:1.2.2.","title":"Updating from 1.0.5, 1.0.4 or 1.0.3"},{"location":"user-guide/upgrade/#updating-the-azure-function-facade_1","text":"There are no changes on the Azure function therefore you can use the same versioning as Release 1.0.5 just below.","title":"Updating the Azure Function Facade"},{"location":"user-guide/upgrade/#release-105","text":"To update from version 1.0.4 or 1.0.3 you can follow the below instructions. If you want to update manually from a version prior to 1.0.3, please refer to the instructions in the Release 1.0.3 section below.","title":"Release 1.0.5"},{"location":"user-guide/upgrade/#updating-from-104-or-103","text":"Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.5 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.5 On the same Set Modules page, also update your current edge version to 1.0.9.5 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.0.9.5 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.0.9.5 and mcr.microsoft.com/azureiotedge-agent:1.0.9.5.","title":"Updating from 1.0.4 or 1.0.3"},{"location":"user-guide/upgrade/#updating-the-azure-function-facade_2","text":"If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.5/function-1.0.5.zip","title":"Updating the Azure Function Facade"},{"location":"user-guide/upgrade/#release-104","text":"To update from version 1.0.3 you can follow the below instructions. If you want to update manually from a version prior to 1.0.3, please refer to the instructions in the Release 1.0.3 section below.","title":"Release 1.0.4"},{"location":"user-guide/upgrade/#updating-from-103","text":"Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.4 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.4 On the same Set Modules page, also update your current edge version to 1.0.9.4 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.0.9.4 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.0.9.4 and mcr.microsoft.com/azureiotedge-agent:1.0.9.4.","title":"Updating from 1.0.3"},{"location":"user-guide/upgrade/#updating-the-azure-function-facade_3","text":"If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.4/function-1.0.4.zip","title":"Updating the Azure Function Facade"},{"location":"user-guide/upgrade/#release-103","text":"To update from 1.0.1 or 1.0.2 you can follow the below instructions. If you want to update manually from a version prior to 1.0.1, please refer to Updating existing installations from 1.0.0 to release 1.0.1 section below.","title":"Release 1.0.3"},{"location":"user-guide/upgrade/#updating-existing-installations-from-101-or-102-to-release-103","text":"Go to your solution's Azure IoT Hub and under IoT Edge, select each of your gateways. Select Set Modules and configure the two deployment modules LoRaWanNetworkSrvModule and LoRaWanPktFwdModule . Make sure, the following image URIs are configured: Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.3 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.3 On the same Set Modules page, also update your current edge version to 1.0.9 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.0.9 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.0.9 and mcr.microsoft.com/azureiotedge-agent:1.0.9.","title":"Updating existing installations from 1.0.1 or 1.0.2 to release 1.0.3"},{"location":"user-guide/upgrade/#updating-the-azure-function-facade_4","text":"If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.3/function-1.0.3.zip","title":"Updating the Azure Function Facade"},{"location":"user-guide/upgrade/#release-102","text":"We recommend re-deploying your solution based on the 1.0.2 release if you have been working with a solution before version 1.0.2. To update from 1.0.1 you can follow the below instructions. If you want to update manually from a version prior to 1.0.1, please refer to Updating existing installations from 1.0.0 to release 1.0.1 section below.","title":"Release 1.0.2"},{"location":"user-guide/upgrade/#updating-existing-installations-from-101-to-release-102","text":"Go to your solution's Azure IoT Hub and under IoT Edge, select each of your gateways. Select Set Modules and configure the two deployment modules LoRaWanNetworkSrvModule and LoRaWanPktFwdModule . Make sure, the following image URIs are configured: Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.2 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.2 On the same Set Modules page, also update your current edge version to 1.0.7 by pressing the Configure Advanced Edge Runtime settings button. On the menu, ensure the edge hub and edge agent are using version 1.0.7 by respectively setting image name to mcr.microsoft.com/azureiotedge-hub:1.0.7 and mcr.microsoft.com/azureiotedge-agent:1.0.7.","title":"Updating existing installations from 1.0.1 to release 1.0.2"},{"location":"user-guide/upgrade/#updating-the-azure-function-facade_5","text":"If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.2/function-1.0.2.zip","title":"Updating the Azure Function Facade"},{"location":"user-guide/upgrade/#release-101","text":"We recommend re-deploying your solution based on the 1.0.1 release if you have been working with a pre-release version. If you prefer to update your existing installation, the following lists describes the required steps.","title":"Release 1.0.1"},{"location":"user-guide/upgrade/#updating-existing-installations-from-100-to-release-101","text":"","title":"Updating existing installations from 1.0.0 to release 1.0.1"},{"location":"user-guide/upgrade/#updating-your-gateways-iot-edge-module-versions","text":"Go to your solution's Azure IoT Hub and under IoT Edge, select each of your gateways. Select Set Modules and configure the two deployment modules LoRaWanNetworkSrvModule and LoRaWanPktFwdModule . Make sure, the following image URIs are configured: Deployment Module Image URI LoRaWanNetworkSrvModule loraedge/lorawannetworksrvmodule:1.0.1 LoRaWanPktFwdModule loraedge/lorawanpktfwdmodule:1.0.1","title":"Updating your gateways' IoT Edge module versions"},{"location":"user-guide/upgrade/#updating-the-azure-function-facade_6","text":"If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.1/function-1.0.1.zip Edit the Function's Application settings and make sure the FUNCTIONS_EXTENSION_VERSION App setting is set to ~2 . If during a previous upgrade you manually set it to 2.0.12342.0 , please change it back to ~2 . App Settings Name Value FUNCTIONS_EXTENSION_VERSION ~2 Make sure the IoT Hub and Redis connection strings are properly configured in the function.","title":"Updating the Azure Function Facade"},{"location":"user-guide/upgrade/#updating-existing-installations-from-040-preview-to-release-100","text":"","title":"Updating existing installations from 0.4.0-preview to release 1.0.0"},{"location":"user-guide/upgrade/#updating-the-azure-function-facade_7","text":"If you have manually deployed the Azure Function, re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. If you have deployed the solution and with it the Azure Function through the Azure Resource Manager template, you will see an App Setting in the function with the name \"WEBSITE_RUN_FROM_ZIP\". Update it's value to: https://github.com/Azure/iotedge-lorawan-starterkit/releases/download/v1.0.0/function-1.0.0.zip Edit the Function's Application settings and change the FUNCTIONS_EXTENSION_VERSION App setting from ~2 to 2.0.12342.0 App Settings Name Value FUNCTIONS_EXTENSION_VERSION 2.0.12342.0 Make sure the IoT Hub and Redis connection strings are properly configured in the function.","title":"Updating the Azure Function Facade"},{"location":"user-guide/upgrade/#updating-existing-installations-from-030-preview-to-040-preview","text":"","title":"Updating existing installations from 0.3.0-preview to 0.4.0-preview"},{"location":"user-guide/upgrade/#updating-iot-edge-runtime-containers-to-version-106","text":"We highly recommend running the latest version of the IoT Edge runtime containers on your gateway to Version 1.0.6. The way that you update the IoT Edge agent and IoT Edge hub containers depends on whether you use rolling tags (like 1.0) or specific tags (like 1.0.2) in your deployment. The process is outlined in detail here . Furthermore, make sure, the following environment variables are set for your Edge hub container: mqttSettings__enabled: false httpSettings__enabled: false TwinManagerVersion: v2 You do this by clicking \"Set Modules\" \u2192 \"Configure advanced edge runtime settings\" on your IoT Edge device in Azure IoT Hub. Make sure the DevAddr of your ABP LoRa devices starts with \"02\" : Due to addition of NetId support in this pre-relese, ABP devices created by the template prior to 0.4.0-preview (and all devices with an incompatible NetId in general) will be incompatible with the 0.4.0-preview. In this case, make sure the DevAddr of your ABP LoRa devices starts with \"02\".","title":"Updating IoT Edge Runtime Containers to Version 1.0.6"},{"location":"user-guide/upgrade/#updating-the-azure-function-facade_8","text":"Re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. Make sure the IoT Hub and Redis connection strings are properly configured in the function.","title":"Updating the Azure Function Facade"},{"location":"user-guide/upgrade/#updating-existing-installations-from-020-preview-to-030-preview","text":"","title":"Updating existing installations from 0.2.0-preview to 0.3.0-preview"},{"location":"user-guide/upgrade/#updating-iot-edge-runtime-containers-to-version-105","text":"We highly recommend running the latest version of the IoT Edge runtime containers on your gateway (Version 1.0.5 at the time of writing). The way that you update the IoT Edge agent and IoT Edge hub containers depends on whether you use rolling tags (like 1.0) or specific tags (like 1.0.2) in your deployment. The process is outlined in detail here .","title":"Updating IoT Edge Runtime Containers to Version 1.0.5"},{"location":"user-guide/upgrade/#updating-the-azure-function-facade_9","text":"Re-deploy the updated version of the Azure Function Facade as outlined here if you have a previous version of this Azure Function running. Make sure the IoT Hub and Redis connection strings are properly configured in the function.","title":"Updating the Azure Function Facade"},{"location":"user-guide/testing/e2e_tests/","text":"E2E Tests This guide helps you to execute and author E2E tests on your local environment. Requirements +----------+ | | Dev | A | Machine | +------------+ | | | IoT Edge | +----------+ ) | LBS/PktFwd | | ) ) | NtwSrv | | (usb) | ) ) ) +------------+ | A ) ) +---------+ ) | Arduino | +---------+ LoRaWan solution up and running (IoT Edge Device, IoT Hub, LoRa Keys Azure Function, Redis, container registry etc.) Seeeduino LoRaWan device (leaf test device) connected via USB to a computer where the LoRaWan.Tests.E2E will run. Module LoRaWanNetworkSrvModule logging configured with following environment variables: LOG_LEVEL: 1 LOG_TO_TCP: true LOG_TO_TCP_ADDRESS: development machine IP address (ensure IoT Edge machine can ping it) E2E test configuration (in file appsettings.local.json ) has TCP logging enabled \"TcpLog\": \"true\" Setup LoRa Basics Station and Network Server setup Configure LoRa Basics Station and Network Server to run on your concentrator: Copy LoRaEngine/example.env file and name it .env . * Update Container Registry settings and facade function app section with details of your created registry and function app. * Update LoRaWanNetworkSrvModule settings: ```bash NET_SRV_LOG_LEVEL=1 NET_SRV_LOGTO_HUB=true NET_SRV_LOG_TO_TCP=true NET_SRV_LOG_TO_TCP_ADDRESS=<your-local-ip-address> ``` * Update LBS_TC_URI : `LBS_TC_URI=ws://172.17.0.1:5000` Build and push IoT Edge solution to your container registry using LoRaEngine/deployment.lbs.template.json file. In VS Code: Ctrl+Shift+P -> Azure IoT Edge: Bild and Push IoT Edge Solution -> select template file. Create deployment for a single device using generated deployment template. In VS Code, right-click on LoRaEngine/config/deployment.lbs.json and select Create Deployment for Single Device. Provision a device in your IoT Hub by following the Basics Station configuration docs. End device setup Connect and setup Seeduino Arduino with the serial pass sketch void setup () { Serial1 . begin ( 9600 ); SerialUSB . begin ( 115200 ); } void loop () { while ( Serial1 . available ()) { SerialUSB . write ( Serial1 . read ()); } while ( SerialUSB . available ()) { Serial1 . write ( SerialUSB . read ()); } } E2E test configuration Create/edit E2E settings in file appsettings.local.json The value of LeafDeviceSerialPort in Windows will be the COM port where the Arduino board is connected to (Arduino IDE displays it). On macos you can discover through ls /dev/tty* and/or ls /dev/cu* bash commands. On Linux you can discover them with ls /dev/ttyACM* . { \"testConfiguration\" : { \"IoTHubEventHubConnectionString\" : \"Endpoint=sb://xxxx.servicebus.windows.net/;SharedAccessKeyName=iothubowner;SharedAccessKey=xxx;EntityPath=xxxxx\" , \"IoTHubEventHubConsumerGroup\" : \"your-iothub-consumer-group\" , \"IoTHubConnectionString\" : \"HostName=xxxx.azure-devices.net;SharedAccessKeyName=iothubowner;SharedAccessKey=xxx\" , \"EnsureHasEventDelayBetweenReadsInSeconds\" : \"15\" , \"EnsureHasEventMaximumTries\" : \"5\" , \"LeafDeviceSerialPort\" : \"your-usb-port\" , \"LeafDeviceGatewayID\" : \"your-iot-edge-device-id\" , \"CreateDevices\" : true , \"NetworkServerModuleLogAssertLevel\" : \"Error\" , \"DevicePrefix\" : \"your-two-letter-device-prefix\" , \"TcpLog\" : \"true\" , \"FunctionAppBaseUrl\" : \"https://your-function-app.azurewebsites.net/api/\" , \"FunctionAppCode\" : \"your-function-code=\" , \"TxPower\" : \"a-value-for-setting-arduino-tx-power\" , // following options are used and to be configured for MultiConcentrator and CUPS Test // where the Concentrator startup/shutdown is programmatically invoked in the test itself \"RunningInCI\" : \"should-be-false-if-not-running-with-e2e-ci\" , \"RemoteConcentratorConnection\" : \"username@remote-ssh-host\" , \"DefaultBasicStationEui\" : \"a-fixed-basic-station-eui-to-be-used\" , \"BasicStationExecutablePath\" : \"path-to-station-prebuilt-binary-on-remote-ssh-host\" , \"SshPrivateKeyPath\" : \"path-on-local-host-to-ssh-private-key-used-for-remote-ssh-connection\" , \"SharedLnsEndpoint\" : \"wss://IP_or_DNS:5001\" , \"SharedCupsEndpoint\" : \"https://IP_OR_DNS:5002\" , \"RadioDev\" : \"the-device-path-for-concentrator (i.e. /dev/ttyUSB0)\" , \"IsCorecellBasicStation\" : false // or true if a SX1302 based concentrator is used } } If the value of CreateDevices setting is true, running the tests will create/update devices in IoT Hub prior to executing tests. Devices will be created starting with ID \"0000000000000001\". The deviceID prefix can be modified by setting a value in DevicePrefix setting ('FF' \u2192 'FF00000000000001'). Creating a new test Each test uses an unique device to ensure transmissions don't exceed LoRaWan regulations. Additionally, it makes it easier to track logs for each test. To create a new device modify the IntegrationTestFixture class by: Creating a new property of type TestDeviceInfo as (increment the device ids by 1): // Device13_OTAA: used for wrong AppEUI OTAA join public TestDeviceInfo Device13_OTAA { get ; private set ; } Create the TestDeviceInfo instance in IntegrationTestFixture.SetupDevices() method // Device13_OTAA: used for Join with wrong AppEUI Device13_OTAA = new TestDeviceInfo () { DeviceID = \"0000000000000013\" , AppEUI = \"BE7A00000000FEE3\" , AppKey = \"8AFE71A145B253E49C3031AD068277A3\" , SensorDecoder = \"DecoderValueSensor\" , // GatewayID property of the device GatewayID = gatewayID , // Indicates if the device exists in IoT Hub // Some tests don't require a device to actually exist IsIoTHubDevice = true , }; Create the test method / fact in a test class. If a new test class is needed (to group logically test) read the section 'Creating Test Class'). Code should be similar to this: // Tests using a invalid Network Session key, resulting in mic failed // Uses Device8_ABP [Fact] public async Task Test_ABP_Invalid_NwkSKey_Fails_With_Mic_Error () { var device = TestFixture . Device8_ABP ; LogTestStart ( device ); var nwkSKeyToUse = \"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\" ; Assert . NotEqual ( nwkSKeyToUse , device . NwkSKey ); await ArduinoDevice . setDeviceModeAsync ( LoRaArduinoSerial . _device_mode_t . LWABP ); await ArduinoDevice . setIdAsync ( device . DevAddr , device . DeviceID , null ); await ArduinoDevice . setKeyAsync ( nwkSKeyToUse , device . AppSKey , null ); await ArduinoDevice . SetupLora ( TestFixture . Configuration . LoraRegion ); await ArduinoDevice . transferPacketAsync ( \"100\" , 10 ); // THIS DELAY IS IMPORTANT! // Don't pollute radio transmission channel await Task . Delay ( Constants . DELAY_FOR_SERIAL_AFTER_SENDING_PACKET ); // Add here test logic } Creating Test Class E2E tests cannot be parallelized because they all share dependency to Arduino device. Those classes also rely on TCP and IoT Event Hub listeners that should be created once per test execution, not per test. Therefore, when creating a new test class follow the guidelines: Use attribute [Collection(Constants.TestCollectionName)] to ensure executing in serial inherit from IntegrationTestBase . Create a single constructor receiving a IntegrationTestFixture as parameter. Call the base class constructor passing the parameter. Example: // Tests xxxx [Collection(Constants.TestCollectionName)] // Set the same collection to ensure execution in serial public sealed class MyTest : IntegrationTestBase { // Constructor receives the IntegrationTestFixture that is a singleton public MyTest ( IntegrationTestFixture testFixture ) : base ( testFixture ) { } } Asserting Assertions and expectations are implemented in 3 levels. Arduino Serial logs Serial logs from Arduino allow test cases to ensure the leaf device is receiving the correct response from the antena (LoRaPktFwd module). Checks can be done the following way: // After transferPacketWithConfirmed: Expectation from serial \"+CMSG: ACK Received\" // It has retries to account for i/o delays await AssertUtils . ContainsWithRetriesAsync ( \"+CMSG: ACK Received\" , ArduinoDevice . SerialLogs ); LoRaWan Network Server Module logs The network server module logs important execution steps. Those messages can be used to ensure expected actions happened in the network server module. This validation creates a tight dependency between tests and logging. We might need to reavaluate it if the friction between code changes and breaking tests gets too high. An option is to have the Network server publish events when an operation happens and have the test create assertion on them (i.e. { \"type\": \"otaajoin\", \"status\": \"succeeded\", \"deviceid\": \"xxx\", \"time\": \"a-date\" } ). Module logs can be listened from IoT Hub or TCP (experimental). Validating against the module logs. // Ensures that the message 0000000000000004: message '{\"value\": 51}' sent to hub is logged // It contains retries to account for i/o delays await TestFixture . AssertNetworkServerModuleLogStartsWithAsync ( $\"{device.DeviceID}: message '{{\\\"value\\\":{msg}}}' sent to hub\" ); IoT Hub Device Message For end to end validation we listen for device messages arriving in IoT Hub. Examples: // Ensure device payload is available. It contains retries to account for i/o delays // Data: {\"value\": 51} var expectedPayload = $\"{{\\\"value\\\":{msg}}}\" ; await TestFixture . AssertIoTHubDeviceMessageExistsAsync ( device . DeviceID , expectedPayload );","title":"E2E Tests"},{"location":"user-guide/testing/e2e_tests/#e2e-tests","text":"This guide helps you to execute and author E2E tests on your local environment.","title":"E2E Tests"},{"location":"user-guide/testing/e2e_tests/#requirements","text":"+----------+ | | Dev | A | Machine | +------------+ | | | IoT Edge | +----------+ ) | LBS/PktFwd | | ) ) | NtwSrv | | (usb) | ) ) ) +------------+ | A ) ) +---------+ ) | Arduino | +---------+ LoRaWan solution up and running (IoT Edge Device, IoT Hub, LoRa Keys Azure Function, Redis, container registry etc.) Seeeduino LoRaWan device (leaf test device) connected via USB to a computer where the LoRaWan.Tests.E2E will run. Module LoRaWanNetworkSrvModule logging configured with following environment variables: LOG_LEVEL: 1 LOG_TO_TCP: true LOG_TO_TCP_ADDRESS: development machine IP address (ensure IoT Edge machine can ping it) E2E test configuration (in file appsettings.local.json ) has TCP logging enabled \"TcpLog\": \"true\"","title":"Requirements"},{"location":"user-guide/testing/e2e_tests/#setup","text":"","title":"Setup"},{"location":"user-guide/testing/e2e_tests/#lora-basics-station-and-network-server-setup","text":"Configure LoRa Basics Station and Network Server to run on your concentrator: Copy LoRaEngine/example.env file and name it .env . * Update Container Registry settings and facade function app section with details of your created registry and function app. * Update LoRaWanNetworkSrvModule settings: ```bash NET_SRV_LOG_LEVEL=1 NET_SRV_LOGTO_HUB=true NET_SRV_LOG_TO_TCP=true NET_SRV_LOG_TO_TCP_ADDRESS=<your-local-ip-address> ``` * Update LBS_TC_URI : `LBS_TC_URI=ws://172.17.0.1:5000` Build and push IoT Edge solution to your container registry using LoRaEngine/deployment.lbs.template.json file. In VS Code: Ctrl+Shift+P -> Azure IoT Edge: Bild and Push IoT Edge Solution -> select template file. Create deployment for a single device using generated deployment template. In VS Code, right-click on LoRaEngine/config/deployment.lbs.json and select Create Deployment for Single Device. Provision a device in your IoT Hub by following the Basics Station configuration docs.","title":"LoRa Basics Station and Network Server setup"},{"location":"user-guide/testing/e2e_tests/#end-device-setup","text":"Connect and setup Seeduino Arduino with the serial pass sketch void setup () { Serial1 . begin ( 9600 ); SerialUSB . begin ( 115200 ); } void loop () { while ( Serial1 . available ()) { SerialUSB . write ( Serial1 . read ()); } while ( SerialUSB . available ()) { Serial1 . write ( SerialUSB . read ()); } }","title":"End device setup"},{"location":"user-guide/testing/e2e_tests/#e2e-test-configuration","text":"Create/edit E2E settings in file appsettings.local.json The value of LeafDeviceSerialPort in Windows will be the COM port where the Arduino board is connected to (Arduino IDE displays it). On macos you can discover through ls /dev/tty* and/or ls /dev/cu* bash commands. On Linux you can discover them with ls /dev/ttyACM* . { \"testConfiguration\" : { \"IoTHubEventHubConnectionString\" : \"Endpoint=sb://xxxx.servicebus.windows.net/;SharedAccessKeyName=iothubowner;SharedAccessKey=xxx;EntityPath=xxxxx\" , \"IoTHubEventHubConsumerGroup\" : \"your-iothub-consumer-group\" , \"IoTHubConnectionString\" : \"HostName=xxxx.azure-devices.net;SharedAccessKeyName=iothubowner;SharedAccessKey=xxx\" , \"EnsureHasEventDelayBetweenReadsInSeconds\" : \"15\" , \"EnsureHasEventMaximumTries\" : \"5\" , \"LeafDeviceSerialPort\" : \"your-usb-port\" , \"LeafDeviceGatewayID\" : \"your-iot-edge-device-id\" , \"CreateDevices\" : true , \"NetworkServerModuleLogAssertLevel\" : \"Error\" , \"DevicePrefix\" : \"your-two-letter-device-prefix\" , \"TcpLog\" : \"true\" , \"FunctionAppBaseUrl\" : \"https://your-function-app.azurewebsites.net/api/\" , \"FunctionAppCode\" : \"your-function-code=\" , \"TxPower\" : \"a-value-for-setting-arduino-tx-power\" , // following options are used and to be configured for MultiConcentrator and CUPS Test // where the Concentrator startup/shutdown is programmatically invoked in the test itself \"RunningInCI\" : \"should-be-false-if-not-running-with-e2e-ci\" , \"RemoteConcentratorConnection\" : \"username@remote-ssh-host\" , \"DefaultBasicStationEui\" : \"a-fixed-basic-station-eui-to-be-used\" , \"BasicStationExecutablePath\" : \"path-to-station-prebuilt-binary-on-remote-ssh-host\" , \"SshPrivateKeyPath\" : \"path-on-local-host-to-ssh-private-key-used-for-remote-ssh-connection\" , \"SharedLnsEndpoint\" : \"wss://IP_or_DNS:5001\" , \"SharedCupsEndpoint\" : \"https://IP_OR_DNS:5002\" , \"RadioDev\" : \"the-device-path-for-concentrator (i.e. /dev/ttyUSB0)\" , \"IsCorecellBasicStation\" : false // or true if a SX1302 based concentrator is used } } If the value of CreateDevices setting is true, running the tests will create/update devices in IoT Hub prior to executing tests. Devices will be created starting with ID \"0000000000000001\". The deviceID prefix can be modified by setting a value in DevicePrefix setting ('FF' \u2192 'FF00000000000001').","title":"E2E test configuration"},{"location":"user-guide/testing/e2e_tests/#creating-a-new-test","text":"Each test uses an unique device to ensure transmissions don't exceed LoRaWan regulations. Additionally, it makes it easier to track logs for each test. To create a new device modify the IntegrationTestFixture class by: Creating a new property of type TestDeviceInfo as (increment the device ids by 1): // Device13_OTAA: used for wrong AppEUI OTAA join public TestDeviceInfo Device13_OTAA { get ; private set ; } Create the TestDeviceInfo instance in IntegrationTestFixture.SetupDevices() method // Device13_OTAA: used for Join with wrong AppEUI Device13_OTAA = new TestDeviceInfo () { DeviceID = \"0000000000000013\" , AppEUI = \"BE7A00000000FEE3\" , AppKey = \"8AFE71A145B253E49C3031AD068277A3\" , SensorDecoder = \"DecoderValueSensor\" , // GatewayID property of the device GatewayID = gatewayID , // Indicates if the device exists in IoT Hub // Some tests don't require a device to actually exist IsIoTHubDevice = true , }; Create the test method / fact in a test class. If a new test class is needed (to group logically test) read the section 'Creating Test Class'). Code should be similar to this: // Tests using a invalid Network Session key, resulting in mic failed // Uses Device8_ABP [Fact] public async Task Test_ABP_Invalid_NwkSKey_Fails_With_Mic_Error () { var device = TestFixture . Device8_ABP ; LogTestStart ( device ); var nwkSKeyToUse = \"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\" ; Assert . NotEqual ( nwkSKeyToUse , device . NwkSKey ); await ArduinoDevice . setDeviceModeAsync ( LoRaArduinoSerial . _device_mode_t . LWABP ); await ArduinoDevice . setIdAsync ( device . DevAddr , device . DeviceID , null ); await ArduinoDevice . setKeyAsync ( nwkSKeyToUse , device . AppSKey , null ); await ArduinoDevice . SetupLora ( TestFixture . Configuration . LoraRegion ); await ArduinoDevice . transferPacketAsync ( \"100\" , 10 ); // THIS DELAY IS IMPORTANT! // Don't pollute radio transmission channel await Task . Delay ( Constants . DELAY_FOR_SERIAL_AFTER_SENDING_PACKET ); // Add here test logic }","title":"Creating a new test"},{"location":"user-guide/testing/e2e_tests/#creating-test-class","text":"E2E tests cannot be parallelized because they all share dependency to Arduino device. Those classes also rely on TCP and IoT Event Hub listeners that should be created once per test execution, not per test. Therefore, when creating a new test class follow the guidelines: Use attribute [Collection(Constants.TestCollectionName)] to ensure executing in serial inherit from IntegrationTestBase . Create a single constructor receiving a IntegrationTestFixture as parameter. Call the base class constructor passing the parameter. Example: // Tests xxxx [Collection(Constants.TestCollectionName)] // Set the same collection to ensure execution in serial public sealed class MyTest : IntegrationTestBase { // Constructor receives the IntegrationTestFixture that is a singleton public MyTest ( IntegrationTestFixture testFixture ) : base ( testFixture ) { } }","title":"Creating Test Class"},{"location":"user-guide/testing/e2e_tests/#asserting","text":"Assertions and expectations are implemented in 3 levels.","title":"Asserting"},{"location":"user-guide/testing/e2e_tests/#arduino-serial-logs","text":"Serial logs from Arduino allow test cases to ensure the leaf device is receiving the correct response from the antena (LoRaPktFwd module). Checks can be done the following way: // After transferPacketWithConfirmed: Expectation from serial \"+CMSG: ACK Received\" // It has retries to account for i/o delays await AssertUtils . ContainsWithRetriesAsync ( \"+CMSG: ACK Received\" , ArduinoDevice . SerialLogs );","title":"Arduino Serial logs"},{"location":"user-guide/testing/e2e_tests/#lorawan-network-server-module-logs","text":"The network server module logs important execution steps. Those messages can be used to ensure expected actions happened in the network server module. This validation creates a tight dependency between tests and logging. We might need to reavaluate it if the friction between code changes and breaking tests gets too high. An option is to have the Network server publish events when an operation happens and have the test create assertion on them (i.e. { \"type\": \"otaajoin\", \"status\": \"succeeded\", \"deviceid\": \"xxx\", \"time\": \"a-date\" } ). Module logs can be listened from IoT Hub or TCP (experimental). Validating against the module logs. // Ensures that the message 0000000000000004: message '{\"value\": 51}' sent to hub is logged // It contains retries to account for i/o delays await TestFixture . AssertNetworkServerModuleLogStartsWithAsync ( $\"{device.DeviceID}: message '{{\\\"value\\\":{msg}}}' sent to hub\" );","title":"LoRaWan Network Server Module logs"},{"location":"user-guide/testing/e2e_tests/#iot-hub-device-message","text":"For end to end validation we listen for device messages arriving in IoT Hub. Examples: // Ensure device payload is available. It contains retries to account for i/o delays // Data: {\"value\": 51} var expectedPayload = $\"{{\\\"value\\\":{msg}}}\" ; await TestFixture . AssertIoTHubDeviceMessageExistsAsync ( device . DeviceID , expectedPayload );","title":"IoT Hub Device Message"},{"location":"user-guide/testing/integration_tests/","text":"Integration Tests Most of the integration tests can be run locally without any additional setup. However, a few of them depend on a local Redis instance. To run these integration tests locally, you can install Docker. Before the tests are executed, the test logic prepares a Redis Docker container (and it will automatically reuse/start it if you rerun these tests).","title":"Integration Tests"},{"location":"user-guide/testing/integration_tests/#integration-tests","text":"Most of the integration tests can be run locally without any additional setup. However, a few of them depend on a local Redis instance. To run these integration tests locally, you can install Docker. Before the tests are executed, the test logic prepares a Redis Docker container (and it will automatically reuse/start it if you rerun these tests).","title":"Integration Tests"},{"location":"user-guide/testing/load_tests/","text":"Load Tests The (simulated) load tests in LoRaWan.Tests.Simulation allow you to generate load on an arbitrary number of gateways by simulating an arbitrary number of concentrators. There are a number of load-test scenarios that are used to simulate real-world scenarios. Typically, you would want to use LNS components that are as close to a production scenario as possible (e.g. LNS deployed on VMs with the correct OS/SKUs in the cloud). You can then run these tests from your local machine to simulate many devices and many concentrators sending a large amount of messages to the gateways deployed in the cloud. Running the load tests In LoRaWan.Tests.Simulation you have access to a set of load tests that can be used to validate the performance of the system. If you have access, you can either run the load tests from the E2E CI by setting the RunLoadTests input parameter to true . Alternatively, you can run the tests on your local machine. If you decide to run the tests on your local machine, first to copy the appsettings.json from the Simulator project into a appsettings.local.json and make sure that this file is copied over to the output directory. Replace the tokens in the appsettings.local.json : To connect the load tests with a locally running LNS, replace the value in LoadTestLnsEndpointsString with something similar to {\"LoadTestLnsEndpointsString\":\"[\\\"ws://<lns-url>:5000\\\"]\"} . You can insert an arbitrary number of LNS stations into the array, and the load tests will connect stations to LNS using round-robin distribution. The DevicePrefix can be any prefix that is used for the test devices generating the load. If CreateDevices is set to true , it will create devices with this prefix in the IoT Hub that is referenced in your appsettings.local.json . Make sure that the LeafDeviceGatewayID matches the ID of one of the LNS that you connect to the load tests. Example load tests All load tests use the Connected_Factory_Load_Test_Scenario load test scenario. All example load tests below were tested against IoT Edge version 1.2.7. March 4th 2022, load test of v2.1.0 in gateway mode (ENABLE_GATEWAY=true) These tests were using gateway mode - passing through the edge hub queue. For all tests a IoT Hub S3 instance was used, devices were issueing 3 join requests per second and 5 upstream messages per second. edgeHub module Configuration Environment Variable Value OptimizeForPerformance true IotHubConnectionPoolSize 200 OptimizeForPerformance 5000 LoRaWanNetworkSrvModule Configuration Environment Variable Value IOTHUB_CONNECTION_POOL_SIZE 200 Succeeded IoT Hub SKU Gateway count Number of devices Concentrators per gateway Duration [min] Total messages sent Receive windows missed Avg message delivery time [ms] Note true S3 2 900 2 25 7200 0 500 true S3 2 1000 2 30 8000 0 500 failed S3 2 1500 2 - - - - With only 4 join attempts, some devices could not join true S3 2 1500 2 45 12000 160 (join requests) Increasing the join attempt count to 7 January 25th - 28th 2022, load test of v2.0.0-beta1 in gateway mode (ENABLE_GATEWAY=true) We ran a set of load tests to ensure that we can support a certain amount of LoRa devices. These tests were performed using gateway mode - passing through the edge hub queue. By taking into account these variables and KPI, we ran several load tests successfully with the parameters we used listed below. For all tests against an IoT Hub S1 instance, we ran at a rate of 1 join request per second and 1 upstream message during the cache pre-warm phase. For all IoT Hub S3 instances we use 3 join requests per second and 3 upstream messages per second during warm-up. Succeeded IoT Hub SKU Gateway count Number of devices Concentrators per gateway Duration [min] Total messages sent Receive windows missed Avg message delivery time [ms] Note true S1 2 40 2 4 1240 2 700 true S1 2 80 2 6 1680 2 650 false S1 2 120 2 - - - - true S1 1 140 4 10 2940 0 500 true S3 1 900 4 25 7200 0 500 false S3 1 1100 4 - - - - Issues encountered in these load tests: Unexpected ObjectDisposedException when IoT Hub is throttling \u00b7 Issue #6042 \u00b7 Azure/iotedge (github.com) In case of two gateways and many devices, we quickly run into limitations that come from the fact that IoT Edge is actively managing a cache for each device that connects to it, for which it requires an active connection. Since IoT Hub only allows a single connection per device, multiple Edge Hubs will start competing for the connection on a high frequency. This results in (what we refer to as) connection ping pong and limits scalability on the Edge itself as well as the IoT Hub (throttling). We plan to improve the situation by introducing connection affinity to preferred Edge Hubs in a subsequent release. The memory/CPU usage of a single IoT Edge host in gateway mode (for 900 devices) was fairly stable at around 1GB of memory used and an average CPU consumption of 40% on a Standard D2s v3 Debian 11 VM: January 21st 2022, load test of v2.0.0-beta1 in direct mode (ENABLE_GATEWAY=false) Warning Direct mode is not recommended for production use, as it has limitations with respect to message delivery guarantees. If you decide to use this, you may lose messages. This load test used the default deduplication strategy. First, we deployed two LNS on Standard D2s v3 Debian 11 VMs (2vCPU, 8GB of memory). We simulated 1600 OTAA devices, distributed among 8 factories with 4 concentrators each. All devices are in reach of all concentrators within the same factory and send 5 messages each, starting with a join rate of 1.5 messages per second and then progressively sending messages faster and faster (starting at 1.5 messages per second to pre-warm the cache and not hit IoT Hub S1 quota, and then successively increase the load to around 9.5 messages per second). Keep in mind that the effective message rate is higher than 9.5 messages per second, since every message is delivered to the gateways by the four concentrators per factory. The following bugs/issues became apparent in the load test: AMQP exceptions when running load tests \u00b7 Issue #1348 \u00b7 Azure/iotedge-lorawan-starterkit (github.com) AMQP exceptions when handling > 1000 devices \u00b7 Issue #1337 \u00b7 Azure/iotedge-lorawan-starterkit (github.com) We should send messages upstream when on DeduplicationStrategy Mark or None. \u00b7 Issue #1032 \u00b7 Azure/iotedge-lorawan-starterkit (github.com) Resubmit threshold does not consider deduplication strategy used \u00b7 Issue #1334 \u00b7 Azure/iotedge-lorawan-starterkit (github.com) Investigate memory evolution of LNS under load \u00b7 Issue #1374 \u00b7 Azure/iotedge-lorawan-starterkit (github.com) In addition to these issues, for which we will not provide more details here, we discuss several performance/health indicators. Unhandled exceptions : For a total of ca. 10k messages sent, all exceptions that we saw (ca. 48) were caused by one of the issues mentioned above. D2CMessageDeliveryLatency : The D2C message delivery latency took a distinct shape for the three phases: in the join phase, the average processing time was ca. 100ms, then for the first round of messages (cache pre-warming) the average delivery/response time was ca. 800ms on the gateway winning the race. As soon as the cache was warm, the response time dropped to ca. 450ms. No receive windows were missed for all ca. 10k messages. Memory and CPU usage : CPU usage was fairly stable, while memory was staying between 100 and 130MB for the LNS during the entire load test. To ensure that we do not have a memory leak, we ran a longer load test over the course of several hours, during which memory was bounded at ca. 200MB and analysis of the Heap Dump revealed that the largest contributor to the Gen 2 Heap were the device connections (as expected), which the LNS manages in an internal cache. January 24th, 2022 load test of v2.0.0-beta1 (ENABLE_GATEWAY=false). This load test was for deduplication strategy drop, the same parameters as the January 21st load test, except that we send seven messages per device, ending at 13.5 messages per second (giving a total of 12800 messages in one hour). The analysis was identical to the January 21st load test, there were no new findings and observations match everything we saw before.","title":"Load Tests"},{"location":"user-guide/testing/load_tests/#load-tests","text":"The (simulated) load tests in LoRaWan.Tests.Simulation allow you to generate load on an arbitrary number of gateways by simulating an arbitrary number of concentrators. There are a number of load-test scenarios that are used to simulate real-world scenarios. Typically, you would want to use LNS components that are as close to a production scenario as possible (e.g. LNS deployed on VMs with the correct OS/SKUs in the cloud). You can then run these tests from your local machine to simulate many devices and many concentrators sending a large amount of messages to the gateways deployed in the cloud.","title":"Load Tests"},{"location":"user-guide/testing/load_tests/#running-the-load-tests","text":"In LoRaWan.Tests.Simulation you have access to a set of load tests that can be used to validate the performance of the system. If you have access, you can either run the load tests from the E2E CI by setting the RunLoadTests input parameter to true . Alternatively, you can run the tests on your local machine. If you decide to run the tests on your local machine, first to copy the appsettings.json from the Simulator project into a appsettings.local.json and make sure that this file is copied over to the output directory. Replace the tokens in the appsettings.local.json : To connect the load tests with a locally running LNS, replace the value in LoadTestLnsEndpointsString with something similar to {\"LoadTestLnsEndpointsString\":\"[\\\"ws://<lns-url>:5000\\\"]\"} . You can insert an arbitrary number of LNS stations into the array, and the load tests will connect stations to LNS using round-robin distribution. The DevicePrefix can be any prefix that is used for the test devices generating the load. If CreateDevices is set to true , it will create devices with this prefix in the IoT Hub that is referenced in your appsettings.local.json . Make sure that the LeafDeviceGatewayID matches the ID of one of the LNS that you connect to the load tests.","title":"Running the load tests"},{"location":"user-guide/testing/load_tests/#example-load-tests","text":"All load tests use the Connected_Factory_Load_Test_Scenario load test scenario. All example load tests below were tested against IoT Edge version 1.2.7.","title":"Example load tests"},{"location":"user-guide/testing/load_tests/#march-4th-2022-load-test-of-v210-in-gateway-mode-enable_gatewaytrue","text":"These tests were using gateway mode - passing through the edge hub queue. For all tests a IoT Hub S3 instance was used, devices were issueing 3 join requests per second and 5 upstream messages per second.","title":"March 4th 2022, load test of v2.1.0 in gateway mode (ENABLE_GATEWAY=true)"},{"location":"user-guide/testing/load_tests/#edgehub-module-configuration","text":"Environment Variable Value OptimizeForPerformance true IotHubConnectionPoolSize 200 OptimizeForPerformance 5000","title":"edgeHub module Configuration"},{"location":"user-guide/testing/load_tests/#lorawannetworksrvmodule-configuration","text":"Environment Variable Value IOTHUB_CONNECTION_POOL_SIZE 200 Succeeded IoT Hub SKU Gateway count Number of devices Concentrators per gateway Duration [min] Total messages sent Receive windows missed Avg message delivery time [ms] Note true S3 2 900 2 25 7200 0 500 true S3 2 1000 2 30 8000 0 500 failed S3 2 1500 2 - - - - With only 4 join attempts, some devices could not join true S3 2 1500 2 45 12000 160 (join requests) Increasing the join attempt count to 7","title":"LoRaWanNetworkSrvModule Configuration"},{"location":"user-guide/testing/load_tests/#january-25th-28th-2022-load-test-of-v200-beta1-in-gateway-mode-enable_gatewaytrue","text":"We ran a set of load tests to ensure that we can support a certain amount of LoRa devices. These tests were performed using gateway mode - passing through the edge hub queue. By taking into account these variables and KPI, we ran several load tests successfully with the parameters we used listed below. For all tests against an IoT Hub S1 instance, we ran at a rate of 1 join request per second and 1 upstream message during the cache pre-warm phase. For all IoT Hub S3 instances we use 3 join requests per second and 3 upstream messages per second during warm-up. Succeeded IoT Hub SKU Gateway count Number of devices Concentrators per gateway Duration [min] Total messages sent Receive windows missed Avg message delivery time [ms] Note true S1 2 40 2 4 1240 2 700 true S1 2 80 2 6 1680 2 650 false S1 2 120 2 - - - - true S1 1 140 4 10 2940 0 500 true S3 1 900 4 25 7200 0 500 false S3 1 1100 4 - - - - Issues encountered in these load tests: Unexpected ObjectDisposedException when IoT Hub is throttling \u00b7 Issue #6042 \u00b7 Azure/iotedge (github.com) In case of two gateways and many devices, we quickly run into limitations that come from the fact that IoT Edge is actively managing a cache for each device that connects to it, for which it requires an active connection. Since IoT Hub only allows a single connection per device, multiple Edge Hubs will start competing for the connection on a high frequency. This results in (what we refer to as) connection ping pong and limits scalability on the Edge itself as well as the IoT Hub (throttling). We plan to improve the situation by introducing connection affinity to preferred Edge Hubs in a subsequent release. The memory/CPU usage of a single IoT Edge host in gateway mode (for 900 devices) was fairly stable at around 1GB of memory used and an average CPU consumption of 40% on a Standard D2s v3 Debian 11 VM:","title":"January 25th - 28th 2022, load test of v2.0.0-beta1 in gateway mode (ENABLE_GATEWAY=true)"},{"location":"user-guide/testing/load_tests/#january-21st-2022-load-test-of-v200-beta1-in-direct-mode-enable_gatewayfalse","text":"Warning Direct mode is not recommended for production use, as it has limitations with respect to message delivery guarantees. If you decide to use this, you may lose messages. This load test used the default deduplication strategy. First, we deployed two LNS on Standard D2s v3 Debian 11 VMs (2vCPU, 8GB of memory). We simulated 1600 OTAA devices, distributed among 8 factories with 4 concentrators each. All devices are in reach of all concentrators within the same factory and send 5 messages each, starting with a join rate of 1.5 messages per second and then progressively sending messages faster and faster (starting at 1.5 messages per second to pre-warm the cache and not hit IoT Hub S1 quota, and then successively increase the load to around 9.5 messages per second). Keep in mind that the effective message rate is higher than 9.5 messages per second, since every message is delivered to the gateways by the four concentrators per factory. The following bugs/issues became apparent in the load test: AMQP exceptions when running load tests \u00b7 Issue #1348 \u00b7 Azure/iotedge-lorawan-starterkit (github.com) AMQP exceptions when handling > 1000 devices \u00b7 Issue #1337 \u00b7 Azure/iotedge-lorawan-starterkit (github.com) We should send messages upstream when on DeduplicationStrategy Mark or None. \u00b7 Issue #1032 \u00b7 Azure/iotedge-lorawan-starterkit (github.com) Resubmit threshold does not consider deduplication strategy used \u00b7 Issue #1334 \u00b7 Azure/iotedge-lorawan-starterkit (github.com) Investigate memory evolution of LNS under load \u00b7 Issue #1374 \u00b7 Azure/iotedge-lorawan-starterkit (github.com) In addition to these issues, for which we will not provide more details here, we discuss several performance/health indicators. Unhandled exceptions : For a total of ca. 10k messages sent, all exceptions that we saw (ca. 48) were caused by one of the issues mentioned above. D2CMessageDeliveryLatency : The D2C message delivery latency took a distinct shape for the three phases: in the join phase, the average processing time was ca. 100ms, then for the first round of messages (cache pre-warming) the average delivery/response time was ca. 800ms on the gateway winning the race. As soon as the cache was warm, the response time dropped to ca. 450ms. No receive windows were missed for all ca. 10k messages. Memory and CPU usage : CPU usage was fairly stable, while memory was staying between 100 and 130MB for the LNS during the entire load test. To ensure that we do not have a memory leak, we ran a longer load test over the course of several hours, during which memory was bounded at ca. 200MB and analysis of the Heap Dump revealed that the largest contributor to the Gen 2 Heap were the device connections (as expected), which the LNS manages in an internal cache. January 24th, 2022 load test of v2.0.0-beta1 (ENABLE_GATEWAY=false). This load test was for deduplication strategy drop, the same parameters as the January 21st load test, except that we send seven messages per device, ending at 13.5 messages per second (giving a total of 12800 messages in one hour). The analysis was identical to the January 21st load test, there were no new findings and observations match everything we saw before.","title":"January 21st 2022, load test of v2.0.0-beta1 in direct mode (ENABLE_GATEWAY=false)"}]}